{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short Text Classification with Over-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP service “Bake-Off” on short-text classification of a real-world dataset.\n",
    "\n",
    "A comparison of the short-text classification performance of a selection of commercial services, open source solutions and common research baselines.\n",
    "\n",
    "Will cover:\n",
    "\n",
    "* How well do the commercial NLP APIs perform on a real-world dataset?\n",
    "* What are the trade-offs of various approaches?\n",
    "* What should feed into a buy vs. build decision?\n",
    "* A summary of lessons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Classify short text utterances, such as \"Turn off mobile searching\", by a defined set of intent categories such as \"Service_Management-E_De_Activate_Roaming\".\n",
    "\n",
    "Overall goals of this research include:\n",
    "* Evaluate commercial services\n",
    "* Compare against baselines\n",
    "* Compare against state-of-the-art\n",
    "* Lessons\n",
    "\n",
    "Specific challenges include:\n",
    "* Limited context to learn semantic representations\n",
    "* Limited data for sophisticated models with a large number of parameters\n",
    "* Idiosyncratic text, spelling errors, abbreviations, \"text speak\"\n",
    "\n",
    "The following general caveats apply:\n",
    "* This paper focuses on intent classification; not entity extraction. Training both tasks together may yield an improvement.\n",
    "* These results are pertinent to the specific dataset - your mileage may vary with a different dataset.\n",
    "* Some methods have procedural constraints, which impact performance. A dataset tailored with these constraints in mind could improve the performance of those methods.\n",
    "* The services will in all likelihood continue to evolve and improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Work\n",
    "\n",
    "* [Evaluating Natural Language Understanding Services for Conversational Question Answering Systems](http://workshop.colips.org/wochat/@sigdial2017/documents/SIGDIAL22.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "import zipfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show TensorFlow errors only\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification_benchmarks.data_loader import clean_data, load_data\n",
    "from text_classification_benchmarks.data_loader import remove_classes_with_too_few_examples, tokenize\n",
    "from text_classification_benchmarks.metrics import perf_summary, print_perf_summary\n",
    "from text_classification_benchmarks.metrics import perf_by_label, print_perf_by_label\n",
    "from text_classification_benchmarks.metrics import plot_confusion_matrix, print_best_worst"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuIAAAE0CAYAAABpbFaQAAAMFWlDQ1BJQ0MgUHJvZmlsZQAASImVVwdYU8kWnltSCAktEAEpoTdBehUIhBZBQDrYCEkgoQRMCCp2dFHBtYsFK7oqouhaALFjVxYFe30goqKs4io2VN6kgK6vfe9839z758w5Z/5z7sxkBgBNZ25BQS6qBUCeuFASFx7MTElNY5IeAwToABrwBGZcnrQgKDY2CkAZfP9d3t+C1lCuO8pj/Wv/fxVtvkDKAwCJhTiDL+XlQXwIAFyfVyApBIDQDPUWUwoL5LgXYl0JJAgAEZfjLCXWl+MMJR6hsEmIY0PMAoBM5XIlWQBoyHkzi3hZMI6GnKOzmC8SQ7wB4gCekMuH+AHEI/Ly8iHWJENsm/FDnKy/xcwYisnlZg1hZS4KIYeIpAW53Gn/Zzn+t+TlygbHMIeNKpRExMlzhnXblZMfKcdUiI+JM6JjINaB+KKIr7CX43tCWUSiyr6HJ2XDmgEGACjgc0MiITaCmCHLSQxSYVeuROEL7dFoUSEnQYUzJPlxqvhokTg3OkoVZ6FQwBnEmwTS0PhBm0xRGAdiONPQQ8XChGQlT/RskSgpGmINiK9Jc+IjVb6PioXs6EEbiSxOztkS4neZkrA4pQ2mnycdzAtz4nEVY8G5gLEKhQkRSl8sRSBNiRrkwBeEhCo5YHyBOFHFDYOzKzhO5VtakBurssc2CXLD45R1xvZLi+IHfdsK4QRT1gF7nM0dHasa631BYWyCkhuOgijABiGACWSwZYB8kA1ELT31PfCXsicMcIEEZAEBcFRpBj2SFT1i+IwHxeBPiARAOuQXrOgVgCKo/zqkVT4dQaait0jhkQOeQpyHG+IBuB8eBZ8s2Fxxb9xn0I+pOTgqMZQYQowghhHthnjwIOtc2CRA9G90kfAtgNnJuYgHc/gej/CU0Ep4TLhJaCfcBUngiSKKymqSqETyE3MmGAPaYbQwVXYZP2aHW0PWHngw7g/5Q+44AzcEjrg7zCQID4S5eUDtjwxlQ9y+1/Ln8eSsf8xHpdew1/BQscgY+jLsIaufo7B/qBEfviN/tsQWYgexC9hp7BJ2DKsHTOwk1oA1Y8fleGgmPFHMhMHR4hTccmAc0aCNc41zt/OXn8bmqsaX10taKJhaKF8M7PyCaRJRlrCQGQR3YwGTI+Y5jWC6Ort4AyDf25Vbx1uGYs9GGJe/6+YtAMC/emBg4Oh3XWQXAAdfA0B5+F1nkw2XqxCAi6t5MkmRUiffjgEBUIAmXBUGwARYAFuYjyv8B/EDLBAKRoMYkABSwURYcSHIg5yngBlgLigF5WAZWA3Wg81gG9gF9oIDoB4cA6fBeXAFXAM3wX04L7rAS9AL3oN+BEFICA2hIwaIKWKFOCCuiDcSgIQiUUgckoqkI1mIGJEhM5B5SDmyAlmPbEWqkd+RI8hp5BLSitxFOpBu5C/kM4qhVFQXNUat0ZGoNxqERqIJ6AQ0C52MFqPz0SXoWrQK3YPWoafRK+hNtB19ifZhAFPHGJgZ5oh5Y2wsBkvDMjEJNgsrwyqwKqwWa4Tf+TrWjvVgn3AiTseZuCOcmxF4Is7DJ+Oz8MX4enwXXoefxa/jHXgv/o1AIxgRHAi+BA4hhZBFmEIoJVQQdhAOE87BddNFeE8kEhlEG6IXXJepxGzidOJi4kbiPuIpYiuxk9hHIpEMSA4kf1IMiUsqJJWS1pH2kE6S2khdpI9kdbIp2ZUcRk4ji8kl5ArybvIJchv5GblfTUvNSs1XLUaNrzZNbanadrVGtatqXWr9FG2KDcWfkkDJpsylrKXUUs5RHlDeqqurm6v7qI9VF6nPUV+rvl/9onqH+ieqDtWeyqaOp8qoS6g7qaeod6lvaTSaNY1FS6MV0pbQqmlnaI9oHzXoGk4aHA2+xmyNSo06jTaNV5pqmlaaQZoTNYs1KzQPal7V7NFS07LWYmtxtWZpVWod0bqt1adN13bRjtHO016svVv7kvZzHZKOtU6oDl9nvs42nTM6nXSMbkFn03n0efTt9HP0Ll2iro0uRzdbt1x3r26Lbq+ejp67XpLeVL1KveN67QyMYc3gMHIZSxkHGLcYn4cZDwsaJhi2aFjtsLZhH/SH67P0Bfpl+vv0b+p/NmAahBrkGCw3qDd4aIgb2huONZxiuMnwnGHPcN3hfsN5w8uGHxh+zwg1sjeKM5putM2o2ajP2MQ43LjAeJ3xGeMeE4YJyyTbZJXJCZNuU7ppgKnIdJXpSdMXTD1mEDOXuZZ5ltlrZmQWYSYz22rWYtZvbmOeaF5ivs/8oQXFwtsi02KVRZNFr6Wp5RjLGZY1lves1Ky8rYRWa6wuWH2wtrFOtl5gXW/93EbfhmNTbFNj88CWZhtoO9m2yvaGHdHO2y7HbqPdNXvU3sNeaF9pf9UBdfB0EDlsdGgdQRjhM0I8omrEbUeqY5BjkWONY4cTwynKqcSp3unVSMuRaSOXj7ww8puzh3Ou83bn+y46LqNdSlwaXf5ytXfluVa63nCjuYW5zXZrcHvj7uAucN/kfseD7jHGY4FHk8dXTy9PiWetZ7eXpVe61wav29663rHei70v+hB8gn1m+xzz+eTr6Vvoe8D3tZ+jX47fbr/no2xGCUZtH9Xpb+7P9d/q3x7ADEgP2BLQHmgWyA2sCnzMsmDxWTtYz4LsgrKD9gS9CnYOlgQfDv7A9mXPZJ8KwULCQ8pCWkJ1QhND14c+CjMPywqrCesN9wifHn4qghARGbE84jbHmMPjVHN6R3uNnjn6bCQ1Mj5yfeTjKPsoSVTjGHTM6DErxzyItooWR9fHgBhOzMqYh7E2sZNjj44ljo0dWzn2aZxL3Iy4C/H0+Enxu+PfJwQnLE24n2ibKEtsStJMGp9UnfQhOSR5RXJ7ysiUmSlXUg1TRakNaaS0pLQdaX3jQsetHtc13mN86fhbE2wmTJ1waaLhxNyJxydpTuJOOphOSE9O353+hRvDreL2ZXAyNmT08ti8NbyXfBZ/Fb9b4C9YIXiW6Z+5IvN5ln/WyqxuYaCwQtgjYovWi95kR2Rvzv6QE5OzM2cgNzl3Xx45Lz3viFhHnCM+m2+SPzW/tcChoLSgfbLv5NWTeyWRkh1SRDpB2lCoC485zTJb2S+yjqKAosqij1OSphycqj1VPLV5mv20RdOeFYcV/zYdn86b3jTDbMbcGR0zg2ZunYXMypjVNNti9vzZXXPC5+yaS5mbM/ePEueSFSXv5iXPa5xvPH/O/M5fwn+pKdUolZTeXuC3YPNCfKFoYcsit0XrFn0r45ddLncuryj/spi3+PKvLr+u/XVgSeaSlqWeSzctIy4TL7u1PHD5rhXaK4pXdK4cs7JuFXNV2ap3qyetvlThXrF5DWWNbE372qi1Dess1y1b92W9cP3NyuDKfRuMNiza8GEjf2PbJtam2s3Gm8s3f94i2nJna/jWuirrqoptxG1F255uT9p+4Tfv36p3GO4o3/F1p3hn+664XWervaqrdxvtXlqD1shquveM33Ntb8jehlrH2q37GPvK94P9sv0vfk///daByANNB70P1h6yOrThMP1wWR1SN62ut15Y396Q2tB6ZPSRpka/xsNHnY7uPGZ2rPK43vGlJygn5p8YOFl8su9Uwame01mnO5smNd0/k3LmxtmxZ1vORZ67eD7s/JkLQRdOXvS/eOyS76Ujl70v11/xvFLX7NF8+A+PPw63eLbUXfW62nDN51pj66jWE22Bbaevh1w/f4Nz48rN6JuttxJv3bk9/nb7Hf6d53dz7765V3Sv//6cB4QHZQ+1HlY8MnpU9Q+7f+xr92w/3hHS0fw4/vH9Tl7nyyfSJ1+65j+lPa14Zvqs+rnr82PdYd3XXox70fWy4GV/T+mf2n9ueGX76tBr1uvm3pTerjeSNwN/LX5r8HbnO/d3TX2xfY/e573v/1D20eDjrk/eny58Tv78rH/KF9KXtV/tvjZ+i/z2YCBvYKCAK+EqjgIYbGhmJgB/7QSAlgoA/Ro8P2go714KQZT3RQUC/wkr72cK8QSgFr7kR272KQD2w2bNgrHnACA/eiewAOrmNtRUIs10c1XGosIbDOHjwMBbYwBIjQB8lQwM9G8cGPi6HZK9C8Cpyco7n1yI8Hy/xVmO2kwPgp/ln+MZbgw8Ued2AABAAElEQVR4AeydCYBcVZX3T1V1dVWv6ewb2TdCWBIIO7IoKjCCsowjgzPIp46jIOI4forOxzDOuIKoDCAowgwOiOiwiiCELZAQEiAJ2ROSkL2zdNJ7d3Vt3/9/q27360pVdfVSXUufm1S/qvfu9n71uuv/Tp17jiuKIlqUgBJQAkpACSgBJaAElIASGFQC7kEdTQdTAkpACSgBJaAElIASUAJKwBBQIa4XghJQAkpACSgBJaAElIASyAEBFeI5gK5DKgEloASUgBJQAkpACSiBEkWgBJSAElACSkAJDA6BXC3Kcg3O6ekoSkAJ9JKACvFeAtPqSkAJKAEloAQyIWBCIUABO0Ww83kmfWSnTlSiUZe48mMy2TlF7VUJFAgBl0ZNKZB3SqepBJSAElACBUPAWr6t1uXrXMcoo/C28ykYkDpRJVDkBNQiXuRvsJ6eElACSkAJ5IYARW/EKvLcTKHbqLwRsNNxqyLvxkZfKIFcEVAhnivyOq4SUAJKQAkUJQFj/Y6fmRW+fOnJsfgNOyZj5ogfKsiL8hLUkyogAuqaUkBvlk5VCSgBJaAE8p8ARS41d8iqXTz3wC+kLRyRpo4wrNI8YAtr4rVt5Dxkq9htumO2ToptudcjVT6PhB0m+hKocDtsima6WwkogSwTUIt4lgFr90pACSgBJTC0CMSlNXzCY8qZVueGYFge2VQnm+paja84JbA5jCqmHqtih91niUUpnE03dmuPZL5lHxOHlcpnTxovx2BrtbjpNvNutKYSUAJZIKBCPAtQtUsloASUgBIYugQocPmwgtcLJf5BQ0Be2nJYWls6cAQynIqb/434ts8j8X3YxBs7hbgR6X3AGoVPyiavS2aNqZApNaMlZCfGeWJojZ7SB6jaRAkMEAEV4gMEUrtRAkpACSgBJUACRjDDCm6FcxBCeNown3xizkhZB4t4CHWMv3ZciBtB3tkw1s5a060gx17zn9V6WyLQ91Nr/HLGhGojwu287La3/Wl9JaAEBo6A+ogPHEvtSQkoASWgBJSAsYQjTLd0GCfxGBC6p1B8h+Anjo15dKLCsW6FFeKluz+53dv7rdftllJMwtwAxJuXYvUoh+bctCgBJZAbAmoRzw13HVUJKAEloASKmACtzUyaYwu9QbBeUrwujxG/dn/3F517s/KE9wWJVnCH5s/KmNqpElAC6QmoEE/PR48qASWgBJSAEug1AQpcpzWbr9fUtcmOpo64GI4vzGQ9qOOYQO4ui82+ROXc65mgAVxTJlSWyonjKsVESokPE8VdQNetQl861jZKQAn0l4AK8f4S1PZKQAkoASWgBBwEqHOhfeGiElO8PriAvF/fLnes2CuHj7SZ2IZ2EaYR4TCXW9Ed28bEObu09Yys767TeTijwsWafn+J3HTBVLlweo20BmMdRSDDYaTXogSUQA4JqBDPIXwdWgkoASWgBIqTAKWu1c0RuKgEoczpo+0tdZswJXRViYlu+IxTiON4lwhn41jrbtZy22EvkbH/EsQQ7zCC3wROND3wZkGFeC9hanUlMMAEdLHmAAPV7pSAElACSmBoE+CCyAAeHVTfKHZB5E64pexpDUoY+yjEYwVP4s/j2rvztTneudPW78MW/Y8u98jsEeWC2wA7nPhwU+DF6xL1T+kDVG2iBAaGgArxgeGovSgBJaAElIASMAS4KLIdj2BHTIhzJ2N1e/HD7QzanSiA44J8oB23OQxnEkTElq4bABGfD5FUIPTpN65FCSiB3BBQ15TccNdRlYASUAJKoIgJUFNbXc0tLdFBqOAggnrb/YmnDweVxF3dX/dwuHvlrleU2SXwU3e73BDkXKIZK+yuj13Ge9CNElAC/SWgQry/BLW9ElACSkAJKAEHgZhft6tzsSY0sLTAOv5fGw/K5oNtRvyyTvwJ3MG7FmuyG+ONQn9u+8LsiO93jJPp0wj6moSEQv9n4USZVO0zNwS260z70HpKQAlkh4AK8exw1V6VgBJQAkpgCBPoFNdg4IES394YkPf2NkkLfMSNSZo6nA8Kbjyouo04R327n/jsMVaI63Hu7l1Bw/qGdnkbmTWn1ZRJIBw2U+CwWpSAEsgtARXiueWvoysBJaAElEAREqBPtvUQ78DqzEmI473wmGGy9XCbWaxpk+vELOPdhXhMlMehGFXO530X4hTzY6tjccQDjsyedn7xkXSjBJRADgjoYs0cQNchlYASUAJKoHgJ0Be8EeLbLtak4ZmRSRi+uxmq3JlmPkYhbpqOb5KRSXMoWfVu+/BBL5W+EikrcRu3FOsjzsWaFXjBVPdalIASyA0BtYjnhruOqgSUgBJQAkVMgG4fNqEPT7MDr8tLPFJT4UYElQThm/AyG1h4c9BsorjEfc8xCOcoLvMjG0Nqn0pACWRAQIV4BpC0ihJQAkpACSiBjAlA29KjxAjdeCOGCFx5sEW2w1fbSGHW4THzw/Ycdz9Jto8Vu+23bXreci7HVPlk/vhqE0aRr1mc84vt0Z9KQAkMNgEV4oNNXMdTAkpACSiBoiZAnUuxG9e7xvVja0NAHlizXxqa22PnzuOmEsQ3FLERx/jBDJssnQs37bH+CHH06fO65dozJskF04ZLWzzRkBkzNpz+VAJKIEcEVIjnCLwOqwSUgBJQAsVLgCIXIcNNCTOrPZ754IvtgWWckbxjIhx7Ywo8ptr5nBWp4OMq2QXXkdhTKnfTXbcf3GU8W8yPboc660fQhxtCPAqXGFrB7bzM84Qm+lIJKIHBJaCLNQeXt46mBJSAElACRU4ggNWYhzuQ5p7hUuKFAnwr3FJ2NLWbxZrmiBXWVNrx53aXFeKJr21/3NLV3KSsRyUGJGQkFopranKuv+QCUTdEeCTqknGVXjlxdGWsebxTn88jw71R8XvYixYloARyQUCFeC6o65hKQAkoASVQtAQoxOsgxNsdQpwn64c69lMdx0vXM7vHeSDl0bjVPCphqO6mkEtqMdZBhGRpggWei0L5VXeFR2SkFwLcKzKiJKa8m1EnrsHNQBTiI3HMj2gqWpSAEsgNAXVNyQ13HVUJKAEloASKmAAt051+3jjPEpivW+CbXdsSghiOy2GnKk7BIu6h0v0odnYgXf0HwRLZifxALbB4MzRizEelq6oH45S7EUMconxeeVQmlMas5rYG55fBFGx13SoBJZAFAirEswBVu1QCSkAJKIGhS4DilgKaLiEs9PxoCIbkD1sOy456pLi3FeIq2LlYk/U7j1Oy0888tqNzv89XKjNmTZCQ3yVt9HGJ+5GbauwgXjh6AGMwpvmRsEsWlIvMQBuTTIgSnPNLbGQb61YJKIFBIaBCfFAw6yBKQAkoASUwlAhQH0fi9mYvrNf7WoKyaX+ztLbBj4QKmToYIjuKHzaNvbFQU5zzWFwg22Pcyecen1cmjhstTd5SCcLCbnQ6m6CNM1EQXNKN/zj9yDncXlRsb4bLCm4KxsAyzrpsq0UJKIHcElAhnlv+OroSUAJKQAkUIQEKY2tsDkL1TigvlQUTqmTrkTaJQBnTKt0puFHR1LVb8og3jhgflzggtCmrqZYR42qkBanqGf2E3bCU49P8QzUukyyIH+xrmiOyt80cMj/oBV6Lu4O3WkTOx4tK+KvHh+iqpM+UgBIYdAIqxAcduQ6oBJSAElACxUyA1my6pdjMmtx64Z9y5cxREoKwtuK5i8HRe7qOxcS2EdLwB//zkSjcXCLdrN8crwpW7k+PLoX5m2JcpC7UITtautu8aRl/H+J8AhZonojc9iXGZu4cSZ8rASUw2ARUiA82cR1PCSgBJaAEhgQBp7ymWGYIQ18fQwVSXG9oCMkRrMoM050l7n8es6rDFxzRUQJ0XUG9Uqj2AEzu4XjiHruIk300wxy/ts0lM8oQwQXvgnOOQ+JN0ZNUAnlGQIV4nr0hOh0loASUgBIofAJ0KYH27iz02d7eFJADrUEjfhE7uPNY59POJzjEw2hjtnjOZDybo6USwqLLmP840wLFCreeqFvoAhNGPUYrxPpN2LtjXupmwSfq0D5OMb6v3Y1wh24ZASVu+4j1pD+VgBIYbAIqxAebuI6nBJSAElACxU2AwhkPunezeGGm3gER/tu1tdLYHIhpa1Yw9SDYIaCNBscPszWtuvZFcLy0zCej506GXzjENXy9vfj0/ui4UplSBgEOhV2GMQLY73JFhOHLz6/xyPFwP2Hh8ScRbPwIXFXcCGXYjontDLhlFvL7xKdo6ukPJaAEBp+ACvHBZ64jKgEloASUQJEToMC1HtoU116Yor0wi9Mi3SW24xCwj5KZbcw2ro5dqGzrupB0hyI8ApcTY+GG+8lMnwti2yMdGAha3bimsEc2H4NP94lej+mPLivPYW8kFJuRC+4p9Wa1KGtrUQJKIJcEVIjnkr6OrQSUgBJQAkVHgEI4DAUdcyGBQIZKHuX3yqfnjoVrSgDHYuEDY3o7/pObuOqO7Ylh4S4m5jkQccsmpM00Yhr7IhD1bdDVLeg7gC3rObU1jOISQDIfCnuOH8aDbc2NAPYGEXWFdZxjxUbUn0pACQwmARXig0lbx1ICSkAJKIEhQYAC1ylyKcwnVpTKpEpENmFxHqRaZuE++9zsiO0qwb4PkJln087WmBsLLeBwAt/aFJIOqO8g+qZrygSu0oTSjkVYiUh9fLEmj7fhOeOQR0Ko4kFae47jnEN8PN0oASUwuARUiA8ubx1NCSgBJaAEhgABWqj5sIW6NwghHGLwb1PgdhJ/1vXE7ui+pRXbh7YlsIJ3YEtLewfyAv1lR6upyHGGwUXlqzMrIcIhsiHKXzrQLmsOoFK8mLHwIwq3FOQXkjFehFe0B3WrBJRAzgioEM8Zeh1YCSgBJaAEipmAFdqMmBKAK8iLu+pNinvGGKdKjwn1uM83QBhXlrg6tm4tJrMmIcExPFBeIW5/mUTgomLbGn4YKIJoKhT6tIZDh5sIKnRFsXOwpnYXbgQqyrwyvhQOLxTmpgP9oQSUQK4IqBDPFXkdVwkoASWgBIqTAAVu/METZPzwfQhbuHpPg7S10kodX4Rp6sRcRliPotsIbLMfP+w+I84j4qsMScU4L+qgPXy+bTFjxUV4TIhDieM1o610lfhzqPSZlR6pgb8LqqgS7wKkz5RATgioEM8Jdh20EAlc+4s3ZNX2w4U4dZ1zGgILpo2Q//raOWlq6CEl0EsC8WgnRuiiKeN7jy0rlTMmDZedje2CBJlGBBvRDZu0iYJidDJ+xPWytYhTmcfqMS44XFs8EWmOemJhDON1Obvm1qg8uqPZuJi7Mf6eJsQrhxXeVqF7C/3Hx1R75czhPhNnPIwJdiYGYidalIASGHQCKsQHHbkOWKgEVIQX6juXft4r9eYqPSA92nsCUM42Ign1L6OZeN1uOWdCjQTGdYljZ8dWlHftY0uWTilt3E5a4FryXG277DmIESjS42qf6zI37UX++ngxwput0Zw+4Yyf4vO55cNj/VID/3C6sZRgH49pUQJKIHcEVIjnjr2OXKAERh13foHOXKedSODQ+lcTd+lrJdBvAgjfLe5oCAZoxv6mJI+FM6SlugLxwPtaKM2r0eel48vkMQQPrzvSEQtHaAR5THR39h3X8S46qKP4/W45f2K5zChn3PGYOo+GQ1Lq9nY20SdKQAkMPgEV4oPPXEdUAkpACSiBIibg9bhlmA/uJxGPtLaGjbsIT5chDLu5bfeRwXCvWz4ztVLeKG+XjXXtEmgLw+LdlfLedAv9Tau4G77gE2pK5cMTymQSYplThNPlvLysRIa5wlKCMIj0WdeiBJRAbgjkTIgzQ1gwGIz7uSElb0dQ3PjqjvsbGxulra0NX6lFpQKrxCurKnE37xev1yslJTmbcm7eIR1VCSgBJaAECo7AuPISaW4Iix++4cFgOJ7V0rqZ9O906OpSBYH9VxPLZOFIn7x3JCA74RPejBz39Pt2wwruw/GxFV45vsYnMypLhIbxINq5PR4pQ8QUTzgs44Z5zOdu/2ajrZWAEugPgUFXtaFQSI4cOSJr1qyRd99+R7ZufV8OHTwkLS0tENolEkBw1L379kkgEDBf61WWl8uIkSPl2GPnyBlnnCFnnn22jB8/3gjz/py4tlUCSkAJKAElkC0CfrigTKkS2dOKsIMQvqES+KsMtOEZwnqyX2TGcL8R2a1I1oPIhvD9hsUbw/nwhBZ4+o9jI8jjg9CGMHDh2Lhyt5T1w00mW9y0XyUw1AgMqhCnlXvp0jflycefkE2bN0koGJL29jZpb2uHBbxVKNJpBe+AGO8IBfHVWZmE/T5pgoV8+bLl8torr8nYcWPl03/zN/KZv71aKisrh9r7peerBJSAElACBUKgCpkup8ElvAFhUprg0x1CFJOYJB7AE2CXKNDWAm0NA1YsNCJdVeCmbvabXJ7Y74WVvAI3BPBUgUhnCy1KQAnkmsCgCfHGpiZ5+qmn5MUXF+Gc3TJi1GhpaWqUKO7OIxDf/OPUBkEeggCnCwpLBF+dtTS3GKFu3FKw/9ChOrn7rrtNvU9/5jMyYsQIU1d/KAEloASUgBLINwI+WJ3H4JN2TBmCD+KzjkI5FyWXY+fifHVMJVAoBAZFiDdBhD/2hz/IurXrYdEej8UrrRKs6xCPp0T8vjLzh6mU/t940Gre0REw/CjK6aJCnzZay33wH/eUxPzE/+d/Hpbyikr560//tZTBcq5FCSgBJaAElEA+E8iVCCeTXI6dz++Jzk0J5JpA1oU43UyeeeZPsnr1Ghk2bJhZjBlCyCQ/xDP/MPjgeoKATBJob5eGhkazjwsyA+0Q4wjTFIYAp0AvQ1rf0lKfeH2lUgJhzkxlzzz9jMyZc6ycetpCXXCS6ytJx1cCSkAJKAEloASUgBLoFYGsC/H31rwnb761HCu2kU4XFu36+npEPvFCOHsgrEuNuA7AT/zQoUPGsu1DdBRUlGAAiQkiQanGivNRw6uk1FsqgVBYmtvDAls6EiS4pAWW9SXwOZ89Z7YMH17TqxPXykpACSgBJaAElIASUAJKIJcEsirE6Wby8kuvICJKswyrrha6qNDFhGEKPbBqD6uhhTyK/Y1SgRCFo0ePRnIB+NB1tMjIihKZO32iHDv9GBlVVYZFLmFpbGqWbbv3yerNu+SDJo+0YSn4+vVrZe/evSrEc3kV6dhKQAkoASWgBJSAElACvSaQVSG+fsMm2blrF6KjBCUMId0OdxNaxe2iEYryQKDDuKyMGDkCPuBwR2k5JFPHTpCF84+XSZMniAt+5NF4BoSxWBE+68R5cvbJ++SRv7wpG5Hi99DhRiPE5849Vt1Tev32awMloASUgBJQAkpACSiBXBHIqhBf8sbrJmY4Y6JQcHdg4SULF19KNAJLeAjhlLwyaepUqYg0S6j+kJx04kxZMH+elMInnAFQo0zFy8INXFOiaFc5dqJ8ZOFcaV62FVbxqOzYuctY2+mDrkUJKAEloASUgBJQAkpACRQCgawJ8YaGBtmxa6eJCe6BKwoXbXKRJhdomvimUWT0QujCmpoaqfTBf/zAAZkyYbTMP/E4+I3DT5ypwyjYsWDTFIY4hF+4CxZ15uetgVsLciSYhZsHDx40kVhUiBfCJadzVAJKwBKoawrIF+9eKltrm+wu3RYRgRnjquT+G86SEZUMStC3crg5IF+5d5ls2N3Qtw60VUETWDBthPzX184p6HPQyacnEFe56Sv15Sj9tpsamxALnEkMwhKkEIcrCl/zwWgojBNeVTVM3O314vOE5bjZs8THUIR0RaEId5dAh3vhnoLsA3gueA7/E0zHLRXlFfjJvkJSW7vfWMT7Mk9towSUgBLIBQEV4bmgPnhjzhwgEf6Fu5aqCB+8ty3vRlq5/XDezUknNLAEsmYRr62tNYl4aAV3R1wSdHdIGG4mLmT2sj7iLojqCn+peAIHZVhlmYwbDdcSuqJQbOPhMuI7NkUXZHc0gjRhrjAIRI3rig99hYMBOXiwHS4wai0Y2EtDexsMAqMrXDKpxi17GiKyvxnX/hAoo8pd0hCISpC/ykO0OEW4x1chw6acBFuDyX84RIkU/mlHQh3SsGO1hAMtQhH+6wGwhFOE89sSj68c18h8vUYK/zLp1RkcWv9qr+pr5cIkkDUhXl/fAHeUdmP1jsIdha4pFN4RiHIWF1xOmC3TA/eUkmhQRtWMFCQgw8JMuK94/ThOizgenpgFHL4q4opCjNNVJRoWN2KK+7wlxtLeFghBiNcZiztjkGtRAvlOwIfL9KZz/Oa+c8uhsFwwA78LuLTvWIzssvGU1fl+DpnMr8Kk0nbJ4daum4wvnOaTx9d2yOZDRXSimcCI11ER3gtYBVJVRXiBvFE6TSWQhwSyplrpIx7C4koK444ORk2B4IbSLkEUlHAkDKENtxJYvz1RLNiENq+pqoLAxgdzqB0CHNPyMM09DpjPb/ygj7gp8X0eJAPyeuDiQpcXhDZsbFQhHiekm/wncMmxpbIJUX+eXBeMTzYoV55QKn+7wCcPvRNb1Jz/Z9HzDBceUyJe/K4u2mLPU+RHr+J3fIgWFeHF98arCC++91TPSAkMJgGam7NSmpubzcJMhisMw8ode4RhAYwa/3CGM6SVPIjQht4Sj1SVY4EmVTfEeRRiPIqEPtEQBAkXZ1KgG0VuxXjMok4hHoWvOf3PmxFjnH1qUQL5TgBJYeUjM73y7IYucco5P7+pQ86blrV743zHUvTzUxFefG+xivDie0/1jJTAYBPI2qd+S0tLbJFmKGgs1ca6zYgpENW0YLvciCcu7ciUGRBvjVf8+K4+ikWcUO+IjIIwhS64snSgDi3ktI7b6CkMmULrOOrForEEJNAelJZmjAdRrkUJ5DuBUfAL33EEC5h5f+koLR0it8E1xZbhZS756tl+qSh1STl+BZ5eH5QX45Zlune8sjVmRfdjrQRdPx5ZFTDbG87yy0PvBqSxvevG9bqFPljfO+RIWxT9iXzxNL/48dtfAmv18l0heWFz7KaA/b70flCugnWev2a3Yz5zRrvlw3CdGVHulrGVLvnNioCs3he76R3md8nfnewzfXKe7+wOyVOYJ8unTyyVMyaXmCUfJ0/0yFs7Q/LatpBce4oPNyEdcijurtLX87ScCmGrIrwQ3qXezVFFeO94aW0loASSE8iaEKe1m5k16YZCgcywhW6YAqOwcEewj6EIIxDlhxuaJTqyQnywiotZjBkT2Zwu6xoBDvcTU6gM+KAYd+Erb/iXM1lQewCCvrkR/SYom1gr/akE8opADcSrUyQ7J7fxQNe3Ol+DDzndVLYdjogX311RlO9risja2rAcM8wtn5hbKrfBzYO/EbNHxV6z/prakFw02yuPvRf7vaE/+vSRbiPCOdbNF5TJfy5p71wcynEONkdk5d5YvxfP8cpPIcC5bprlsxDa/76oTTowNd4QsP2a2jZz/DPzS+UZiOodR2K/e9863y/rcQ5b4P/N8fej30TXFC5QNUs/Yt1LX88z3jzvNyrC8/4t6vUEVYT3Gpk2UAJKIAWBrLmmtLW1Qhw3SxCJfOh+QjFO15GYqwq2sIqHsSrtMBd1ihdCIy6wsRCT0VGidDOhMA/DuhaGiwrcVKJBiI6OVom2t0i0rUECrU0mfnigDVFT6uuRNKh4fGtTvF+6uwgIlOCGtKcFmeOqXEY4U4Sz0HpOS/QnjuXaCfOFkCyDhTmulc3CR4pxljc+CMlZU7vusc+d5jWWaB6bUO1CEizpFOHcx4WTF8NnnQX3y/L2brqQmZfmhw9W8wnVsb5b0fZ7EOX2+GOru0Q4Le28keBNQqalP+eZ6Ri5rKciPJf0szO2ivDscNVelcBQJdD1aT2ABBiesKmpCeELW8WPDJkU4m5ETDEWcYxjfbndiILSBN/u5g4s5IR1m/7eLkZKYcFizmgU04MwMIXCACLdPGAR51MKbwp8Pg7sPyDt7V1f68db6UYJ5B2B+vaIVMMqnq6MqXTLvsbu3/A0wNXE2W4tLN/JCj281sB1ZMEEj7Fynwu/839/qc1UHV3hNkL5/8Jy7SxH2rrG2nCge78/ebVNLj2uVKaPcEs7DtEC/l7cNWXeWI+cOYULsEVakeV2LOa9dEf39s5xEp/35zwT+8q31yrC8+0d6f98VIT3n6H2oASUQHcCWRHi+/btk927d+PDOdJpDY+5pjB8IV1VgrC8xaxmAbiVtCL8oHE5oSU87n7CUIexmOFWsECJ45hxV4FLiwvRVg7XN5lwhty3a+dO4yfe/fT0lRLIPwIHES98GkQtF21ayzJnibXHcudlFfLlJ1qMr/dwxNt2Fvp004/cFlq2U5U/QSx/8XQ/LN/tcrAlatxKWPdgS0QO4PGThMglzFJri3MMhhRtRMzvB9+OfdvEOXznw2Wyq75dAsh+y7CLVuSz/RfhY96bQt/2/pxnb8YazLr5JsJ5A1cFH35bmmD8SOUeZetkY1vIMeTzWYTzb0cZwo9l+p7OHeORDQ43uMT3uqfjifX1tRJQAn0nkPl3yBmOQev0H//4R9m+/QOTQZN+4sFgzD0l5pYSMZZs667CY4EOZNnkAk3jhkJXlKB5bl5H8BoPPo+GoUL4gGAPt7TKztpDEoJV3Yu/QvuQybO2dl9MyGc4V62mBHJBgG4mL2HRJcMVOsuVx5fCLSRmTd4La/j0ER6p9nWJp6uw+HHx9jTq29EZkwNRXP/tfJ88h2gstuxthFUdfXKBpC2fmueVUyclvyevhHj7NnzCbaFFnH7fleijFC4rAWbBjReOdzLCFfIGwxbOg+IrVenveabqN5f7802Ek8U18OWnP//FcG3i458+5JcHP10hpx7juANLA41uRyPSvI9pmnY7xMXA04YP+MdOtzGy8SKfRTjPl+tF/u2jXb+nPTG4ZkH3vz2J9Xs6nljfvk52nSTbZ+sX2raYzqXQ2BfzfJN/+vbxjOkasmjRInn44UdMXG8PVmRZSzgt4CamONxJGFfc70dyHli4Q0ivx9CGEQpseLwyvjgjqhiLORxWmQwoVvCBD8s3rd8umOkO1tXLtj0HpLUNQrzEKw1YHLplyxY56+yzpaws8z9IfTxVbaYE+kXgGYQu5CLIH15cLgcgbOfDjYQ+3796K2Z5pqX8nqXt5viO+rBMRvbNlXvC8vr2zN0+ntsUNBFKuHDSWW57rU2+ca5fKIJnjPTIdvihP7kuuVtXPdxh3t0TknuvqDCLRGfCD52LRXfVx/rciUWa7ItuMyMh1O5Y3CafP9UvSz4IwuVMZBOsbpfPK5VvnueXdfvD8ueN3W8kBuI8neeW6+f5KMItkz+u6fLn5z4uvL3n8gq56elW4fucriSLB5+ufqpjhRhDPt9FOFmfjhvp/VjIzTUgvNnOVUl2nSTbl6v59XfcYjqX/rLQ9gNHoN9CnL7gDFXIhZmLFr0k99xztxw+XIcZesQDi5nH4zGiugRRUXx+H3zCG038cJ/PZxaa0X2lBD7fblrE8dkepQg3D7qm8H9MiJs/LXHXFA/8yLfs3CM7auvlIL7aHjNyBNrAN3XJUvnEpZfKMcccM3CEtCclkAUCFKCMcELrMUMC/ucS3JR218uyA2L3+idbZAyOU+jSg8uWf30h5vNtX3P7L3/pvu9N+GrzkVj4Qc26FM5t8OvmAkxbkvX7J9w0UNRzHnUONxe2eRSLNem+Qsu5FXM3P4cF1fEOuf3hK20mVCKt6SwMiegs/T1PZ1+5fJ7PIjwZF77vDCl5/DiPWeCbrM5Q31cIInwqvmHYg5vqxduC8vHZpZ1uZEP9vdPzVwKFQqDfQnzJkiXy6KO/l9WrV8tO+GnTCs5FmbRsR+E2wuyZFOFVVTWwfoeMpdyGMgzAgl6BjJqV+JaMPt90XXFBjUdN5BSqcMpwK8TxkR73H2ea+9Ubd8qeQ/XSFnabr8jZ95KlS2TdunUyYcIEszi0UN4EnefQJUBBvq/JytbkHA7AvSMbpS4exzuTvrkYc18KSxtvIKwIZ1/JZmtFeLqxsnWe6cYcqGOFJsLtefN9aYevPwu/dk8WXz5VPPhkMefZT7rY8okx5NPFw2dfuSyFIMLJ5+MIVcrMtfT5/hzyBfAT0/k7SNewr+NbK0Zr4t+b3yHfgLP0dNxZ90aEUL0ToU+dheFHf/FGe9K8AVy8nSyXQKprjf0mu67SXVO2Taq8CjxOowPDvzLnQhPWvLCuXVSebi5sa0uq34N0eRBsW90qgXQE+i3Ep02bZlxM6uuPGBHOwSi+3QhHSMHt9ZZIdXU1rOFl8OGuNQs1Y64jLhN6cOToMTIRljbEMkQ7yG6KcZoJIbbZ3hoJjRxnv7Cyd8A/fOX7e6QBq9W8JSUmQgvFP+OJ3//rX8ukSZNkzpw5xhqf7uT1mBJQAkqgvwQKVYQzCs5pcGn4b3wzw5IqvnyqePAMU5kYc579pIstnxhDPl08fPaVq1IoIpwflcdi4eV9cZc2RjNagORZ78KNzZYbIEB/tSxgvmFjPgIKZ7azpafjth63/FYssfA9ZUl1nSTLJZDqWkuVyyDdNcWxe7qObsI534/wr8x3wHP/fx8pM65y/KYx3VzYty2pzi9dHgTbVrdKIB2Bfq+aoeD9wQ++L//8z9+EW8hlMnv2bPhoVxg/7YqKCljCq4xQ370LUU1ams1cSktL5ciRwxDVJTKiwiszR/uwHrMDazDxwKLMCKKq2EcUz7lQk6/D2OKF7Nh3QFZtq8VdPy3vIjXDh0tlVTVEflhefuklefKJJ4zIT3fiekwJKAEl0F8ChSTCv3S6T76LiDd8/OrKCmG21W8+22KspD3Fl0/GiX97E2POs15vYsuzj1Tx8JONORj7CkWEkwV9lilebWHm3Y/BQm4L4/Tzmy+6f7FwofjDsIi7CR6lp+Om0gD/6OlaS3Zd9XRNpbuOxoPBAbjU2aRj/Fbgbqy/YaSZnubS06n3lAehp/Z6XAmQQL8t4uxk4sSJcv31X5EDBw7IrbfeKrt27TYLMpld88iRI8blhL7iFODc0q+cX52NHTdWjhsWkTJXSIJRxDVmdBT6ijOWOH6zjFtK/A8GvVKYjS/Y3iFL39sqOw40xuKS48CUqVPlwxdcIHv27DEuKfPmzTNbzk2LElACSiAbBApJhPP8aTW1YoRf1f8T3BW4oJYlk/jysZrdfybGnOfR3saWTxUPv/tIg/OqkEQ4iVB0L98VMswtoZlYgM2FuFwDMBGJuPY22O+VYzX2wxUuwg9UlJ6Ox1qk/unMkJu6VvcjmVxriddVJtdUquuIuQq4kNVZDsXd8k4a7+kxr4KzXeLzTPIgJLbR10ogkcCACHGGKNy6das8/vjj8pe//MUs1qRbCR8U3kzmE3PvjsIq3mrcVUaNHi1++JGfPDoqB7ZvlfDkmVI9rAquKR3IoIksmvj+yCVQ3vweCX8z2FcJ+lq7fY889up7WGQWksoyWNLR8fr16+XrX/+63Pyd7ySen75WAkpACQw4gUIT4YkAaCXlwttZiILDqDqZxJdP7IOvnTHn+ZoCsLex5dPFw2efg1UKTYTTt5kWWS6UnjO6KwwlfcXPR3x/RihiDoGFk2LWb8txFFxJrEW8p+O2Taot443HbWWpqhy1P5NrzXldZXpNpbqODrdFpcYRrpUTKsN16oW2yGQuR52AY0cmeRAc1fWpEkhKoF+uKVwYedNNN8lnPvMZueqqq+THP/6x7N+/3wzE0IQU34wPzpjhfDCjZmVVhQwbVmMWbW54f7vsQ3KRCvwhqd22UXbt2CGtHfgjUT4M4r005pLSEYA4D8F0H5KVG7fLvz38qry2bo9ZoMnFneXl5SZqyw9+8ANZu3Zt0pPUnUogHYHXNzXIj57ZJbUNcfNgusoDdMwkWEmT+4aJc/iBqSX/CBS6CLdEf4+IN39zUuwi7Cm+fE/x4G2fmcSWt3XzaVtoIpzszp/ulafXB+XxtR3dHnS7+NC0mHvKbljDZ8FC7sxHwHwF1iLe0/HE9+gD+FjTH9sWLsTk57wtya6TxH09XWu2L7vt7zW1BwwYppU3LrZcf6ZfqpALobdzOfpc+pfvwc5Ht0ObQL8s4l6vV958803ZuHGjSTPPGN/8AojWaxYu2PTAD9zv9xuf8VKELAwj4c+hpkNGmNNXa+3eJvnYcTMkGD4iLUcOyq7WVqkZNRp+3yPEX1Zj3FVCEOObN++V+//0tjy/ajscaviHIGqEPcepgn84RfhPfvIT+d73vidTp07lbi1KICMCQSSl+d8VdfLUu4flkyePkM+dO1bGDXP81c6ol95VYoKVqUjY860/tyZteM0Cn5yIr02/hhjPWroI8MPUh8gHtETlohxuDsgX714qW2ubxOODUWHKSeIuye61kq3zZMg7iii6J/B5uvjyPcWDt3Nk9Jx0seVtvXzaxkT4KgkHWmXmuCr59Q1nyYjKNHfJPUye18gX7rLXSDmukflZuUYotv/1xaP/PjASDi299n295812uQkJnJoRLYQi+tmNHUjOFBPT/AxOdzzxVP+MtswT0IKwpz4ETngNIROdBoNk10myfemutcQxe7qmrHtVYjv7mud437J2+cklFfLBkbDJQLoGuRB4zbP0Zi7JzqW/+R7sPPuzfWd7k/zqlVq57//M6k832jZHBFywXPfrE2358uXy0EMPyZ+ffVYaEUucf9npikKXFCbwibmlIEYyBDgftIyzlEDEhxAT7ZNnzpHb//Z0aairk9b2gDTj+6UAfj/cPr944VPOBZh19c3ScCAoTdub5eW1a2R5e5vsDQQh+N1ShmQ+w4ZVY1jEWUayoHPPPVe+9rWvyfnnn2/G0R9KoCcCL6+vl289+kFntRJ8wCQT5Cfd9LSpM+q48zvr9vXJl8+g0C6R773UelRYQHpjMdEPP0AYk1tLF4HzppdgkZXLhGvr2tv3Z4fWv2oar/75ZT12MlgCq8eJZLlCsvjydkh+U5NJKMrE2PI0zfTrg8ZOYIC3ThE+AyL8/gIR4X3BUON3SSPEOP+uJCs9HXe24Td6TbjpStFVt7wBtl2yayfdtWbb2e1AXFOM8HII7jrJ5t2buSQ7l2T5Huzc+7rt6e+TFeDvftBihljxvfl9HUrb5ZBAry3idC+hTzbjhjMpD11R6iCi2yCCae2m7xmzYVJwUxjH0tpjASaEMh8U6LSQh9BPBJZIX6lXSssrpBTCWjxtyJqJUFpYkNnS3ipH6hukuT0oDa0B8Udr5IxxE+TYlnq5MNAhT9cekLfqG6UF0VSCeEQg6in0mdmT1vG/+qu/khtvvFGmIbyitdDnkLMOXUAEQoNkIX9mQ4d84thS+fXy7nF9z5pSIkuRmfJ0fO2bq8K4vZcgFfrvVg2eu06uzjWTcYeKCCeLdPHlMxHh7COT2PKsl8sylEQ4OTtj/Sfj3tNxZ5tGiPB0Jdl1kmxfumstsf+BuKboE5+q9GYuyc5lMPMgJArwVOek+wuDQK8/6a2F+6mnnpK33nrLCG0u1uTDFgpfK7y5j8+5j8Ldj3jiQYQqDEGoe0r9MnPiKLP1IeGPy10iLgh1bt0e+Lh5ILA9AQm6kKWzDYtRQh6pQR/zYS2fCt/wdY3Ncv/ufbIfIvyij35UqhEqkbHKhw0bJscdd5wJnZhOhJ96yyo7Zd0qgaMIJAryoyr0cwe/Hv3wTK/xtHJm1fwI9vHrUqcQ729Ci57ac9HXFfAdLfe6xI8HF0g9+HbsBiFdwgsm33h3T0g+MbcUi5/EhEn7n3cDciPi9nIxFDN3/gGp1XfFw6el64s40yV4SZVQo59vQ4/Nh5II7xFGkVQYaiK8SN62IX8aKsCL8xLotRCnsGXs8K985SvGGv7uu+8a9xO6odBHnCnraTVn4deRboQiLPXjAx7CmWnoW1tajKWcgnvCiBoZiYWa/Kqs1F8BEQ4BDpcVlwdfx0OAC8S4C/3Czi7BAAQ6BH0sS7ZLxpeViw/9nYJEQs8ebpTlK1fKZ//mbxDP/J9l7NixJlQiLe9alEC+EsDlLK/Dx/JD00qQ6S12ZTPdPZNMONPOc/79TWjRU/uvf6hM7ljcJlyMxN/bH11SDn/KmA9luoQXk2rc8NmGi82i2I3450/1wRezXP7j5TahhYg3AF+EWLdp7dP1xfNMl5gjVUINtstWURGeLbK563egRTjP5Cv3LouvG8ieT3juiOnIuSaQqQBX42Ku36nej3/S5Iq+xRGnZZu+2HfccYf8wz/8AxZSbo65nEBs0/WEYp0PLub0woebFvGWtlZpaWiQDrireNB+/MQJclU1rODv75ddJzfLFIQzdKG+x1NqBLmrpEWiHoQyRH8BZNxsQhzQSDRi+muFcn9nfy1Ef1jORcjDSXBveWLfXrn3/vvlnXfekb/77GeNa0o6azhxqT9V7y+aYmyR6CNuzzHRV/x3L620hwZsywQc30WWNyvEL4GrChdTJRYmtDiCMFwstCpvRIgyilaGnmPBr9tRiVH+/pTYgiwe76l9CL9TFOEs/Mn+Z4/yYMwIrNrSeYzHGaXh7072IZFITHz/CZEbbHkH1nGGCrNf0/KmwoYOS5U8w9lXT+dhxxmsLW+WtCgBJaAElIASyAaB1Ttb+ibEORkK7pNPPll+85vfyJ133y10VWmAtdsPMV1qBLXH+Gw3BhsliMQ+Qfhve7B/+LhxcgwiopyPr60/gmCekVa3rHl3q4z/+Ci0gwgv8eNBMY7whe5muKgEIMTd0lbSDncWxBeHG4oHFrgSWNpLIMRH4PlELNYch75/e+CQLFm6VKqrq+WUU04xrinZAKd9FjeBRAGezbOl5fsgBDAtywyzNQ1pxx98OyauneP2J6EF++mpPaMBnI+FkIu3h4zAPxlpsh9dHTBinIL//57f/dslCnRb9jmSZdB38mBz1zFbh9tMEnmwXqrEHDw22GVklc8s4LNRMBp2rMpaFIzBPrehOh6j3DCSCd9LRr/he9vfRZr3/OMZnZFS9BoZqldW9s77lGlVch8ePVnG1biYvfcgGz3bbzB67ZrinAz9xRcsWCDXnHGqRJe8Ju/UiezCQsrW9nZjouOiTQ/q+CorZTQeYyoqZQYE+PGIC34cLOV+COnqsmo5sumgrJ+zT04+bhbcTxBxpRSho2hJh9j2lLRKKyzih93wFUf9DopxLM6cBzHfgWCJdRD/DYF2me73yWfHjJTZ//R/5dRPXSEjR450TlWfK4EeCQymAHdOxizanOuV1UhVvXRHzEXFeby/CS0yac8McfwG6RuTSoxLyr+9iHUfvElAGLQDePzkVfxOO0ppV/4QszDPcSjl00z6YuNUiTlSdpzlAwxlR6GmYjxz0Ez0wsQymZTe1M2kv0zqDLQY12sEeQ+QrbUBUVmCGbztvambyfs5VOpkKsiHCo9iOc+u7677eEZrXl4k7/3utzIbuW4/NX2GfGrcGDlzxAg5HsJ7PhZNLhgxXE6trpKP4vjFiNN6frhdji8tkWFe+H7Dn5w+47NKKmTb4nVysLHVuKe4sYiztGq4+IeNEn/1cKmqGSmlEPGxSCsRiPGQNLU0SjkWdY6sHiYMKdwEizvFuLz9lpRBsNNnXYsSyIQAw+FdeepIeeKmufLtSydlPYZ44py21kVkEqzOTFf9ytYuNw9br78JLXpq74WoHlfllt/DAn7ba+3yh/c6xKaA7m3CCzvnZNuB6CsxoUaycbKxzwothrhjvGlaPelrrCU5gWsWZB5bvTd1k4/Wt71WjHt85Z2Wca4J6Gsp1GuErm4jIKL7W7jQetrwzCRFb+r2d16Zth8oDpmO1596RpAjZvi9182Qk6dW9KcrbZsHBPqlVtuQfOethx6Qtp07pXz8ZIkgvvfYjjaZUDNcDjc1SQU+qFrb2qWirExmQTAPg/dpFQR5KazkDGvIDPatgTZYvbFwE/6vyxevlIs+9WEjoj2uEvF5IcirR0lkeFhKt7WYkIhutAuhH/pust2uI4dhQetAlAevtOBYYOkbsnflO1I+eoyK8Ty4wAphCh+aM0z4yGV5YXMQbilYD3G0QdyEHUuXJKWnhBaZJMTYfCgs37+o3CTKCcNfnGG+VuwOyXv7wr1KeNETw94kz0jWV7KEGsnqZWOfFVpqGc8G3dz0acX4QLmpFOI1svCYgYnN/6OEb83SvaO9qZuun4E8NlAcBnJOPfWVaCHvqb4ez08CvUrow0WXtvBr7PdXLJPff/FzMszjk7IxY6Vx3x5pbzgiZbBih4eNkPq9u6UaCywPw5WkCn7bx40eK2XIkhmFK4lJ+gNBzn4Ye7wMscS3hNpk1KfOkXPOWACRjdt0+IuHoy7Zd7hF1r25Xvxvvi3RfbskiHn4kezHhcd7Bw9KJcaohAW8BVbxGljah1/2KTn7n78t5XBf0aIEBorAQCb06cuc+pvQIlV7WsM+t9CHqCld7idMKnTLhWUmGgqjGrH0JuFFrEXqn/3tK1lCjdSjpT7SU8KMZC01kkoyKt33/cfHy+Rf/tIV0rb70e6velO3e8uBezXQkVQK6RoZ6CRZA/eupO4pG3kO8pFDX/4+paamR/KNQK99xBNFeDus4Rtfe1VCsHxHx1ZLqA1f6XW0ix+LOD0tTXLM5KkSbB0hpY11MhOuJnuam5ARs12OnTpNxiMlfaT+sFnASRHOkA9h9DMBwnrTmx9IzbxzZEKFR8KtcDYrHybhMcdI6bA6CcF6zhCJSMyM7HolsrsZ2aTCIamANTxIazgEOkV67bvvSBsitKgQz7fLTufTHwL9TWiRqj0FemtH100252jFNwW5fd6bhBc9nWd/+0qWUKOnMQfqeCFaPRPPvbfx34cjEs5Xz/YjYk8sxvzTiJTDiD8s9Pf9+rl+LKCPhaL93aru7h09xY5PnFsuXg9Vy3iq2Py8Pl56PyhXnYCgCfjTwPCjPeUiuPYUnzyLJGV0a2N7utldifb+Eqzxwr5HcF1wy+Ksy9c91U+X54DtbZkz2i0fnuGFq41bGAr2NysCshrf6rGkuw5TcbD96lYJZJNAj64pTgHunMih7Vtly+uviBuLKiNYVNne1gzf7aC48VsbhoW68cA+GT3xGNkOwe1zRWRKmV/qO0KyfvMmOTRxshyLh/fQQQk1N5pwaSEJiwe+3aM++EC2rkIUlWuvEy+T/rB/CPtwKJa504W+Gem4A3WPwBWmFCLeg0czYpdThBtBvme3NNbukxFTphqLu3Pe+lwJKIHuBBhqkGEGGeN7Zz3cwOAzP32kW16EuwzFu5ajCRS6GO9t/PevIUHTQ+8EZNthhJDFjRtFOaPlrEVSqhvw/FfLAiaZE4+xLm/gbOkpdrytl+vtUBTjqWLzM1LSxXO88lMIcHsj3lMuAqaPh+epKenyAbCCsy5f91Q/XZ4Dtrflswir+u/IadBBGx6SkvHaW1PbZs4h3XWYioPtV7dKIJsE4r82yYdIJsLpSsL9ezdvlN1IJR+GCA/jj247rNVBWKeN/zbq1NcdlAp8oEeQeOdIKCztsFhXYVXY9DKfNO7ZIcs2rZfGMeOkBO4qEQhrLsQMwLWkFP20PfuUbF+zCnHIkSQoHMR4sILjeIT9Q4Az0nEjXFxCeO3DWJTmHfhrEcG8uEWwcmmAmwyzd/anNDc3d2vO827B4tJiKA34xoDFbhPPtRjOUc8hcwJMZU//7ZdhBXtqfYfcArcChjLUkpqAFeOFuoAzMf77DmQ/TRb/ndZIxrCnCGcJYkNL4yeO9WKRr0v47Qbb2mMPw/JpvunEjlSx4y9GvPx8LFaMD/UFnPhYlbd34zPX8UUZcxHsiCf5onXZ5jJI9j6y/bKdVAOxshn5DmaPSi03eqqfKs9B4tg+aI4J1bFxGBqWicZ4DoV2HSael74ubgIpfzOSiXCLog1uJns3rDe+3mH8BoUQ27ujA9YzCOYQxCo/vjvgF9566IDU1NRIHYR4AHXa8RvBX8wJsI5Xoo8V766QPf5yKZ00hYHJkZETdnEI9vJD+2Xb43+UJli8SyDGubAzhFjkYQhrim320dCOrz/xnH/ww9jSGs5fOP7qc1/j3j2IatB3Ic4x//u//9uestm2w7Xmd7/7Xee+devWdT7nk8TX3Q7m0Yvdu3fLhg0bZPHixcJzYrkfyZCyXdLxSXcs2/PS/mMEaP3e1xQ1Xx/zd0xLzwQKWYxnGv+doS33NcaEtiXCb1CqkTV1IkTPXsS/d5b9uIb4d5rFGTuesej5uHp+qUkU5WyTT89VjMfejQ0Hut+IMxfBN8/zyz99yG8Ses2fwHweUNwpSm/zAaSrb/MccLjJyLnAPAfbDsdcTpzD/+TVNrkArin//rEy+e6Hy2Qu5sxSiNeh87z0eXETSCrEU4lwilMeaz58WPZv2xrz7YbopSWcwjsIJcw71yAFOfbXw/Wk0lcqbS533HWEYhy+3KhTBX/w0ai3ceVy2Q4Ltm/KdJPOnkIcEcQluvxN2bzkdXEjpngElvKW+oZOIR6GqG+BKIdt3rw7dEehlZz/OAd+BjTV7pcIwhxms1DIOkvia+exfHq+d+9ek4Bpx44d8txzzw3a1NLxSXds0CaoAymBPhAoVDGeqdsR/XqHJ4S342LZFkRvZHSdUfDFdZZRcFGwFnFn7HjGoreP3yzv7kfubJ8Pz1WMx95f+17YXAQMb3rH6+1yL1yR9ibcnNm6dtvbfADp6vNmcMpwj3wDaxFOn1wiNs+BHYtbrnVpRBzzB98OyP97oQ1uNW3Gx53rGwr1OnSenz4vXgI9+ojz1Cm+w/TBhvhlfO7GQ4ekHinlocTh2Y2vKnkMSXpi1moIYehifENk0tr74WrihrW7Hol4SnE7S9cWiuYQ2vrwmzPe7ZWda1dLx5zjZObk6RLe/r7JoOmHX/jeJ5+QQ6edCT/0Enib4OtOCH4XRHY0CuEfhS8r+mLa+5gMj88TryKIi9hwYD/6yV6c38cff1xWr14t9913nxx//PGyf//+bq/PPvtsWbRokSxFpk9yu+iii4T7HnvsMWlsbITbjVeuvfZasBB55ZVXZPPmzdKKBbDMVnreeeeZ/Y8++qjQZaStrU0qEZf9uuuuM/ufffZZWbFihQwfPtzUnT9/ftKxWPlb3/qW3HLLLVJR0RVr9LTTThM+0pVnnnlGLrzwQilD6EmORRcWvmb53//9X7nyyit7Ne9EXmRhS7Jjzz//vCxbtsxcd5dccomceeaZtrpuEwjQL3M6MnJyId02xCTnh5GWwSVgxXgxhjak4JqO0JrVPnzTGL+2rjqxFK5LQdkNa/iskd2PXXl8aadF3Bk7nu4tLJ+a5zUCfskHMUNJGLtjnwqD+571NJoV48Ue2pCx+eePT2qT60SUKhfBzvrsfcbawW2eg7uWtkq6RdqV+Pt3I9Yn0B2FhXX3I8tvJa7bXXCd4vVLUZ7qOsyEg52TbpXAQBJIK8QpwGkFpwjvgGtICJZpisojdYekBWKclmcunKTfdhBWakY0YWxwOIcYceyGSG5raoTg9kgzv8rEcSygNtYS1qEFuwTW8jE+r+zfskFcM+bIVCziDO3aJlGME924Xt5/5SWZ+eGPGB9xWt1L0CejozDWsQsKhH/KY1+DciaxCA+0yDdwISj6yFa54oorjPj+0pe+1DkExbh9zefbtm0zIpgcf/nLX8pZZ50lTz/9tNx9990yDMmOWMjW2e62227rFOIUqA888IAR4S+88IJs375dfD6f1NXVya233mra33nnnTJu3LikY/Gm58YbbzRi2lTuxY8JEybIxo0bTebU9957TwK4EaIQ34mY8VVVSGrSy3kn42Wnk3istrZW+LDneNddd8kJJ5xgONg2uo0RoAD/yll+WbkH3xoh8sllx5UacfQAfHj7U+gD6otHO+hPP0OpbbGKcfyplXuWtssPLy6HL3jYuAas3BOW1+NrCO55yKMxSAAAQABJREFUs11ugrtCM0Q6F909u7HDRK2w731PseMpyBkq87fvxhaD2nb5sB0KYjyT2PyZ5CLI1vvFTJ3p8hzYcTnHd/F38N4rKswi4pnwSediYopwlp6uw0w42LF0qwQGkkBKIU7xaIU3t1aIM/5305Ej0gKrLu0bFL90FaF/eIR/sWGyhnyHOMbXk3jW3NJsxHY7jtMtxQ+rOO+9PXiNbPamD0Y9GQmr+f5tW8Q9fZaMGzlWArV7kOu6WWqff1aGzZ4jLiwK5U0AujX9EAJHoitK7NcMQ2NsCnRa20MN9bEbA1bMQVm5cqURjkuWLDGjUxRT2E6ZMqVThPOAB+d96aWXGos2BTbdRWyZPXt2p/icOXOmbNq0ycRfp6C3hUKb1mNazBPHmjt3rkycONFW7dX2uOOOkyeeeMIIYFrvy8vLpb6+XtZige6CBYjz3st5T5s2LePx16xZI+ecc05n/YULF8qWLVvMuJ079Ykh8OUz/fLDl9vMgjnueHJd0EStmImoJ+/DOt7XUojJLfp6rgPZrlDE+L/iq3tn4cI7PpzFGQecizGvf7JFxsANhf7hzsRTXMRJK2QNfMZpMefHwEvvx6zd7I9WcfaVKnY8k1m98j5dG52j58/zYhfj/Bz/4SttCDMYsyKTfOL1wX2PYrEm3T9oeaboZbn5uVbzGc7nDHFoS7L2zuvJWZdt0tVnngNatb/xp1bbPYx5sTwHa+MRUeyBP20IynObguY6rYPbFKOn2NLTdZiMg22rWyWQTQLUxEcVWjtpAeVCPueD++gmwcWaoUCHEcWxxpDEuIrDRhhHjDimMKc9ug2W9Cgs2XQhoRDnwkqzoBOvKZoZ6pAW7CiEKhc77/lgq+yH2C+proGQhiX+/U2yZdHzWBCKxaCYF4V3By3vKPwZ64uru3kzwL55ExCVMiTz8ZSkvM8w7dP94A1HYuEix8mTJyfuTvqawpjuINVIZMQHhSWtzInCmC4f99xzj0yfPt24r0yaNMm4ArFT1rcl5tKD88VNEd2DnCXVWM46vX1OlxS+97yhoLsMXUnoZrNv3z4ZP368cVXpzbx7Mz5vuCj0beH58ry1dCdgQ4UlxuR+BlFPTp7Y/Rrp3lJfZZOAFeOFGk0lHRtGVXGKcGddijOK8FSF1ykjWSQr+SrC7VytGC/maCrp3D4sB64rsCKc+9K83bZJv7cU/+nyHCQOALsgFhd3F+HOOumuQ9bLhIOzP32uBPpL4Gi1iR4pxCnC6LNsH/Y1w/cFkBnT/ArirtQ4bdtfR/xW8g8xF09SLPMRQF9hCHHG/24xQhqCGfspmjvwYN1Y/TDs2C6pgq/5rg+2yUG4s3grkcwHon//M09L7bo1EPZRI+bbIdBpB+fCziDdYuJ9UOTT9cU7d55c+M2bpXLkqH7xsWLUdvLWW2/J6aefbl8eFaPcimVWoBW3CUmK6FLBx549e4xbibMO69HCTJcPCnEK9lWrVnG3KYl1+S3FrFmzhK4itjz88MNGKCcby9bp65bj0zpN6zhvQHbt2tXZVW/nzYaJ59PZWcIxfhNA/3tbOIfeWNRtu2Lf8gOHv2+0ZDkLLZSMi8vypdN9UuVzHhX56CyvnDTeI0x+8eUzfCa6wJ2XlZt9rMnkFp+Ei8sn5npNlAtmnGOhu8pN8MH8NiJf/MtHyuRjsxGo11GYlIPRDOhmwKgFfM25MVIGIxgw2gLjVw+FUsxifCi8f8nOcSiI8WTnnet9zjwH1ywoleuQBfjfkbmVoVYzXXCc63PQ8ZVAOgIJH+GxqrRAliKqibWG00JJiyQfFIMdsIbDhm1cTLo6570xH1TnMYFAM3mErioRt1m8aQQz/FFo68QhBP+ncwnlt3Etp7Q2yXl8kaDsP3BQPMNrzEJPV8Nh6Wg4IgF8htPvnEK+BCIxiPpc6EMBTvcWfsRXn7xQPvxP35LpC08zbhzY1efCBZY///nPjQilWwYXR1rfbnZKgc2wf3QBocU48TWturfffruMHDlSxowZI36//6i5nHrqqcYiTv9vuqZcddVV8vrrr8u55557VF3uoBCnSH3wwQfNDdOMGTOM20iqsT7/+c+bc6Bfd28LxS/DCtpvB+ieYhd99nbeHDuRj3M+icdoff/FL35hXKIozEeN6t9NlXOsYnr+v2s65N8+Vi7r94fhGx6GL2Wk0yeS58msch+fXSp/RD1bLoQQ/+7zrfKvH4VgTpL8IlVyi3QJMdh3b5PE2PkU69aK8WJcwFms71lP52XFeLEv4OyJw2AfZ54DWsaZCCgAd5Mj+HaFakOLEigGAi4I66TXM63itIYfgT843Sf43LoHbF/6hiz/5Z3iCnWIv6rGZL9sqa+TINxQXFh8mVi4JwABHcRII7AE2oM69PEqgQRnmCsjxLFlsa/bjKmvXMbCPznQ2mTCH9J9xYe2dHHx4rn9VaQop5V8xsWXyvn/eINMOfGktNZXM1AvflCE0/0j0SWEXZAJRbC19ia+pisP29HPOl2hRduKZb4ltr9UbeizT4HsnFOmY6Xqsy/7ezvvRD7OMROP8dsXniO/mciHctJNT5tpjDru/HyYTucc+Lt0IizcjOk8b5wHGeVccteSdpNqmr9VP7qkXL7155h/JX3HPwpL9i/fDMhPsJ8L7T6IJ+lgVkTrIkAruBehjxZtifkSMCHGdQv98n34o9tC4f13yGT3g/i+f4MV/AGEpbPJXeZP8MhHZsay89k2/wFLltNX1O7P1fbQ+lfN0Kt/flnWpnC4OSBWjNO1YdiU+YgEha8XtBQsgQg++yjGw4FWoQvS/TecJbzx6mvRa6Sv5Iq73WD8fSpugvl9dqfeEvOASGoR59QpLq34pNijMKfQ4zZKAVgKYYk/Rlw86aISiAtpp1XcIqDSpyCg7zYzX5Yi5T1FtWmL/RTqMI4bcc46FOOUra1tLVIXQfIfLNR0Q3xTnEfQltZ4T9yWTkt4GEmDzvjsdbLwqk/L2MlT0HJgC5MSpSpOIcw6ia8zFZFWhLOPnkQ46/Abi8SS6ViJ7frzurfzTuTjHDvxmLW+O+vo86MJ8J511d6weTy7MSgnQIxfcUKp/OqtgLEardwbEopi1mFGw6fhQ87C5BeXwgWFkVfoF/nMhg55Dxb0ZMWZEMN5/Egb/GMcJdMkMY4mRf9ULePF9xarZbz43lM9IyWQKwJHm68dM6EgpLijWwV9hMeOHWv8nH2jRkv1rGMhyiGJjThPXEhH6c1HrPAZLeXsjwl/WNtk4YS4DsOSbRZ2Gos5kwFRrGM/tkhwb7JrtiB+eEzoI8U8F+2hLsU6A7RNuPBjcuXP7pELvviPWRHhsTPQn0og/wjQAv43Jx19Q7Ye0S9oIbflOYjzi2AFL8Uupn9mmmp+zZsq+YVt59xmmhBDfTad1LqeWzFejAs4u85yaD2zYryYF3AOrXdUz1YJ5IZAWiFup0RLJf2jp8FnmD7Ks0+aL/P/9u9lwiWXSRuimYQb6+GmgqCBEMfdixXktGDT8s0llhDiFOMwpDEdfQhV+JrRUxiP3Ah0inG8Zl2K7ib0zYWZnCyTArHNyNPPlk/97G65/Hs/krkfOlfK++AD3X2u+koJFBaBPUi0wkWX46q6/95dCHeQzQe7LNUMN8e1FJ+chyQs22KuJgxB9u0Lulx+nMkvSIHJLUY5sik6E7NYSkzMcuqklF+q2Wq6jRNQMV58l4KK8eJ7T/WMlMBgE8j4U5Qim4sNmVCGCxYZwm7anGNlFSKUbHvtZTmC7JheRFqhJGBME37wJxZGNIlpdQpyuKrgB+sbzxZu8QpO6/gZa8z9dmEn+wwhXtv4BafI/MuukPkfvwRRUUb26HudOAd9rQSKicB/whf8BiT0YVg4uolMQkKVfU1RuKV0xfTl+dJl5QcXlctnHm4yp99T8otkyS16SohRTFyzdS5WjFufcfoZq894tmgPTr9WjOsCzsHhraMogWIjkHKxZk8nygWF9BfnQs5D+2tlK0LqbVvxpux9921p2bFTIu2t+PobkhqampbtKBzCEU085g8el9oU4bYYQY76tHobQY4dDHHog3/2aLjBzDz9TJl99odkIoR/OcL8eZP4SNu+dFt4BBijng+78JURWvKt5OtiTXJimMDhsGAz1BfDGiaW8bCaX73AJ3c4km6wDmORM0lLYvIL296Z5MPuS5WYxR4vpG2uFkPp4rxCukoym6su4MyMk9bKnECu/j5lPkOt2R8CdrFmn4W4c3CKckbxaEWUi7qDB2X/ju2yF1kkDyIZz6Ft70v7oUMSaG6UjhZk4UJMcQY/Zhv+c2Hhp8dTIh5Y2n2ITOIfNlyGI6nNmBmzZNLxx8uk446XUROPEZ+/DJEGSjpD6TnHz9Zzhu6bN29etrof8v06+S5fvlxefPFFYThGXhtXX3113vHJZyHeEyxazZ/f1NGvbJs9jVGIx3P5QVfXFJAv3r1UttbGvqUoRH4659QEBjqaSuqR9EixE8hmVKdiZ5fP52eFeMauKelOhm4rdFnhY/iIETIDcZ/DH77QWDgbYTFvaWyU+gMHpPlInbQ3NyMrJ7J2tjQbPxVat0eOGSsVcHepHjHKuJtUwt+bWTHZr41hnW78bB1bvHixCvFswUW/Tr6MFc5QmRTi/JZFy8AQYBjCs6d6ZV1tSEX4wCAdsF5GItMSw95ZN5UB61g7ygsCvMHie9uf0IZ0Zfr19WfJ9fctkw279e9iXryxgzyJBdNGDPKIOtxgExgQi/hgT3owxnv88cflhRdekAULFsjxsMwzYc/zzz8vy5YtMy45l1xyiZx55plmKo888ohJ/W5DPl533XXGxSJxns24CXn55ZflsstiMYuZIZM3Guw/kz5++9vfyuHDh834M2fONDc+mzdvNmN95jOfkWeeeUauvfbazmEfeugh+exnP9vtZuaVV14RtmFceKauP++880z9Z599VlasWGEW5XLf/PnzJdk+Vk7GId25Pfroo8LjDH/JkJjkk8iXCYIYkpHuKbyhy8dSyBbxfOSZD3PKpUU8H85f56AElIASUAK5ITCgFvHcnEJ2R73iiitk//798qUvfckMVFtbK3zceuut5vVdd91lMkVSWD799NNy3333mUWsGzZsMK8vv/zyoyZIn3omwLGFotNa/DPp4y9/+Yv8+te/NiElf/rTn5rxvvrVr5p5vfHGGzJu3Djh+Mz0yayoFL62f47J8Z3ndNtttxkhvnfvXpPV057bnXfeKaNHjz5q30knnWTaJ+OQ7twouh944AEjwnlzwyyiiXwtk3wV4XZ+ulUCSkAJKAEloASUwEARyCh84UANVsj9rFmzRs4555zOU1i4cKFs2bLFvKb1mJFkWCiC9+3bZ8QxxTkfDz/8sDmW7keyPhLrMw28TdozceJEOffcc00VCvDdu3cbUb1kyRKz78033zRWfGcftNhfeumlsmjRIvn9738vO3bsMIfXrl0rZ511VmfVG2+80aS2T9xHV6F0HDo7SHhCtxPesLDQkr9p06aEGvpSCSgBJaAElIASUAJDj8CA+IgPBWzBYLCbuwljqzMlO4szyyUXGjI1O8Wxtaan4nMIi1iZLClVH4ntErNYjoA/vi02vGQEMSE51/Xr18v1119vD5stfa9/9atfyZVXXil0Bfnggw/MwkieR2JWy2T72Ek6Ds7BnOc2YcKEzkOcpxYloASUgBJQAkpACSgBRgrUkpKAUzTSqrt69erOurQMM8ERCy3KFKgsGxEtxoprs8Pxg0Kavtm2OPvLpA/nfCj4kxVasRl9pAZhHxMLx7jwwgtl+vTpUo1FsqtWrTJVmKSJ/uq20ILPRZOJ+yjyU3FId27OeXMMO/fE/XZ83SoBJaAElIASUAJKYCgQUIt4mneZriD333+/cTfhYs2lS5fKL37xCxOqkYJ01KhRpvXUqVPljjvuMEmO6urqUlrC6a89duxYefDBB5HMKGLq2+Ez7cPWT7Xlws+7775b/uVf/uWoKrSC33PPPcZHm/O86qqr5PXXXzcuLrwp4Lzo600RPmfOHOOG4tzH+dO1JBWHVOd21ETiOxL5pqqn+5WAElACSkAJKAElUIwENGpKD+8qXTRskhlWpdsJBan11ea+X/7yl/LlL3/ZRAaxvtDcn6pwkSZdQdivLb3tw7ZLtuVC0htuuCHZIbOPC0atmwut09YyzVjwPDenm0qyfewkGQfuT3Zu3J+qJPJNVS8f9mvUlHx4FwZ2Dho1ZWB5am9KQAkoASWQGQGNmpIZp26ilE0qKipStsxEhLNxusggmfaRbBK7du0y4RUZcjFdsSKcdawI53OnrztfsyTbx/2pOKQ7N7ZLLE7Rn3hMXysBJaAElIASUAJKoJgJ9OiawhB4DFdH1wmnaCtmKL09N7p49LcMRB+0bp9xxhkyCZlJtSgBJaAElIASUAJKQAnkN4G0QvzVV18VPhiqj4louMjvggsu6NMZOdOZ96mDPG7EmNv9LQPRx+TJk/s7DW2vBJSAElACSkAJKAElMEgEUgpxRvfgAj6b5IXzuffee43F1ekfnek8nenMM22j9ZSAElACSkAJKAEloASUQLESSCnEV65caUS388SvvvpqE1UjXTpzZlFkGnYuwvvYxz5mrOjcR1HP5DY9pYvvKY07Y2czIQ0jdzBk4EUXXdSZuOaxxx6TxsZG8Xq93VK9O89BnysBJaAElIASUAJKQAkogXwgkFKIM/kLQ9U5i80eyWPJUrUzfTrF8Re+8AUTK/qJJ54wQjwxnXm6dPE9pXE//fTTZdu2bXLLLbeYMRhthLGz6b/ONPEM3Wfn6Zy7PlcCA0XARtoYqP7ytR9XiV+iofZ8nZ7OSwkoASWgBJRAwRNImdCH0Sxo1e5NobWaIvm5556TnTt3CgV4spIuTXpPadxpqWdkEaZyp1WcApxJdFimTJmiIjwZcN03IATmT+vKZDogHeZxJx5fjXjLx4i7tDqPZzkwU1swhN7XgSGmvSgBJaAElMBAEUhpER85cqTs27dPjjvuuM6xNm/eLMOHDz8qpJ1NZ06XkG9/+9uyYcMGWb58ubzxxhtyzTXXdLa3T9KlSU8MrZeYxp0inLGqmRmS5ZxzzhGbQn3ixIl2CN0qgQEn8N9fO2fA+8zXDt/Z3iz/+OD7Ul45XH53/ZkyeaQvX6eq81ICSkAJKAElULAEUlrE58+fLytWrDAZIO3ZPf/880KBniqdOS3dW7ZsMeL9r//6r42vuG3rDH2YKk066zrr2VTotg9uGcGFbjG0nPOxZ8+ezrjczrbONvpcCSiB3hE4ZVqlXLpghHSEovKjZ3b1rrHWVgJKQAkoASWgBDIikNIizqyPF198sXzjG9+QefPmydatW+WTn/ykybzInpOlM6fAfuSRR+Sdd94xvuJz587tnERiOnO6lSRLF9/ZIMUTv99vMlLefvvt5qZgzJgxwn1alIASGFgCN358gize1CArtjXLn1cflktOGjquOQNLUntTAkpACSgBJZCcQEYp7hkFpaamplOE265SpTNnEiCK40QLdWI681Rp0m3/6bYcg37sdIfRogSUQHYIPLvqsNz6+E6pKffIH2+cK8PKU967Z2cC2qsSUAJKQAkogSIkYFPcp3RNcZ4z/bTd7qOrMp05LeeJhXHGE0U461A4O/czTXpfYpKzL7ZTEU4SWpRA9gj81fwRQjeV+taw3PnC3uwNpD0rASWgBJSAEhiCBI5W10MQgp6yElACqQl8+9JjxOtBeNB3D8uqHc2pK+oRJaAElIASUAJKoFcEVIj3CpdWVgJDj8DUUX753LljzYn/4OldEgpHhx4EPWMloASUgBJQAlkgoEI8C1C1SyVQbAQ+96ExJoTh9oMBeeiN/cV2eno+SkAJKAEloARyQkCFeE6w66BKoLAIlJa45Wa4qLD85rX9svtwoLBOQGerBJSAElACSiAPCagQz8M3RaekBPKRwMLpVfJX84eb2OI/1Nji+fgW6ZyUgBJQAkqgwAioEC+wN0ynqwRySeCmj0+UYWUeWb61WZ5/70gup6JjKwEloASUgBIoeAIqxAv+LdQTUAKDR6CmokSY6IflZ8/tkaa20OANriMpASWgBJSAEigyAirEi+wN1dNRAtkmcNnJI+XkqRVyuCUk//nivmwPp/0rASWgBJSAEihaAirEi/at1RNTAtkjcPOlk6QEscWfeLtOVu9syd5A2rMSUAJKQAkogSImoEK8iN9cPTUlkC0CU0f75dpzxpjuf6ixxbOFWftVAkpACSiBIiegQrzI32A9PSWQLQLXIcnPpBGlsvVAu/zPkgPZGkb7VQJKQAkoASVQtARUiBftW6snpgSyS8Dndcu34aLCcv+rtbLniMYWzy5x7V0JKAEloASKjYAK8WJ7R/V8lMAgEjhtRpVcfOJwCYSi8uNndg/iyDqUElACSkAJKIHCJ6BCvPDfQz0DJZBTAl+/eKJUI7b4m+83yQtrNLZ4Tt8MHVwJKAEloAQKioAK8YJ6u3SySiD/CAxnbPGPxWKL34HY4s3t4fybpM5ICSgBJaAElEAeElAhnodvik5JCRQagctOHiEnTa6QumbGFt9baNPX+SoBJaAElIASyAkBFeI5wa6DKoHiIuByueQ7l00SD/6iPL6iTtbs0tjixfUO69koASWgBJRANgioEM8GVe1TCQxBAtPH+OXvzxlrzvwHGlt8CF4BespKQAkoASXQWwIqxHtLTOsrASWQksDnzxsrE4eXyvv72+WRpRpbPCUoPaAElIASUAJKAARUiOtloASUwIARYGzxm+OxxX+F2OJ7Nbb4gLHVjpSAElACSqD4CKgQL773VM9ICeSUwOkzq+TjJ9RIIIjY4n/S2OI5fTN0cCWgBJSAEshrAirE8/rt0ckpgcIkwNjilX6PLN3SJIvW1hfmSeislYASUAJKQAlkmYAK8SwD1u6VwFAkMLLSK1/92Hhz6rf/ebfGFh+KF4GesxJQAkpACfRIQIV4j4i0ghJQAn0hcPkpI+XESeUmtvg9i/b1pQttowSUgBJQAkqgqAmoEC/qt1dPTgnkjgBji98cjy3+xxWHZN1ujS2eu3dDR1YCSkAJKIF8JKBCPB/fFZ2TEigSAjPHlslnzx4j0ajID57eLaEwnmhRAkpACSgBJaAEDAEV4nohKAElkFUCXzh/nEyoKZXNtW3y6LKDWR1LO1cCSkAJKAElUEgEVIgX0rulc1UCBUjAj9ji37r0GDPz+16uldr6jgI8C52yElACSkAJKIGBJ6BCfOCZao9KQAkkEDhrVrV89PgaaQ9GNLZ4Aht9qQSUgBJQAkOXgArxofve65krgUEl8E+ILV7hc8sbmxvl5fUaW3xQ4etgSkAJKAElkJcEVIjn5duik1ICxUdgVBVii390gjmx25/dIy2BcPGdpJ6RElACSkAJKIFeEFAh3gtYWlUJKIH+Ebji1JFy/DHlcrApKBpbvH8stbUSUAJKQAkUPgEV4oX/HuoZKIGCIcDY4t+Jxxb/w/JDsn5Pa8HMXSeqBJSAElACSmCgCagQH2ii2p8SUAJpCcwaVyZ/e1Y8tvhTuyQc0djiaYHpQSWgBJSAEihaAiVFe2Z6YkpACeQtgX9AbPFFa+tlE2KL/x6xxSnMnSUYioi3RO0ETiaF+PzaX7whq7YfLsSp65yzRGDBtBHyX187J0u9967btrY2qa2tlalTpwq/rRuKZd++fTJ+/PgBO/Vdu3bJqFGjpKysbMD6LPaO9JOu2N9hPT8lkIcE/KWILf6JWGzxexlbvCEWW/xIS0hu+eMOeeLtujyctU6ptwRUhPeWWPHXXzkAN2ZPP/20fP/73+8XrFdffVV+/OMfy7p16+SBBx6QV155pc/9sY/+lP62d47d276efPJJZ/M+P29ubpaf/exnsn79enniiSfkz3/+c5/7GmoN1SI+1N5xPV8lkCcEzp5dLR+ZVyMvrauX257dLefOGSZ3vrBXGtvCMg6ZOLUUD4FRx51fPCejZ9JnAofWv9rntrbhH//4R5k3b57s2bPH7ur1trW1VVavXi233nprZ9t7771XzjjjjD5ZchcvXmzm1NlZL5/0t71zuIHsy9lvT89ffvllufzyy823C6z7wx/+UC655JKemulxEFAhrpeBElACOSPwz5dMlGXvN8rijbGHnUgdoqpoUQJKQAkkErjyyiuNGwkt2n0tK1euNKLb2f7qq6+WcDgWUvX555+XZcuWmdcUk2eeeaap+uijjwotv3RpqayslOuuu04ef/xxI+rvu+8+Of744+Xss8+WRYsWydKlSyUYDMpFF11k9rGDTNs755WsDY8nm2Oyudi+nn32WVmxYoUMHz5czjvvPJk/f7491LlNNm9+U7B582bhzcvJJ59s2rLBY489Jo2NjeL1euXaa6+Vyy67rLOfw4cPS3295oroBNLDExXiPQDSw0pACWSHQABZNh9765DJtpk4wqFmFeKJTPS1ElACMiC+3A0NDTJz5sxuOIcNG2Ze02ecD2stv+uuu+SEE04wwptCl24sFOEvvPCCbN++Xa644grZv3+/fOlLXzLt+Xzbtm1yyy23SDQalV/+8pdy1llnmXln0r7bpPAiWRv6XyebY+JcbF979+6Vurq6znO688475aSTTurGMtm8Tz/99G7ndtttt3UKcboH3X333WK52bFCoZBhdP3119tduu2BgArxHgDpYSWgBAaewFvvN8kPn9kle47EfMMTR6hrDiXu0tdKQAkogQEhUFJSIhSMycqaNWvknHO6FpMuXLhQtmzZIgsWLJDZs2cbEc52FPKbNm2SadOmdeuG1nYK9SVLlpj9XAS6ceNGmTt3bkbtu3WGF8nG9Hg8KeeY2J6v165da24G7LEbb7zRPu3cJps3z/vSSy81Fn4K+R07dnTWnzJlylEinAefeuop+dSnPiWTJ0/urKtP0hPQxZrp+ehRJaAEBphABOEKV+9qkQONqa3edWoRH2Dq2p0SUAKWwMiRI4XRQpyF7hcHDx407iQUurY4RfuECbHMwDyWKsoKRXhFRYVUV1ebB0W9bWe36drbce02WRu6vKSao23n3PKmg+eRriSbN/fdc889Mn36dONiM2nSJGPlZz8TJ05M2h0jpiR+25C0ou7sJKBCvBOFPlECSmAwCLjdLvmHC8bJ7284Vk6fUZV0SEZP4de6WpSAElACmRCw/t2Z1KV/NP2lI5FIZ3X6XFOg0wLNhZy20EJurd6J4tv+jXLupwW9qanJuLPQpYWLSn0+n+nOWY87krW349ptsja9mSP7mTVrlrz33nu2S3n44Ye7nTsPJJv31q1b5cILLzRCnDcWq1at6uwjcV72AP3PtfSOgArx3vHS2kpACQwQgUkjfXLXtTPkB5+eIqOqultrwvh8rG+NLZwaoOG0GyWgBIqUwJEjR+Saa67J+OxoTb744ovlG9/4htx///1y8803y2mnnSZut9tYc7kI8Re/+IXQJ3rEiBEmLna6zim42Q/dUfx+v7FW33777fLggw+aBZ/cl64426erZ4/R4pxqjsn6ohDv6Ogw8+E8aWXnubIEAgFZvnx50nnTt/21114zfupsd9VVV8nrr79up5F0S5Zc0KolcwIu3JGp2SlzXlpTCSiBLBBoCYTl3pf2mcWbNtHm766fIzPHalKILOAetC5PuulpM5aGLxw05Hk9kA1fuPrnXRE2cj1hRvioqanpFKZ2Pi0tLWZfpolp6P5BgW8txYysQncQRhXJpCS2z6RNqjmm6otinAI80U3F6bqSbN608FdVxb69pGS055jJHLVOagKn3hL7hkEt4qkZ6REloAQGiUCFzyPfuOQYeegfZ8vxx5SbUeuaki+mGqQp6TBKQAkMAQK0eFvrsPN06eedqQhnO4pbp0Bl20xFeLL2zrmkep5qjolzse1LS0uPEuF2bFsn2bytCGcd5znaNrrtH4Hu3wf3ry9trQSUQBYJDKV04W5vpXzp3gMSDbVnkWj+dJ1Pab/zgcqocpccaj36y9oK5Hmi21J7H+/R5o7xyIYD+eXyxMTqpxwDSyq2K3YPztzItyEQleDgDJcPl5TOQQnkLQG1iOftW6MTUwLdCQyldOGRYPOQEeF8lwci7Xf3q6WwX33z/OQuSR+d5ZUFE/puP7pmQf5lbL3lwjIp97qkCcJ4sMoXTvPJtOH68T9YvHUcJZCOQN//oqXrVY8pASWQNQLqb5s1tDnp2PrN5mRwHTSnBMZXu+RAS0QWb++jib+Ps//Rq0Pjm6Y+4tFmSmBQCegt8aDi1sGUgBJQAkpACcQI1Pjd0tA2eJbwgeI+zO+Sq+fn9tsFxtLuT+EiTcYNdz7YX2J88f6MkdiW0UQGI6III6Ewqkq6kq3zdJ7jQI/h7DvduRXaMbWIF9o7pvNVAkpACSgBoXvFK1uDcuUJpeIvcclh+JQ/sipgtsRDP+ivn+uXEsStZySe3+GYs9Df/Iun+dEWC+08Llm+KyQvbO4Sd+z/pfeDchX6Z2yx2xe3mzFf3x6Uzy30S3swKvXtUdPvgeaYmE7XZ2J/6/aH5UPTSmREuVuOqXHL5oNheXJdUIaXueSrZ/ulotQFlxWRp9cH5cUtPc/r3T0h+cTcUvHCvLajPiL/825AbjzHj9cuacNc/7CmQ3ZhP8u1p/jk2Q0dnX74PbEcV+WSK44vNS40frjRcF4Pvt2dp5NtNp8zlvU777xjwu1xnN6ELXTO66c//amccsopzl1y+eWXy5NPPilf/vKXu+0fqBfMsMmoI6eeeupAdZm0H8ZBf/HFF+W73/2urFu3TubNm3dUvWydp/McB3oMZ99HnVAB71AhXsBvnk5dCSgBJTBUCRwzzG2E521ws6AMnj0q9vqhd2IC8QaI2V8tCxhRSnH6NYhSaNLOcvMFZfKfS9plf1xE8/jB5ois3Btbwcj+L57jlZ9CgNuQmtx35Qk++dcXWqUD1cZDoH79Q2XynedazRzS9Zmsvw+ORODz7sENREfnvDgPnsO2wxEjqinK9zVFZG1t6nlNgpD3IWrH9xa1mX4+f6pPfnJJufzHy23CmwRasL+IGwveTLCMrnCJx/F9eE8seY53LG4zrIjwR+ibc89FeeONN+SGG24wQzOdOhPmpMrymG5+48aNkyuuuCJdlYI9xoQ/jK3Osnjx4qRCvGBPLsXE+c1Ga2urTJkyJUWN/N2tQjx/3xudmRJQAkpACaQg4IIiXLYTGVjjxzcfisjfnxJTl7Tg1sFCTsswSxCbh2ER/9rZsUWgE+Cb3QYjsxXhrPP42g75u5N9EOIxMcv+30YUEyvCWYf7HlsdMCKcr/c1RSFIwzIZCx+D4WjaPpP1xz6chfM+AlcVinAWzvs3KwLy5TN8nUI8VT9/guXclndgHa+BZd1a6htguefrVIV9pmLJNiFAsKzIeyMiz8we5RFa9Qe7XHvttZ1D0lWhp2Q5nZX78ITZNpctW2aS8vz/9s4EPKryeuNnZrInhEDCvi+CKwIiCiJqq+KGG1Zba6s+tdLWVu3fLra1VFvbWrXVum/VaqtSa9FitYooWhTFDQVklZ1AQghkX2f5n/cbvsnNMJN1Mpkk73meyczc+233d6l975nznXPWWWfJtGnT5KWXXjLVJpHmD9U5S0tLzXcM/69//UvmzJnTaKbFixfL6tWrBTm/R44caSp3okGksXEc7ZctWyYIvTnjjDPkhBNOwGFTVAfhNMj5ffrpp5tql/PnzzehLsj9jXL0V155pWmbkZEhs2bNMn3gHX/44YflyCOPDI2FRrbAD/oiDaKT65IlS2TDhg1G2E6ePFlstcxo80W7RrOYA3+iXZdtE+18U2O/8cYbguqfNTU15sHjuuuui8rPzpOI7xTiiXhXuCYSIAES6MEEfCr8UvX/nWrD9jAiLKLeUZZ8dUFYgwPMhmS7ZVdpUMxajIUqmv0H6tf1y9RwEPVu/+TkxhUP91c37rN2z8Hj7wgbN1+/D9b5quoCzY4ZaTy7Prz3z3LL7rLGa4CIzlaPttMijQOvuTWkd4R3vzUWjSXGWK/C++TRSWZTKbhNHuKR+fpA0hlmc1rDAwohjrL0bbGdO3fKU089FeoKL/Lxxx8f+l5QUCB43XzzzebYfffdZ8rWoyolQiQmTZpkysYjHhtl4Ldv3x4qemMHQYz0mjVr5PrrrzeHbrnlFiPEo40Nsb5582aZN2+eCWF58MEHBdUt9+zZY4T5VVddZY6/8MILRogvWLBAHn/8cSPCFy1aJFu2bJFRo0YJ8oXD4PEvLCyUuXPnmu/OP6gCisqfEOEIY7F9fT5foz6oLmqFeKT58CAU6Rqdc2ENka7L5iSPdh6coo2NB4kdO3bI1Vdfbaa6++67TZXQpuZxrimRPlOIJ9Ld4FpIgARIgASM9/WYIUmybFtjITx1aJIs3dxwDF7tSFZUGZApwxqL1zwNx3DD9atWpJlKkK3k9rDsISmexqNVNkSMhE701djz3WXWDy+SqzHe6/bUS5XGYTc3ZqTxQgPrB8S599HxnYYY9vB+4d/R3ts63e2cwnyOxhIn8YAA0XTDsCQTknLL69XG+3/QIHE6ALH45JNPyjXXXNPmGQcMGCDnnHNOqH9qamroMz6sWrVKZsyYETo2ZcoU2bhxoxx++OECIYxS8ijYA+9zSUmJ8XpDnDtt5cqVjcT9zJkzzeloY0OQwrMNkQwDc4h+lLSHwPzvf/9r5rchNXh4QHsY2qxfv94IcXOgmT/oCxEOGzNmTKgvqoPOnj3beJaLi4tl27ZtoZEizYc1Oh9g7DWGOumHFStWRLyuww47zDSLdh4PN9HGxi8GzkJMuH/RxrHzONeUSJ8pxBPpbnAtJEACJEAC8tr6Orl0UqoJl7ChIcM1DhqWH+YxjoRrp3qpD8n1SHaqS8oO5Oeeo5sNrUd8lwppnMPGSISCwM4/IlkFekDe3dog9CONjU2L9y8LeoMhkg8f4JG/r6g1hYbaOqadZ5de2+i+jdd90YQU9URHeeKwHTvwPVkfTgb2cst9y6raXEgp1st7+umnjbe3NZUvw9cAEY2qmtEMQg+i1BqqVSIsBHMiFAKiD2Eb2dnZJpQE3m+ErzgNY0DwW7Ol5aONDVENDzvGhOFBAB54rPXGG2+UtWvXygcffCCIk8cmVZyzZr3L9ntz79H6ItTmkUceMSE22FS6detW44XH+JH6RLtG5/zRrsu2iXYeYSeR+KEfHiKwNvxqAK54UAK7SPzsPIn6TiGeqHeG6yIBEiCBHkpgXZFf3lFBfOfZGbJFNwVC4KZppo7fLwnGbzeHBeL9gfdq5PoT06RChTjCKV5eV2cylNi+d7xdLTdoVhWI3zEq2rdoXPaLnzefX3uDru1P52SYB4JDtVLnHW9VGxGOcds6pl2TWfeyGvn9mRka366x5/rwsSLfJ0vjnGfcrgfvqL65Ya9PfntGhvHYI2wIDywf7vTKyt3xjxFfvny55OXlmdAM5zrhJXcKZ+e5tnyG9xfx1Qj1gMGLDU8xDKIU36+44grjlYWn2ops0+DAH4wBwW43ECKm/MQTTzThKZHGhiB9/vnnjbcdQyCO/JBDDjFzweMLbzxe9957r5khXHwjI0u4hbex58OP276IZ0eozejRo40AR5Yaa5H6RLtG2wfvEMmRrsu2iXa+qbHhqceDEOLlbSgOHpCamsfOl2jvFOKJdke4HhIgARIgAZNKEOkE+2cFq06Gh078atHBovym1xqOYcMjsojkaHw1vOIQuW980eDthlcc7XM1FATp/arCnM6RxsdtQUpDvJB5BIIU41prasxI463V2Gu8nIYNpte8WGmuG/Hh4XHykcYJP4bNlHg5zcnGZk+x58P747htj1CcLH0QuuE/Vba5yT6DiqCrC6obXX+oQQd+ePTRR+W4444TvMPgtYXQRcpBbCZsr8GjCq/z1KlTjaf7z3/+s9nYCFGIBwAYxDnSAtrQCISn2DAP5/zoA/GNWGx4mq2nG2Ek2JAZaWw8TNx5550m9r1///5mMyrGeeaZZ0zaRnigWxNqgRCaxx57zPSxGz+dawz/DJ4PPPCAiRlHaMpFF10kS5culUghJ+gb7Rpxzsky0nWhDQxx5pHONzX2oEGD5K677jJZc/AQ0adPHxNqFGmc4CyJ+9elF+D4z0jiLpQrI4GeTuDo6xcaBKys2b3+JdjKmp/dfW73ujC9mu72b/aW09MF8dFO8d3tblrYBeFBCOE4D2kqSKfdfFq63PpGdati07vKv3WEoFgPNzZQQnC3JwwGnloIRISYOC3a2MhkgvnD2+M4RGu4Z9o5ZqTPuB7M35p+5eXloc2nkInN9Y12jU6W0a7Lrjna+UhjI44eG3cnTJhgumNjJx4YvvKVr0i0cew8ifJ+7Lzgrw30iCfKHeE6SIAESIAEEpoAwlh6miEFIjzzyJG+XcNlUrT40ehct7yuv1a0d4NoorK0Ihzri+Tpbu26o6VYjDZ2NNEf7Xhz63FeT3Nt7XmbnQbfmxPhaBPtGp1zN7f+aOcjjY088PhVAaE7MPyKYWPYo41jGibgHwrxBLwpXBIJkAAJJCqBVTsqZfmmcslIUS+hvjJSPeZzhqYcyUjV7zh24HOiXkNb1/VwmFe4reN0tX7PasGhJN0ri3CcWo142a/ZXfhTele7i91rvcj0gl8qXnnlFRPLjhCc8ePHd8mLpBDvkreNiyYBEiCBziEwsHeKPPZWQWiDYrRVoGy8y5MqAV/jkIZo7Xk8sQnA+40CRjQSSBQCiNXHq6tbMB9UV78Krp8ESIAESCAuBPplJ8tpR/Zpdq6fzR5KEd4sJTborgRQbAaxyjQSaI4AhXhzhHieBEiABEigEYFLp/dr9D38C86fO7ltFQ/Dx4r3d1SxRBgGjQTaQgDVPpHNAxUhUfgHoRM0EmiKAP9z0xQdniMBEiABEmhEYP3uKpn/XlGjY84v0w/pJded3lBoxHmuK3z++sQUk7+7pWvN1GriSPEXK4v1eLFaF8dpGYE333xTLrjgApk1a5ZceumlJhd5y3qyVU8lwBjxnnrned0kQAIk0EICfs3Xt3RDmTyzrEg+2VoRtdfIvFT57VdG6iaq2AnTqJMlyIkpQzXNnMbDL94Yloi8jeuL9XhtXEa37/byyy+bHN/IP33SSSfJxIkTzTUvWbJENmzYIFVVVaZgDM7BFixYIPv27TPVNVFEBgVvFi9ebDJ3ILf3GWecIcjTfe65DWlI0b6kpMT05x8SiEaAQjwaGR4nARIggR5OoEpTZLy0Yp/Mf79Idu6rMzQyNTMKwk4uPi5PrvnrJtlVEjyene6Ruy4bLVlpDWXBezg+Xn6CEti1a5egWM3NN99sVnjPPffI0UcfLX6/XwoLC2Xu3Lnm+B133GFEOo5BbF911VUmQwdCTpB6cPPmzTJv3jxzDKXWp0+fHkr1h/zZjz/+uFxzzTUJSoHLShQCFOKJcie4DhIgARJIEAIFKq7/sbxIXvioWCprg7mzh/RJkUuOR+x3X8nUlIWwS47Pk7te3SUeDXL8wyUjZWjf1AS5gtgt46qpqbJkU73MOSpF0pJcpsz7M5/WmveLJ6TI8cOT9BcAkclDPLJ8u1fe3uwVhJd8e2qathdB9pgPdnhNpVCsqi3jje/nli+NSdYQGLcM0AI7f/mwVj7rhPLysaPauSOhjDtEs7Vrr73WfETRG5Sxh6cbQh1l1GF9+/Y1ohul7FFi/sILLzTl51GSHoVlYMi1vW7dulDVy3//+99y/vnny/Dhw815/iGBaAQoxKOR4XESIAES6GEEVm6vlGc1/vvNNSWh6pETR2TKpdP6yUmH9j4o5OS8Y3LlkSUF8oPTBsuU0b26Ja2hvd1yzmEpcsdbNSZ39ri84PenPq6V51bWSWGF/6DQFBS/uffdGj0XTPd33Yw0KdJ2K3b5pC3jXTY5VX6zuFrqNId3hhZnxPirOqG8fHe5wc5qj85rQhn6Rx55RObMmSMo9b5161bj7UaFyxtvvFHWrl1rCse88847MmLECFPC3ZatnzFjRqigDMbMy8sTlLKnkUBzBLhZszlCPE8CJEAC3ZiA1xeQRav2yxWPbJBvPbZRFn9eot49kTMn9JGnvjNOHv3WIXLK4TkHiXAggWf8bg1HmTM1r9sSAov31dNtM2hv2OsXiPFoNjjbJdUaLm5FONotWF0nZx6qbnK11o6HPqnqVR+cHZyzSsf+tYpyDduntZEAqjGuXLky1Pvpp582YSnwlJ966qkm/hsC+9NPgyXIV61aJRs3bjTecJRQR+z3lClTBGXgUUgGr/z8fElNbfhFyMaWhybhBxKIQoAe8ShgeJgESIAEujOB8mqvvPBxsTz3/l4pLAtuNOytcd4XHpsrX5naT5AvvCU2cURWS5p16TarC7wtXn+/TLfxev/k5LRGffZXB0N8cLA146H97W9Vy+zDU2R0X7fU6FJeWlsnKxmaAjRtMgjxzz77TJ544gnx+XxiqzTCC/7AAw/Ili1bTGjKRRddJEuXLpXjjjtOnnnmGfn4449NrPhhhx1mSrojlOXOO++U3Nxc6d+/f6My7z/72c/kF7/4hSB8hUYCTRGgEG+KDs+RAAmQQDcjsL241qQfxCbMmvqgOES2k69p+MlZE/tKWnJ0b283Q9Hiy4GHu6VWVOmXPfq6XUNZnJbi2MPamvGQ07ysNiBPfBSsUIq4859/KV12lNTI/mq6xZ2MW/MZIruurk5/6XFLUlJQCqWkpMj1119vPN29egVDrQKBgIn/vvLKK02BnrS0NPMdc33ta18zx9Af4StO+/3vf+/8ys8kEJUAhXhUNDxBAiRAAt2HwEeby+UZjf9eur4sdFHHjeklKL4zbWyvkLgIneSHFhFACMrEQQ0PL7vKApKd6pI+6a6QUD7/iGQpqgzIu1ub96yHj5eV4pJrNcYc4SgweMQRl56lc1CIt+gWRW0E4R3JrAjHOWzCtJaenm4/ht4jHQud5AcSaAEBCvEWQGITEiABEuiKBOq8fnlN47+f1fzfGwuDHtoUzfyB+O+vqQAf0/9gYdEVr7Mz17x+j08uOCJFfnxSmnxe6JNX1tXLHW9Xyw0z02RXmV/G5Hpkyz6/vPh5Yw95tDVHGu+TfK88dGGmhrT4ZKzGp+N9R0lDqEu0sXicBEgg8Qm49GcX/raV+PeJKyQBOfr6hYZC3uEnk0Y3IrB3zVvmaj67u6EQSHsvb3+lV57/YK957dPPsNysJI39zpM5x+ZJTmZ8fDA96d8sQkbgrXZarlbcrK4PCDZYttbCx0OKyP6aurBYPevIntIVrSP+rXdFDlwzCYDAsfOCm4Hj819jMicBEiABEuhwAl8UVpv0g6+u3C913qCPZdzAdBN+cvqROZKMgGNahxAIF+GYpLiq7X6u8PF86gDfrWEvNJEvvvjCbKhECMnUqVNNnHdruaBID+K6kSPc2u7duyUjI0N69+5tD3XLd6RpRFEjbDptjWFj6z/+8Q+T3tGZIaY1Y0Rqu3z5crMhFudqa2vlRz/6kYnb/93vfmc21R5//PGRukU8hvuKTbVnnXWWqYKKjDg7d+6UY445RlARFXsCEs0oxBPtjnA9JEACJNAKAvhRc9lGjf9etkc+2BwsP4+w1pnjs40AP2ZU98zv3QpEbNqNCLz22mvyhz/8IXRFI0eOlL/85S+NYrlDJ5v48O1vf1tQ3v7JJ58MtfrGN74h48ePl/vvv1/efPNNI/a/9a1vmfMo1vOvf/3LZEIJdeiiH+677z554403zDW25hIg3sHg0EMPlcmTJ7ema9S2eKhChpm77rrLVDf9v//7P5OvHUIfaSN//vOfy9133y0TJkyIOobzxH/+8x9ZsGCBfPnLX5bLLrvMZL/BeVzvokWL5E9/+pOzeUJ8phBPiNvARZAACZBA6wjU1Pnl5U/3GQ/4Ns2EAktPccvsSX3lq1oBc1huQ07j1o3M1iSQmAQqKiqMCO/Xr5/8/e9/F4iue++9Vz7//HM58sgjW7VoCHiUqXfa6NGjZcCAAYJ5nn32WeOVRT7woUOHyt/+9jdZv3698cajLzKlFBUVme9IUYhc4rDq6mrzUAAvLDzrWCuysyBHOQyVOZF5BYZ85CgutHnzZsnJyTEC15zQP/DO79ixwxwfN26cPWxEKjzagwcPjli1E2NCMCPHOeZCikWkasS1Tpw40Yzzwx/+UC6++OLQmJgH82ENzrlQ0KigoKDRXOEbXDds2CAlJSXmOkeNGhUaE3nX9+/ff9BxrAXXjLb4NQJFj/74xz8aEY61o2gS1onsNahKinNWhMPpsGLFCuM1x/22m2r9fr/J+Y5xwRr3A+1QHRVedXjUH330UXNPsVZcZyIZhXgi3Q2uhQS6AIFkTcOWnuySsprY/kx+WH+PrNWNb221PI3HLdU0b/VtH6KtU8e1356yOnlu+V5Tfr6sOnixA3onyyXH9ZMLpuRKVpojT15cV8bJSKBjCUAEnn322TJ37lwTVmIzmsR6q9tPfvIT2bRpk7mYa6+91oQ1vPfee+b7DTfcIPCcQ7QjhMLaJZdcYtYFAQkRag0CHu2d9vrrr5sCQFdccYXzsMD7/vWvf92ISniGrX31q1+Vq6++OiQm7XF4d624xjE8kPzgBz+wpw96h5cYuc3xAPPQQw8Zjzg8/7feemuorb2OhQsXGk+0PYHKouGhLPfcc4+8+OKLton89Kc/lVmzZslTTz0lf/3rX0PHwQlhIeCA0BFr+DUCDzRg+vDDD8t3vvMdcwqFlMAGIhznUO10yJAhcvnll8vevXtNG9x7eL7hOUeRpcrKSjusEfiTJk0SMEQOeAj1V1991Zy3qSpDjRPgA4V4AtwELoEEuhIBlPueOSpJfvhSVUyX/fVJKXLTa8EUbc0NnKlZx1I1+8c+RwzuVVNTTQVDVD7sjrYmv8qEn6DyJeKFYUcNy9Dy8/218mVv8bhdwYP8SwLdlACEOIQZxNi55wY3N6PUPEIlYmm33367/PrXvzbe4Hnz5hmPOITrW2+9ZQr4oHz9hRdeaEQkPOcQioidnjlzZiifOMQnCgQhbAYG0QkvOYTwkiVLjLDE9cBjjXO//e1vTdvZs2cbAYk+8+fPl8cee8y84xox13nnnWdCLpDDHEITohpx7TB4oGGIm8cDwaWXXmq+Yw0IKXnllVfk+9//vvGWwxuNmG+IcMTKYy6IYVzHiSeeaEQ4HjaQDx0MbrvtNiPezYD6B78GQISff/75Zj14YEHI0LRp04wIh2j/zW9+Y8JObNEjiPDvfve7ZnysDX0gtvErBDz4//znP+V73/ueoOASQofg4ca5srIyQRw57js83IMGDRLkdYcAh2CHCL/pppuM5x794VmHQD/nnHNMASbcK9umqQJLp922Skqqgs4Ne53xeKcQjwdlzkEC3YjAccOSpLDcryW3XZqeLbZe8ZZimjJUC2ho2e/FGxvSUdwWVkClpWMlcjuf1jF/a22pCT/5bHvQ44PsGafpxstLtQDPkcMa/7SeyNfCtZFALAhAPEII33LLLfKrX/1Ktm3bZrzXrRXjVrQ612TDFiDW7EZOhE7AIJoR3oHv27dvDx2DmMSaYChzj82Gw4YNM5sFcQxeXMQm492GRGBseHQRRgGvMq4Hnn6EbUDgwiBeUa0TMdIoPgQRD4Nn/oMPPjDrgVCFuLUhIfYXAnjFBw4cKMhxDmGM8zNmzDBCHHNaw0MAuCH+fc6cOUbg3nzzzSHv8i9/+UsTWvLggw+aEBznBk2E3HzpS18yYhwPKGCHmPvs7GyzNoSYYN3ghWtE9VIYxnr88cdNuMiPf/zj0MMDzuHhAJspEQqEsBSE7FiDtx+GUCRruH7wACesBQbxjQcOa2+//ba5Htwn28aeS4T3o9ubrwwAAB5eSURBVIdnCoV4ItwJroEEugiBkX3ckq+5kf+3uV5mjUsJVfvrIsvvMsusqPHJwk+KZb6Wn99dEvw/ToScIPTk4uPyZGBv/UmARgI9jABioy+44ALjcYXX9qWXXhJ4kFGSvrVCHEIP8c9Og+fVilrn8fDPNrwB4tnGmX/44YeCePJnnnkmFAOOfhCAMHjyIWTh0bWGcAuIchjCJyBkbVYPfIch7AYPG7YdQjzs/BDnuA6nQdTjoQGGz3Z9GA/fww0eZHBArPfzzz8vEOIQ4DAb8oMHDTxkIDbe2v/+9z8T2gLvO8JRIJDh1YbBi44xEVOPEBcwwDu8/ohfxwPHO++8IwiDwS8NLTH7kIG5YPBwI04e3J0PF4jRtwzRDptvcd0Q6M3Z6zcG4/ybaxfr84mXxyXWV8jxSIAEYkZg1rhk44X+bLdPJgzySHgwBMJDxuS65Scnp8m8U9Pl+9PTpK/GblvrneYyx36q5399erqcd3jjstC23dzjUqVX2F7D0w5JlqN1zosnpGi/FDnnsGQzz0mjg/6Ey49JFcSJw5C/+ebT0uW2MzPkF1oOfPqIBp/D+H5u+e7xqeb4PedmmDHtvJ39nr+/Vv7033w5+87P5a5XdxkRPqyvFos5e4i88qPD5drTB1OEd/ZN4vydRsAKTIQjIIb7iSeeMGvB5kcIRcRSW49yc4tE7DAE/HPPPWe8vRCPEHTwIMOw2W/lypWyZs0aE94A7yw2NOK7DQV5//33Zfr06SYmHB5biFl4da3nG+NgwyA8vNhwaOOUkSkkmsG7C0OcOtohBAVrsykV4cnHQ8hfNQZ78eLFZnNotLGaOw4vNkQyxjrzzDPNC32s6EfMN9Zw2mmnmV8gampqjAceXPBQBIPAxdowFjzUYIqHDqwNYTQQwjCIfITlgDF+HYC3Hu1barhmcEeoCjK2IIwFLzyAISYfD0BLly412VGc42I+bNa0DzYtnS+e7Rr+3ymes3IuEiCBLkcAIciH6obKh5cHM3SsVDE+aYhHPslviKkb2tutAjlF7tAwEQStjNMqgPj+1MfBPl+dmCIvra2TbfuD3h4I8jW6QXNjWFw3hD487s+vavgZ9dRDkuUXr1YJzqHEd3hoSr9Ml8ZJB7FeryXBH/uw1syDdf/yy+mm6mGpbjC9bHKq/EbLhaMoSoY+B/zslHRZVVAtGgXSaebypMqPn90ib68rVS9UcBnHjMoy4ScnahpC6w3qtAVyYhJIAAIQbwhzgHhEDDEMHuJTTjlFPvroI9mzZ4+JI0bYRHMGTzqyhTg9ssgkYjc/It75uuuuMzHViD9GphFsNkSMNTy5yE+NjZXYRAmD+DziiCPM/1YR8mEN8dWIN4f4tIa+yHONhweEcsDg3YXIhgcbMecY146N9H7YfIh1IKb75ZdfNn0Q5uGMecZ1I47aZmWpqqoKje88h8/w/uOBAR5wvGyaRvBEGAvmwXx2DX/+859NmAkmxmZMxJ3Dw4/rcxrGxaZLcLVj4l7hIQm8kb0ELxiuE5lPEF6DBxgYPN32M67NnoP4xsORM3Ul0jCC37Jly0wsvRlA/zj/e4kwHsTR49615N+FHSOe76ysGU/anIsE2kGgs6sUTtXYcAhxK6ohui+bnCK3LWko3X2LerlR4nv59gZPx62z0kObMPuku2R/dVBpYsPlqWOTpUwznSzZ5BVnO/i1bzsrQ376SnBD6Fj1sp+m3vgH3wsKenjBw4X4j7Sk+N8+qRUI74smpMq97zasy3jK9fherUp4u477wHs1svXAw0Cyivf64HNBO+5O27sWr18myZkDzQC4pllHBcvPoxBPVzf7b7arXwfXH1sC7a0iC8GK0AeIMIR3WIP3OTc3135t0TvivSFYIQidY6EzRGB9fb3xaOM7xodQRAw4xB5Ep00xaPvCA4tz1quMfnhAQF94u+HVhTcZMdxIk+gU0s7vGBthHBDLaGsN4h3ncAyhLOHmHAMebKzDPhjYc/AOI5YdDzYw/IqA9WFtzlAXiHqcc86FfrhmxH4jZAW/TCAUBDHg8J5joyUMvx7YmHtsrrQG3lgXxrQPIXZdaIPQEvzyEb5m2x+/OmA+bNJ1MsYvFvCEYx24B/basEaMb39RsOMk0js94ol0N7gWEkhgAqerEP5gh1eOGNDg7Rmb6zFeZWcJ79UFDSI8/HLQd5qGiSDrR5WW/h6Q5ZZl2w5uD6m+YpdXJg72yKe7fHLmoSmycE2Ddzx8XOf3/jomNpM6ba8ju8rtb1XLbA1tGd3XbUqSw0MP735nWcBXJ35vtVx96ki5SEvQ52apm76b2MRRfeXTLfu6ydXwMmJBYJL+m2ivQYBGEqGtFeFYh1N4hq8LYRBOw/jOOSAk4QV3mg2fcR6DALchJzhuRaJThOO48zvGtkIV56xB8FvRb485351jWM+4PW/PQcjaNeAcPMWRvMWIrQ6PK4cX3G5ghVh25h23IhxjQnw7BTiOwSLxtuvCeee68N15Dt+d8+G7NWR4seYcA2tMZBGONVOI2zvHdxIggagE4L0e2MslWSkuGd+vQYgj7/fJY5KNF9x2rm5IZGIPmXeEgZyibX/zRkOKwm9rTHk0+6961hHLvabQpxla3KFwlmjt7fF96nHPUc+709J17mR1lUP8wwP/xEdBz3qa/hfw5xpDvqOkJuSpd/aL12dvVZHM/dK0eE0Xt3mevG5G3ObiRCRAAiTQFQlws2ZXvGtcMwnEmcDJo5PVI11v8nQvWF0Xer9/WY2cOKplHtwUDbuo9R0IgNb1p6ien6xpCBFKAsMpp3xGPDeOnXdEisnSEmwV/FtYEQhtzHQex+f8Ur9uGPUIHh6sXTMtTTd/Bh8kbtSYcGs16oxHvHmWnqORAAmQAAmQQLwJ0CMeb+KcjwS6IAGI7V+9fnABHwjZokq/DFGPNdIaNmUlKqy3a1z2DRrLDZGNzCZ/+l+1fOvYNHl3a72+vCbTCuK8N+8LjvWyesV/d0aGfPXpYFosO/569cRfoAL9xyelmU2YiEu3hk2XD79fo7HgmRoH7jNVQFcVaPqtA+v7JN8rD12YKav12FjdTIr3HSVNr92OzXcSIAESIAESiCUBbtaMJU2ORQIdSMBufMs7/OQOnKXjh07S3+EQ4gJhDoMvOvgJ4SONN04O0nCYr01KVcHesPHSdDrwB6EleBiIZsikgg2adnzbDtlV+me5pFjPIXtKZ9reNW+Z6du7ga0zr4FzkwAJkAAJtI0APeJt48ZeJEACbSTgVeezFeEYwimSw7OXzDkqVRZ+Hn2TZlMiHGMXqdCOZNgsuruTqoJGWg+PkQAJkAAJ9EwCFOI9877zqkkgoQkgPeEJI5Plc83A8kUxw0YS+mZxcSRAAiRAAm0mQCHeZnTsSAIk0FEE3t7sFbxoJEACJEACJNCdCTBrSne+u7w2EiABEiABEiABEiCBhCVAj3jC3houjARIgARIgARIgARaT8Dv84q3vERq9+0Wb2mx+GqR9colSRlZkpzTX5L7DpSUrN6tH5g9Yk6AQjzmSDkgCZAACZAACZAACcSfQO2+Ailbs1zKNnwiVQXbpL6yXFKQqupAlYZAICDegF8yVIinDT9M+k4+RXqNalwdNP6r7tkzUoj37PvPqycBEiABEiABEujiBOory2TvuwulZMUS8VeXCwS3TyuiIW9ULVJVOQwpY2v2FaqnvEhKV70j2UdOl76TTpasUUeK282IZQequHykEI8LZk5CAiRAAiRAAiRAArEnUFOULzsW3CP1BVukTkW3D1XNmjCc9Wobr9+nfnKfVKgYL1v5rvQaf4wMOffbktKrTxO9eSrWBPjoE2uiHI8ESIAESIAESIAE4kDAV1UuOxfcL/W7t0i1VidrToSHLynoMfeJV2PKa7/4WHa98oR60hsqFYe35/fYE6AQjz1TjkgCJEACJEACJEACHU5gz3v/kbrdm6S6vn0lgiHIq+q8Ur7mPanY+GmHr5sTNBCgEG9gwU8kQAIkQAIkQAIk0CUI1Gk2lOIP35B6X/tEuL1YiHG3yyUlGqpCix8BCvH4seZMJEACJEACJEACJBATAmUbV4hUl5l4b92dKebVppEhwYPm9fmlbMta8VVX2EN872ACFOIdDJjDkwAJkAAJkAAJkECsCVRtWyvqwDYC3OVJEndKqvjr6ySgMd4B3YgZ8Gu2FCvQHe84bs5rXLjfi3hwDBI0v7ZD1pXafXvsIb53MAFmTelgwByeBEiABEiABEiABGJJAAV7qvfsEL9mP4Gozhw0XIaceLaUblmn+cO3S13ZfvHW1kjAq8LcZFGB19slLk1P6EpKlqS0dM2OkiPp/QZL9vBDZM+n70jJpjXmnMvv1fzj+2O5XI7VBAEK8Sbg8BQJkAAJkAAJkAAJJBoBf2211GrlTOQLxytz0AhJ7z9I0vIGiKY9EV9drVbTrDYecuP1Vh3uUvc5RLgnJUW952n6niri8RhxnltfI2VbN5i84y5t66utTbRL7rbroRDvtreWF0YCJEACJEACJNAdCZgQlPpa4xH3qKjuPepQCdRrmAnCUdQ8ySlBoY0vJn4FH9QQomLf0RZhKno+S4V8hgr5yoJ8EVTiVC87LT4EGCMeH86chQRIgARIgARIgARiRkAr1Ws8uFd6jzlMQ0wGhUS4mQCC+4DQhoc89LLHrCBHY/3sSk6VnLFH4YvpjhAWWnwIkHR8OHMWEiABEiABEiABEogNAbfHeLqTMrKk/9EntH9M9YBnjxwvSRm91BnuF7d61GnxIUAhHh/OnIUESIAESIAESIAEYkIA8d1JKemSO36CxoUPDHq82zOyespTsvtI9tCR6hN3iTs1oz2jsW8rCFCItwIWm5IACZAACZAACZBAZxLwVRSLVBZKcnq6ZI08TKNJgnHh7V6Txor3Qqy5etuTRDd6VjFzSruZtmAACvEWQGITEiABEiABEiABEuhsAgEV3f7yPRobXiP9jjpWUnLy1BseIyGuseSZ/YdJWt9+kuRxia+0UMPHYzR2Z4NL4PmZNSWBbw6XRgIkQAIkQAIkQAIhAgc2WQZqaoz3WkI5wkMt2v5Bx05Kz5RBx5+mY6ifFnPh1VDvp+1js2dUAvSIR0XDEyRAAiRAAiRAAiSQQARcWpAnJUNfyQeypASznMRqhcg1juJArtQUfek82BRK61ACFOIdipeDkwAJkAAJkAAJkEBsCEAouzNzVYSrozojvXGO8FhMoeO70jRjinra3Vk6D63DCVCIdzhiTkACJEACJEACJEACsSHgTssSd59hWngny0SONCrY054pVIQb03HdOcM1c0pWe0Zj3xYSYIx4C0GxGQmQAAmQAAmQAAkkAgF3Wrbg5fVrNU1vtQRq2l+S3pWq4S4uTYuYOyIRLrHHrIEe8R5zq3mhJEACJEACJEAC3YmAS8W4uGO0m1LjwV0ZOd0JT5e4FgrxLnGbuEgSIAESIAESIAESaEzAnZ6jqQwR153a+ERrvyUn6TgaF57Ru7U92b6dBCjE2wmQ3UmABEiABEiABEigMwi4kpLF03e4esXVm62ZTtpkKsKRo9DTe7C4ktop6Nu0gJ7diUK8Z99/Xj0JkAAJkAAJkEAXJmA2b+YM1YqYyeJKT2vdlSANoop4j/Z3Z/ZpXV+2jgkBCvGYYOQgJEACJEACJEACJNA5BNypvSSpr26yTEprsWfchLN41KPeRzOkZPXtnIVzVpROopEACZAACZAACZAACXRlAq6UdA1TUTHu0RAVeLptOsLwi8JxhKO40zRDyihxp+uGT1qnEWD6wk5Dz4lJoG0E9q55q20d2YsESIAESKBbE3C5selS6/GUFAUrcCYfiPk2peqRXcUlAW+dBKpLxdMvR1zJrQxl6db0Oufi6BHvHO6clQRaTWDiKP502GpoXaTDJN7bLnKnuEwSSHwCrtR0cXk84tu7S3wqyAO1mmfc75NAXbX57ivO14vQCp1awp7W+QRcAbXOXwZXQAIkQAIkQAIkQAIk0B4CWpleAmWF4i/bJf6KCglUlRkPuA1TcamH3J2RrekOM8SrseGpvXJjloa8PevuyX0ZmtKT7z6vnQRIgARIgARIoEsTCNTVaYhJMCbc1PbpPUCkvkYC9X6N/87UUBWvxqr4NXZcUxxqhpSAfkbhnvTs3IbrVp9swFuv47QxBWLDSPzUSgIMTWklMDYnARIgARIgARIggUQgsLOyVv5RUCYVGmriNE/ucE1J2D8oupFjXAW2y+U2ISqe7H6SlKebOh2G/n/PL5Wt5TWOo/wYDwIMTYkHZc5BAiRAAiRAAiRAAjEikK8C/LX8/fLOnhKp8rtl2pDect0Y9YSHmW9/vm7c3C3BIOSAFu3pLxDpiBF32t1fFMr7u0ol1eWXaXnZcuawvjIiixs5nYw66jOFeEeR5bgkQAIkQAIkQAIkEEMCe6rrZJEK8CUFKsDFI/56zYCiGzFhcyeMlC/363XQbL6SAhXju8TdK09F+DA931iEv1FULg+v3Gr6udxucWsceaq/Xk4ckCNnDu0rgzNZbfMgqDE8QCEeQ5gcigRIgARIgARIgARiTaCq3itLCsvklZ37ZZ83IH6kIPQFBTjmCuguzYz0FLn1mNEyTN/DbdGuPTJzQJ6keRpHJO9QYX/Tx5ulSt9dJsA82NMK8l6ugMwa0kdfOZKF3OO0mBOgEI85Ug5IAiRAAiRAAiRAArEhsKakSuZv2SsbK2rNxks/Nl9GML/PL2MG5sitRw2XZEcxn79t3ysvbyqU44flybVjB4QqOdZrvMpNq7bLJvWuu8MEuh3e5UkSd1KyjExPkktG5snE3Cx7iu8xIkAhHiOQHIYESIAESIAESIAEYkWg1uuT/+zcJwvVC16naQl9dbXNDo2MKGeNGyxXjugnmidFHtpcKEv0JQcSVU8b2U+uGztQPCrUn9hWJK9s2KWe8MZe8kiTIFwlWT3m5w7NkfOG5UpKFOEeqS+PNU2AvzM0zYdnSYAESIAESIAESCCuBFDi5bmtRfLfPVXi07AUGwfe7CI0M8qiLXtkbK90+aC4XN7XMRASbsNO3tPv9RrGgg2ZaKcnmh0SDfz1tVKngv2F/DKprPfJN8f0F3cLBHyLBu/hjegR7+H/AHj5JEACJEACJEACiUUAWVFu+mSrVGkcuDMWvCWrRIYUt8clCFVxOUJUbF+IfISi+H0BW+fHnmr2HXnI05I88uuJw2WEin1a+wm07FGo/fNwBBIgARIgARIgARIggRYQ+HBvudS4tPiOY0NmC7qZJtDe2LwZSYSjAY4Hz7d0xIZ28MzX6bo+Kq5oOMhP7SJAId4ufOxMAiRAAiRAAiRAArEjUK+e7E80rKTF4Sixm7pFI2FdK3R9XlTrpLWbAIV4uxFyABIgARIgARIgARKIDYECTSW4o7LeZEiJzYixHSWgWVvyq+tld1VdbAfuoaNRiPfQG8/LJgESIAESIAESSDwCG8uqpEZ3WCIDSiIa1lUTcMsX5TWJuLwutyYK8S53y7hgEiABEiABEiCB7kpgbakK3MbFLxPvUjXOfF1JZeKtqwuuiEK8C940LpkESIAESIAESKD7EUAFzU2lVRLQHOKJbAGvV74oq5aaBF9nIjO0a6MQtyT4TgIkQAIkQAIkQAKdSKBAY6/31mne8ECCC3FdX3GdTxDPTmsfAQrx9vFjbxIgARIgARIgARKICYFtldVSr0V2EjU+3F5kME7cJds13zmtfQQoxNvHj71JgARIgARIgARIICYEvihXD3MLq13GZMJ2DOL2eGRTOYV4OxCarhTi7SXI/iRAAiRAAiRAAiTQTgLIH76ptLL5Ij4RqmW2c+rI3ZuZx69pDDeVVYpPiwfR2k6AQrzt7NiTBEiABEiABEiABGJCoLi2XopqNT5cC+Y0aYEOTmuoAry+qlLWvzhfY9UhsiOncME691R7Zb/GtNPaToBCvO3s2JMESIAESIAESIAEYkIgX+Otq3wBFb+RhbbL7ZGKgnxZ98Kz4vYkx2TOyIO4xK9ZUYo+X2Heo+hwE8de5vXLriqGp0Tm2LKjFOIt48RWJEACJEACJEACJNBhBLZWanw4BLbxQh88jcvtlpr9xVK6bZOIfu5Ic2n8d31lhfjqILIje8SxTldSkmyvYGGf9tyLjr2T7VkZ+5IACZAACZAACZBADyGwubxaRXhkb7hBoCEjdZXxKaLjQnhKZbl4a6oFn6OainHzABG1AU80R4BCvDlCPE8CJEACJEACJEACHUigSgvj7NDUhQHdABnNXJpNpa68tPnNnNEGaM1xCPFqTaWoXvGmhDjixLeWVUkdC/u0hm6jthTijXDwCwmQAAmQAAmQAAnEl0ChFsYpqfOLv6mNmiqOa8tKxO9rZjNnDJYO8Y2HgrqK8ibTKUKI79NqoMW6yZTWNgIU4m3jxl4kQAIkQAIkQAIkEBMCOytrpA6x2FHiw+0kEOIQv015qW3b9r77NZ1ibVlp00Jc11utzwW7WWGzzbgpxNuMjh1JgARIgARIgARIoP0EtlbUah0fT7MD1ZWXqRCPT97uQMArtSX7dV1Nx4iLJ0nwIEFrG4GktnVjLxIgARIgARIgARIggfYS8Pv9go2a8HQ3ZaasfMm+Zr3mTY3RmnOBep/UlBS1qMv2qvoWtWOjgwlQiB/MhEdIgARIgARIgARIIC4E9mlBnO2V9eJOSg7ziqvn2+H89qSkSFJqmoaKuMSD9zZZcMCmImCwKRTx4e6UZLNhE+uK/pDgMmvGg0Sdxq6naNpDWusIuLRqkuM2t64zW5MACZAACZAACZAACbSdwH7d6Lh0T6mgxP1BphINoSEuVWrII169t1DqdQNlzqhD9Ji2V1GOwBH7st8h4PVUgx1oB2XvVqGNd/R0m0Z+fNL22sn00446dvGGNdJr0FBJ7d1Hz+OcvhwW0L6QkDiqvWVqXpakJVGIOxC16COFeIswsREJkAAJkAAJkAAJkAAJxJYAN2vGlidHIwESIAESIAESIAESIIEWEaAQbxEmNiIBEiABEiABEiABEiCB2BKgEI8tT45GAiRAAiRAAiRAAiRAAi0iQCHeIkxsRAIkQAIkQAIkQAIkQAKxJUAhHlueHI0ESIAESIAESIAESIAEWkSAQrxFmNiIBEiABEiABEiABEiABGJLgAV9YsuTo5EACZAACZAACZBATAjs27dPfFoox2lpaWnSq1cv56EmP5eUlEhOTk6TbXiy8whQiHcee85MAiRAAiRAAiRAAlEJLF++XKqrq2XVqlUydOhQ6dOnjwwbNkyOPfbYqH2cJ1BwZ+HChfLNb37TeZifE4gAC/ok0M3gUkiABEiABEiABEggnMC///1vmTRpkgwfPjz8FL93cQL0iHfxG8jlkwAJkAAJkAAJ9CwCzz33nJSVlUlycrJcfvnl5uKXLFkiGzZskKqqKpk8ebKcdNJJ5vhTTz1lPOLz58+XiooK42HPysqSK6+8MgRt8eLFsmzZMqmvr5czzjhDTjjhBIk0R6gDP8SMAIV4zFByIBIgARIgARIgARLoeAIIN7n//vuld+/eZjLEkRcWFsrcuXPN9zvuuCMkxBFnDluwYIE8/vjjAhG+aNEi2bJli4waNcr027x5s8ybN08QyvLggw/K9OnTTUiLcw4zCP/EnACFeMyRckASIAESIAESIAES6DgCI0aMCIlwzOLxeGT27NkCz3ZxcbFs27btoMnHjRtnRDhOjB07VtavX2+E+IoVK8zxd9991/RxuVyybt06CZ/joAF5ICYEmL4wJhg5CAmQAAmQAAmQAAnEh8CQIUMaTVRaWioPPPCAjB492oSWYEMnvNtOGzx4cOgrxLY1eMgzMzMlOzvbvGbMmCFoGz6Hbc/32BKgEI8tT45GAiRAAiRAAiRAAh1KwCmkMdHq1avl1FNPNUIcgvrTTz89aP7wPlaoT5kyRcrLy+Woo44yr/z8fElNTZXw9gcNyAMxIcDQlJhg5CAkQAIkQAIkQAIk0DkEkM4QHnHEfSM05aKLLpKlS5fKzJkzm10Q8pIjtOXOO++U3Nxc6d+/v+AYLT4EmL4wPpw5CwmQAAmQAAmQAAl0KAF4tm2xH3i8W+PVRr7ypKQkk4mlQxfJwRsRoBBvhINfSIAESIAESIAESIAESCA+BBgjHh/OnIUESIAESIAESIAESIAEGhGgEG+Eg19IgARIgARIgARIgARIID4EKMTjw5mzkAAJkAAJkAAJkAAJkEAjAhTijXDwCwmQAAmQAAmQAAmQAAnEhwCFeHw4cxYSIAESIAESIAESIAESaESAQrwRDn4hARIgARIgARIgARIggfgQoBCPD2fOQgIkQAIkQAIkQAIkQAKNCFCIN8LBLyRAAiRAAiRAAiRAAiQQHwL/D1g/vbaR/gwZAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data\n",
    "\n",
    "The dataset was created to support a chatbot for customer self-service. It was originally created from a set of suggested intent classes and examples from the product vendor. Testing indicated that the initial dataset was oriented to a North American audience and needed to be localized.\n",
    "\n",
    "Historical chat logs were analysed to identify frequently occurring intent classes (matched to the feasible scope), and draw examples for those classes from the chat logs.\n",
    "\n",
    "A team was established to monitor performance in operation. One of the tasks is to identify cases where a conversation is not resolved by the chatbot and determine cause. If the cause is misunderstood intent, then the misclassified utterance is added as a new example, and the model retrained. In this way, the dataset builds up over time.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths Train: 5696, Val: 633, Test: 703, Classes: 191\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df, classes = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data:\n",
    "    \n",
    "* Drop classes without an example utterance\n",
    "* Replace HTML entities and common tags in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after cleaning data: 5695\n"
     ]
    }
   ],
   "source": [
    "train_df = tokenize(clean_data(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.apply(lambda row: pd.Series([row['utterance'], classes[row['label']]], index=['utterance', 'class']), \n",
    "               axis=1).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove classes with too few examples\n",
    "\n",
    "Necessary for some models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after processing data: 5680\n"
     ]
    }
   ],
   "source": [
    "train_df = remove_classes_with_too_few_examples(train_df, min_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after cleaning data: 632\n"
     ]
    }
   ],
   "source": [
    "val_df = clean_data(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after processing data: 346\n"
     ]
    }
   ],
   "source": [
    "val_df = remove_classes_with_too_few_examples(val_df, min_examples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length after cleaning data: 703\n"
     ]
    }
   ],
   "source": [
    "test_df = clean_data(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths after removing labels with insufficient examples Train: 5680, Val: 346, Test: 703\n"
     ]
    }
   ],
   "source": [
    "print('Lengths after removing labels with insufficient examples Train: {}, Val: {}, Test: {}'\n",
    "      .format(len(train_df), len(val_df), len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_df = pd.concat([train_df[['label', 'utterance']], val_df])\n",
    "trainval_df = trainval_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number classes after removal: 182\n"
     ]
    }
   ],
   "source": [
    "print('Number classes after removal:', len(trainval_df.label.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens per utterance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min token length: 1, Max: 70, Mean: 12, Std: 8\n"
     ]
    }
   ],
   "source": [
    "# Min, Max, Mean, Std Dev. of tokens per utterance\n",
    "lengths = train_df['length']\n",
    "print('Min token length: {}, Max: {}, Mean: {}, Std: {}'\n",
    "      .format(int(lengths.min()), int(lengths.max()), int(lengths.mean()), int(lengths.std())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean character length: 56 Max length: 331\n"
     ]
    }
   ],
   "source": [
    "char_lengths = train_df.utterance.apply(len)\n",
    "print('Mean character length:', int(char_lengths.mean()), 'Max length:', char_lengths.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Length by Label Variance: 26, Std: 5\n"
     ]
    }
   ],
   "source": [
    "# Variance, Std. Dev. of lengths by label\n",
    "lengths_by_label = train_df.groupby(['label'])['length']\n",
    "print('Mean Length by Label Variance: {}, Std: {}'\n",
    "      .format(int(lengths_by_label.mean().var()), int(lengths_by_label.mean().std())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12a876438>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12d27c2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['length'].plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Balance\n",
    "\n",
    "Conventional algorithms are often biased towards the majority class, not taking the data distribution into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Utterances by Label Min: 5, Max: 197, Mean: 33, Std: 29\n"
     ]
    }
   ],
   "source": [
    "counts_by_label = trainval_df.groupby('label').utterance.count()\n",
    "print('Number Utterances by Label Min: {}, Max: {}, Mean: {}, Std: {}'\n",
    "      .format(int(counts_by_label.min()), int(counts_by_label.max()), \n",
    "              int(counts_by_label.mean()), int(counts_by_label.std())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13170f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = plt.axes()\n",
    "trainval_df.groupby('label').utterance.count().plot.bar(ylim=0)\n",
    "ax.xaxis.set_major_formatter(plt.NullFormatter())  # hide labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is quite imbalanced by class.\n",
    "\n",
    "Imbalanced data typically refers to a problem with classification problems where the classes are not represented equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "Options include:\n",
    "1. Weighted average F1-score (balances precision and recall)\n",
    "    * Precision - What proportion of positive identifications was actually correct? In other words, how accurate are my predictions? Low precision = too many False Positives.\n",
    "    * Recall - What proportion of actual positives was identified correctly? In other words, how well did I find all the examples? Low recall = too many False Negatives.\n",
    "    * Multi-class evaluation uses averages over binary evaluations, per class.\n",
    "    * Weighted average = macro average weighted by support (number of true instances of each label); takes class imbalance into account.\n",
    "2. Accuracy  (makes sense if your class labels are uniformly distributed)\n",
    "3. ROC AUC (Area Under the Receiver Operating Characteristic Curve)\n",
    "    * Larger area = better able to distinguish between True Positives and True Negatives\n",
    "4. Multi-class log loss\n",
    "\n",
    "I have selected Weighted average F1-score as the primary metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['model', 'precision_weighted_avg', 'recall_weighted_avg', 'f1_weighted_avg', \n",
    "           'accuracy', 'roc_auc', 'mean_latency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits Train: 0.84, Val: 0.05, Test: 0.10\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = train_df.utterance, train_df.label\n",
    "X_val, y_val = val_df.utterance, val_df.label\n",
    "X_test, y_test = test_df.utterance, test_df.label\n",
    "n_train, n_val, n_test = len(X_train), len(X_val), len(X_test)\n",
    "n_total = n_train + n_val + n_test\n",
    "print('Splits Train: {:.2f}, Val: {:.2f}, Test: {:.2f}'.format(n_train / n_total, n_val / n_total, n_test / n_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limit number of API calls to stay within quotas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_api_calls = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical models\n",
    "\n",
    "Bag-of-words features using TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification_benchmarks.tfidf_bow import generate_tfidf_features, show_relevant_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine train and val sets to generate features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels, tfidf, indices = generate_tfidf_features(train_df, val_df, cutoff=5, ngram_range=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Utterances: 6026, Features: 1407\n"
     ]
    }
   ],
   "source": [
    "print('Number Utterances: {}, Features: {}'.format(*features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*i* utterances represented by *j* features, representing the TF-IDF score for various unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_relevant_terms(features, labels, tfidf, classes, every=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC()\n",
    "model.fit(features, labels)\n",
    "\n",
    "X_test = tfidf.transform(test_df.utterance).toarray()\n",
    "y_test = test_df.label\n",
    "y_pred = model.predict(X_test[:max_api_calls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test[:max_api_calls], y_pred, classes, 0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = perf_by_label(y_test[:max_api_calls], y_pred, classes, counts_by_label)\n",
    "print_perf_by_label(stats, rounded=2, sort_column='f1_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_classification_report(y_test[:max_api_calls], y_pred, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_best_worst(stats, rounded=2, sort_column='f1_score', top_n=5, max_name_len=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported averages are a prevalence-weighted macro-average across classes (equivalent to sklearn's `precision_recall_fscore_support` with `average='weighted'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.4\n",
      "Recall (weighted avg)   : 0.4\n",
      "F1 Score (weighted avg) : 0.4\n",
      "Accuracy                : 0.4\n",
      "ROC AUC (macro avg)     : 0.7\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_latency = round(model.mean_latency(), 4)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Linear SVC', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  precision_weighted_avg  recall_weighted_avg  \\\n",
       "0  Multinomial Naive Bayes                     0.4                  0.4   \n",
       "1      Logistic Regression                     0.4                  0.4   \n",
       "2               Linear SVC                     0.4                  0.4   \n",
       "\n",
       "   f1_weighted_avg  accuracy  roc_auc  mean_latency  \n",
       "0              0.4       0.4      0.7        0.0032  \n",
       "1              0.4       0.4      0.7        0.0033  \n",
       "2              0.4       0.4      0.7        0.0000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC with SMOTE Over-sampling\n",
    "\n",
    "*SMOTE: Synthetic Minority Over-sampling Technique.*\n",
    "\n",
    "A combination of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. \n",
    "\n",
    "This method of over-sampling the minority class involves creating synthetic minority class examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/d777710/miniconda3/envs/dltemplate_rasa\n",
      "\n",
      "  added / updated specs: \n",
      "    - imbalanced-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    imbalanced-learn-0.3.3     |             py_1          78 KB  conda-forge\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    imbalanced-learn: 0.3.3-py_1 conda-forge\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "imbalanced-learn-0.3 | 78 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "# !conda install -y -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SMOTE' object has no attribute 'fit_resample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-272-683386cf7a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SMOTE' object has no attribute 'fit_resample'"
     ]
    }
   ],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_smote = LinearSVC().fit(X_resampled, y_resampled)\n",
    "y_pred = model_smote.predict(X_test[:max_api_calls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_latency = round(model_smote.mean_latency(), 4)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Linear SVC with SMOTE Over-sampling', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level CNN (Kim 2014)\n",
    "\n",
    "CNNs have become a modern standard baseline method akin to Naive Bayes models, Support Vector Machine (SVMs) and Logistic Regression.\n",
    "\n",
    "Originally invented for computer vision, CNN models have subsequently been shown to be effective for NLP and have achieved excellent results in semantic parsing (Yih et al., 2014), search query retrieval (Shen et al., 2014), sentence modeling (Kalchbrenner et al., 2014), and other traditional NLP tasks (Collobert et al., 2011).\n",
    "\n",
    "The first layer embeds words into low-dimensional vectors. The next layer performs convolutions over the embedded word vectors using multiple filter sizes. For example, sliding over 3, 4 or 5 words at a time. Next, we max-pool the result of the convolutional layer into a long feature vector, add dropout regularization, and classify the result using a softmax layer.\n",
    "\n",
    "See [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1408.5882.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn\n",
    "import text_classification_benchmarks.word_cnn.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../word_cnn/runs/1540695350/checkpoints'\n",
    "vocab_path = os.path.join(checkpoint_dir, '..', 'vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:203: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:203: tokenizer (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "x_raw = test_df.utterance.values[:max_api_calls]\n",
    "x_test = np.array(list(vocab_processor.transform(x_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1540695350/checkpoints/model-17800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1540695350/checkpoints/model-17800\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "y_pred = util.test(x_test, batch_size=64, checkpoint_dir=checkpoint_dir, \n",
    "                   allow_soft_placement=True, log_device_placement=False)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.4\n",
      "Recall (weighted avg)   : 0.4\n",
      "F1 Score (weighted avg) : 0.4\n",
      "Accuracy                : 0.4\n",
      "ROC AUC (macro avg)     : 0.7\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.05777697563171387\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Word-level CNN', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  precision_weighted_avg  recall_weighted_avg  \\\n",
       "0   Multinomial Naive Bayes                     0.4                  0.4   \n",
       "1       Logistic Regression                     0.4                  0.4   \n",
       "2                Linear SVC                     0.4                  0.4   \n",
       "3                     NBSVM                     0.6                  0.6   \n",
       "4    RASA NLU Spacy-sklearn                     0.4                  0.4   \n",
       "5       RASA NLU TensorFlow                     0.8                  0.8   \n",
       "6                 Snips NLU                     0.2                  0.2   \n",
       "7                IBM Watson                     0.8                  0.8   \n",
       "8         Google Dialogflow                     0.8                  0.8   \n",
       "9            Microsoft LUIS                     0.2                  0.2   \n",
       "10               Amazon Lex                     0.6                  0.4   \n",
       "11      Salesforce Einstein                     0.2                  0.2   \n",
       "12  fastText Classification                     0.7                  0.8   \n",
       "13           Word-level CNN                     0.4                  0.4   \n",
       "\n",
       "    f1_weighted_avg  accuracy  roc_auc  mean_latency  \n",
       "0          0.400000       0.4   0.7000      0.003200  \n",
       "1          0.400000       0.4   0.7000      0.003300  \n",
       "2          0.400000       0.4   0.7000      0.000000  \n",
       "3          0.600000       0.6   0.8000      0.350400  \n",
       "4          0.400000       0.4   0.7000      0.015400  \n",
       "5          0.800000       0.8   0.9000      0.013100  \n",
       "6          0.200000       0.2   0.6000      0.015200  \n",
       "7          0.800000       0.8   0.9000      0.229900  \n",
       "8          0.800000       0.8   0.9000      1.182700  \n",
       "9          0.200000       0.2   0.6000      0.810000  \n",
       "10         0.466667       0.4   0.6875      1.066900  \n",
       "11         0.200000       0.2   0.6000      1.543500  \n",
       "12         0.733333       0.8   0.8750      0.000191  \n",
       "13         0.400000       0.4   0.7000      0.057777  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-level CNN initialised with Word2Vec embeddings\n",
    "\n",
    "Trains the above CNN initialised with word vectors obtained from an unsupervised neural language model. These vectors were trained by Mikolov et al. (2013) on 100 billion words of Google News. The vectors have dimensionality of 300 and were trained using the continuous bag-of-words\n",
    "architecture.\n",
    "\n",
    "We keep the word vectors static and learn only the other parameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../word_cnn/runs/1541065783/checkpoints'\n",
    "vocab_path = os.path.join(checkpoint_dir, '..', 'vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = test_df.utterance.values[:max_api_calls]\n",
    "x_test = np.array(list(vocab_processor.transform(x_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1541065783/checkpoints/model-17800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1541065783/checkpoints/model-17800\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "y_pred = util.test(x_test, batch_size=64, checkpoint_dir=checkpoint_dir, \n",
    "                   allow_soft_placement=True, log_device_placement=False)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.2\n",
      "Recall (weighted avg)   : 0.2\n",
      "F1 Score (weighted avg) : 0.2\n",
      "Accuracy                : 0.2\n",
      "ROC AUC (macro avg)     : 0.6\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit better.\n",
    "\n",
    "See also [A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification](https://arxiv.org/pdf/1510.03820.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.09120020866394044\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Word-level CNN + Embeddings', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  precision_weighted_avg  recall_weighted_avg  \\\n",
       "0       Multinomial Naive Bayes                     0.4                  0.4   \n",
       "1           Logistic Regression                     0.4                  0.4   \n",
       "2                    Linear SVC                     0.4                  0.4   \n",
       "3                         NBSVM                     0.6                  0.6   \n",
       "4        RASA NLU Spacy-sklearn                     0.4                  0.4   \n",
       "5           RASA NLU TensorFlow                     0.8                  0.8   \n",
       "6                     Snips NLU                     0.2                  0.2   \n",
       "7                    IBM Watson                     0.8                  0.8   \n",
       "8             Google Dialogflow                     0.8                  0.8   \n",
       "9                Microsoft LUIS                     0.2                  0.2   \n",
       "10                   Amazon Lex                     0.6                  0.4   \n",
       "11          Salesforce Einstein                     0.2                  0.2   \n",
       "12      fastText Classification                     0.7                  0.8   \n",
       "13               Word-level CNN                     0.4                  0.4   \n",
       "14  Word-level CNN + Embeddings                     0.2                  0.2   \n",
       "\n",
       "    f1_weighted_avg  accuracy  roc_auc  mean_latency  \n",
       "0          0.400000       0.4   0.7000      0.003200  \n",
       "1          0.400000       0.4   0.7000      0.003300  \n",
       "2          0.400000       0.4   0.7000      0.000000  \n",
       "3          0.600000       0.6   0.8000      0.350400  \n",
       "4          0.400000       0.4   0.7000      0.015400  \n",
       "5          0.800000       0.8   0.9000      0.013100  \n",
       "6          0.200000       0.2   0.6000      0.015200  \n",
       "7          0.800000       0.8   0.9000      0.229900  \n",
       "8          0.800000       0.8   0.9000      1.182700  \n",
       "9          0.200000       0.2   0.6000      0.810000  \n",
       "10         0.466667       0.4   0.6875      1.066900  \n",
       "11         0.200000       0.2   0.6000      1.543500  \n",
       "12         0.733333       0.8   0.8750      0.000191  \n",
       "13         0.400000       0.4   0.7000      0.057777  \n",
       "14         0.200000       0.2   0.6000      0.091200  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Embeddings + L2 regularization (l2_reg_lambda = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../word_cnn/runs/1541112212/checkpoints'\n",
    "vocab_path = os.path.join(checkpoint_dir, '..', 'vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = test_df.utterance.values[:max_api_calls]\n",
    "x_test = np.array(list(vocab_processor.transform(x_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1541112212/checkpoints/model-8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1541112212/checkpoints/model-8900\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "y_pred = util.test(x_test, batch_size=64, checkpoint_dir=checkpoint_dir, \n",
    "                   allow_soft_placement=True, log_device_placement=False)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.0\n",
      "Recall (weighted avg)   : 0.0\n",
      "F1 Score (weighted avg) : 0.0\n",
      "Accuracy                : 0.0\n",
      "ROC AUC (macro avg)     : 0.5\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.05578298568725586\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Word-level CNN + Embeddings + L2 Reg', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model  precision_weighted_avg  \\\n",
       "0                Multinomial Naive Bayes                     0.4   \n",
       "1                    Logistic Regression                     0.4   \n",
       "2                             Linear SVC                     0.4   \n",
       "3                                  NBSVM                     0.6   \n",
       "4                 RASA NLU Spacy-sklearn                     0.4   \n",
       "5                    RASA NLU TensorFlow                     0.8   \n",
       "6                              Snips NLU                     0.2   \n",
       "7                             IBM Watson                     0.8   \n",
       "8                      Google Dialogflow                     0.8   \n",
       "9                         Microsoft LUIS                     0.2   \n",
       "10                            Amazon Lex                     0.6   \n",
       "11                   Salesforce Einstein                     0.2   \n",
       "12               fastText Classification                     0.7   \n",
       "13                        Word-level CNN                     0.4   \n",
       "14           Word-level CNN + Embeddings                     0.2   \n",
       "15  Word-level CNN + Embeddings + L2 Reg                     0.0   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy  roc_auc  mean_latency  \n",
       "0                   0.4         0.400000       0.4   0.7000      0.003200  \n",
       "1                   0.4         0.400000       0.4   0.7000      0.003300  \n",
       "2                   0.4         0.400000       0.4   0.7000      0.000000  \n",
       "3                   0.6         0.600000       0.6   0.8000      0.350400  \n",
       "4                   0.4         0.400000       0.4   0.7000      0.015400  \n",
       "5                   0.8         0.800000       0.8   0.9000      0.013100  \n",
       "6                   0.2         0.200000       0.2   0.6000      0.015200  \n",
       "7                   0.8         0.800000       0.8   0.9000      0.229900  \n",
       "8                   0.8         0.800000       0.8   0.9000      1.182700  \n",
       "9                   0.2         0.200000       0.2   0.6000      0.810000  \n",
       "10                  0.4         0.466667       0.4   0.6875      1.066900  \n",
       "11                  0.2         0.200000       0.2   0.6000      1.543500  \n",
       "12                  0.8         0.733333       0.8   0.8750      0.000191  \n",
       "13                  0.4         0.400000       0.4   0.7000      0.057777  \n",
       "14                  0.2         0.200000       0.2   0.6000      0.091200  \n",
       "15                  0.0         0.000000       0.0   0.5000      0.055783  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Embeddings + higher dropout rate (keep_prob = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../word_cnn/runs/1541241817/checkpoints'\n",
    "vocab_path = os.path.join(checkpoint_dir, '..', 'vocab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = learn.preprocessing.VocabularyProcessor.restore(vocab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw = test_df.utterance.values[:max_api_calls]\n",
    "x_test = np.array(list(vocab_processor.transform(x_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1541241817/checkpoints/model-8900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/word_cnn/runs/1541241817/checkpoints/model-8900\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "y_pred = util.test(x_test, batch_size=64, checkpoint_dir=checkpoint_dir, \n",
    "                   allow_soft_placement=True, log_device_placement=False)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.2\n",
      "Recall (weighted avg)   : 0.2\n",
      "F1 Score (weighted avg) : 0.2\n",
      "Accuracy                : 0.2\n",
      "ROC AUC (macro avg)     : 0.6\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.05318779945373535\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Word-level CNN + Embeddings + Higher Dropout', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Word-level CNN + Embeddings + Higher Dropout</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  precision_weighted_avg  \\\n",
       "0                        Multinomial Naive Bayes                     0.4   \n",
       "1                            Logistic Regression                     0.4   \n",
       "2                                     Linear SVC                     0.4   \n",
       "3                                          NBSVM                     0.6   \n",
       "4                         RASA NLU Spacy-sklearn                     0.4   \n",
       "5                            RASA NLU TensorFlow                     0.8   \n",
       "6                                      Snips NLU                     0.2   \n",
       "7                                     IBM Watson                     0.8   \n",
       "8                              Google Dialogflow                     0.8   \n",
       "9                                 Microsoft LUIS                     0.2   \n",
       "10                                    Amazon Lex                     0.6   \n",
       "11                           Salesforce Einstein                     0.2   \n",
       "12                       fastText Classification                     0.7   \n",
       "13                                Word-level CNN                     0.4   \n",
       "14                   Word-level CNN + Embeddings                     0.2   \n",
       "15          Word-level CNN + Embeddings + L2 Reg                     0.0   \n",
       "16  Word-level CNN + Embeddings + Higher Dropout                     0.2   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy  roc_auc  mean_latency  \n",
       "0                   0.4         0.400000       0.4   0.7000      0.003200  \n",
       "1                   0.4         0.400000       0.4   0.7000      0.003300  \n",
       "2                   0.4         0.400000       0.4   0.7000      0.000000  \n",
       "3                   0.6         0.600000       0.6   0.8000      0.350400  \n",
       "4                   0.4         0.400000       0.4   0.7000      0.015400  \n",
       "5                   0.8         0.800000       0.8   0.9000      0.013100  \n",
       "6                   0.2         0.200000       0.2   0.6000      0.015200  \n",
       "7                   0.8         0.800000       0.8   0.9000      0.229900  \n",
       "8                   0.8         0.800000       0.8   0.9000      1.182700  \n",
       "9                   0.2         0.200000       0.2   0.6000      0.810000  \n",
       "10                  0.4         0.466667       0.4   0.6875      1.066900  \n",
       "11                  0.2         0.200000       0.2   0.6000      1.543500  \n",
       "12                  0.8         0.733333       0.8   0.8750      0.000191  \n",
       "13                  0.4         0.400000       0.4   0.7000      0.057777  \n",
       "14                  0.2         0.200000       0.2   0.6000      0.091200  \n",
       "15                  0.0         0.000000       0.0   0.5000      0.055783  \n",
       "16                  0.2         0.200000       0.2   0.6000      0.053188  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-level CNN (Kim et al. 2015)\n",
    "\n",
    "[Character-Aware Neural Language Models](https://arxiv.org/pdf/1508.06615.pdf)\n",
    "\n",
    "Character-level ConvNet is an effective method for text classification without the need for words.\n",
    "\n",
    "Historically, ConvNets usually require large-scale datasets to work. In this case, it appears to be competitive on our small dataset.\n",
    "\n",
    "ConvNets may work well for user-generated data. Further analysis is needed to validate the hypothesis that ConvNets are truly good at identifying exotic character combinations such as misspellings and emoticons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import text_classification_benchmarks.char_cnn.model_setup as setup\n",
    "import text_classification_benchmarks.char_cnn.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"\\/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n",
    "input_size = 400\n",
    "n_classes = len(classes)\n",
    "x_test_cropped = test_df.utterance.values[:max_api_calls]\n",
    "y_test_cropped = test_df.label.values[:max_api_calls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = util.Data(x_test_cropped, y_test_cropped, alphabet, input_size, n_classes)\n",
    "test_data.load_data()\n",
    "x_test_onehot, y_test_onehot = test_data.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1156: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1156: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model at ../char_cnn/models/weights.best.hdf5\n",
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "sent_input (InputLayer)          (None, 400)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 400, 128)      8960        sent_input[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "Conv1D_256_10 (Conv1D)           (None, 391, 256)      327936      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "Conv1D_256_7 (Conv1D)            (None, 394, 256)      229632      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "Conv1D_256_5 (Conv1D)            (None, 396, 256)      164096      embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "Conv1D_256_3 (Conv1D)            (None, 398, 256)      98560       embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "MaxPoolingOverTime_256_10 (Globa (None, 256)           0           Conv1D_256_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "MaxPoolingOverTime_256_7 (Global (None, 256)           0           Conv1D_256_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "MaxPoolingOverTime_256_5 (Global (None, 256)           0           Conv1D_256_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "MaxPoolingOverTime_256_3 (Global (None, 256)           0           Conv1D_256_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 1024)          0           MaxPoolingOverTime_256_10[0][0]  \n",
      "                                                                   MaxPoolingOverTime_256_7[0][0]   \n",
      "                                                                   MaxPoolingOverTime_256_5[0][0]   \n",
      "                                                                   MaxPoolingOverTime_256_3[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1024)          1049600     concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropout)   (None, 1024)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 1024)          1049600     alpha_dropout_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "alpha_dropout_2 (AlphaDropout)   (None, 1024)          0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 191)           195775      alpha_dropout_2[0][0]            \n",
      "====================================================================================================\n",
      "Total params: 3,124,159\n",
      "Trainable params: 3,124,159\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = setup.CharCNN(input_size,\n",
    "                      alphabet_size=69,\n",
    "                      embedding_size=128,\n",
    "                      conv_layers=[[256, 10], [256, 7], [256, 5], [256, 3]],\n",
    "                      fully_connected_layers=[1024, 1024],\n",
    "                      n_classes=n_classes,\n",
    "                      keep_prob=0.1,\n",
    "                      model_filename='../char_cnn/models/weights.best.hdf5',\n",
    "                      optimizer='adam',\n",
    "                      loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.time()\n",
    "preds = model.predict(x_test_onehot, batch_size=128)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(preds, axis=1) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.4\n",
      "Recall (weighted avg)   : 0.4\n",
      "F1 Score (weighted avg) : 0.4\n",
      "Accuracy                : 0.4\n",
      "ROC AUC (macro avg)     : 0.7\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.026536035537719726\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Char-level CNN', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Word-level CNN + Embeddings + Higher Dropout</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Char-level CNN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.026536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  precision_weighted_avg  \\\n",
       "0                        Multinomial Naive Bayes                     0.4   \n",
       "1                            Logistic Regression                     0.4   \n",
       "2                                     Linear SVC                     0.4   \n",
       "3                                          NBSVM                     0.6   \n",
       "4                         RASA NLU Spacy-sklearn                     0.4   \n",
       "5                            RASA NLU TensorFlow                     0.8   \n",
       "6                                      Snips NLU                     0.2   \n",
       "7                                     IBM Watson                     0.8   \n",
       "8                              Google Dialogflow                     0.8   \n",
       "9                                 Microsoft LUIS                     0.2   \n",
       "10                                    Amazon Lex                     0.6   \n",
       "11                           Salesforce Einstein                     0.2   \n",
       "12                       fastText Classification                     0.7   \n",
       "13                                Word-level CNN                     0.4   \n",
       "14                   Word-level CNN + Embeddings                     0.2   \n",
       "15          Word-level CNN + Embeddings + L2 Reg                     0.0   \n",
       "16  Word-level CNN + Embeddings + Higher Dropout                     0.2   \n",
       "17                                Char-level CNN                     0.4   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy  roc_auc  mean_latency  \n",
       "0                   0.4         0.400000       0.4   0.7000      0.003200  \n",
       "1                   0.4         0.400000       0.4   0.7000      0.003300  \n",
       "2                   0.4         0.400000       0.4   0.7000      0.000000  \n",
       "3                   0.6         0.600000       0.6   0.8000      0.350400  \n",
       "4                   0.4         0.400000       0.4   0.7000      0.015400  \n",
       "5                   0.8         0.800000       0.8   0.9000      0.013100  \n",
       "6                   0.2         0.200000       0.2   0.6000      0.015200  \n",
       "7                   0.8         0.800000       0.8   0.9000      0.229900  \n",
       "8                   0.8         0.800000       0.8   0.9000      1.182700  \n",
       "9                   0.2         0.200000       0.2   0.6000      0.810000  \n",
       "10                  0.4         0.466667       0.4   0.6875      1.066900  \n",
       "11                  0.2         0.200000       0.2   0.6000      1.543500  \n",
       "12                  0.8         0.733333       0.8   0.8750      0.000191  \n",
       "13                  0.4         0.400000       0.4   0.7000      0.057777  \n",
       "14                  0.2         0.200000       0.2   0.6000      0.091200  \n",
       "15                  0.0         0.000000       0.0   0.5000      0.055783  \n",
       "16                  0.2         0.200000       0.2   0.6000      0.053188  \n",
       "17                  0.4         0.400000       0.4   0.7000      0.026536  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM (Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import text_classification_benchmarks.bi_lstm.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../text_classification_benchmarks/bi_lstm/util.py:71: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../text_classification_benchmarks/bi_lstm/util.py:71: VocabularyProcessor.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.text) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/d777710/miniconda3/envs/dltemplate_rasa/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/preprocessing/text.py:154: CategoricalVocabulary.__init__ (from tensorflow.contrib.learn.python.learn.preprocessing.categorical_vocabulary) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tensorflow/transform or tf.data.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "cropped_size = max_api_calls if max_api_calls > batch_size else batch_size\n",
    "train_labels, train_utterances, train_lengths = util.prepare_data(train_df)\n",
    "test_labels, test_utterances, test_lengths = util.prepare_data(test_df[:cropped_size])\n",
    "x_train_indexed, y_train_indexed, train_lengths, x_test_indexed, y_test_indexed, test_lengths, max_length, vocab_size, _ = \\\n",
    "    util.process_data(train_labels, train_utterances, train_lengths, \n",
    "                      test_labels, test_utterances, test_lengths, min_frequency=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../bi_lstm/model/clf-8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../bi_lstm/model/clf-8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.38417376882650633\n"
     ]
    }
   ],
   "source": [
    "# Training performance\n",
    "y_pred = util.test(x_train_indexed, y_train_indexed, train_lengths, batch_size=batch_size, \n",
    "                   run_dir='../bi_lstm/', checkpoint='clf-8000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../bi_lstm/model/clf-8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../bi_lstm/model/clf-8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.203125\n"
     ]
    }
   ],
   "source": [
    "# Test performance\n",
    "tic = time.time()\n",
    "y_pred = util.test(x_test_indexed, y_test_indexed, test_lengths, batch_size=batch_size, \n",
    "                   run_dir='../bi_lstm/', checkpoint='clf-8000')\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like overfitting. Need a more data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.17\n",
      "Recall (weighted avg)   : 0.2\n",
      "F1 Score (weighted avg) : 0.17\n",
      "Accuracy                : 0.2\n",
      "ROC AUC (macro avg)     : 0.6\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:cropped_size], y_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.1513441562652588\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'BiLSTM', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Word-level CNN + Embeddings + Higher Dropout</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Char-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.026536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>0.168229</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.174740</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.151344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  precision_weighted_avg  \\\n",
       "0                        Multinomial Naive Bayes                0.400000   \n",
       "1                            Logistic Regression                0.400000   \n",
       "2                                     Linear SVC                0.400000   \n",
       "3                                          NBSVM                0.600000   \n",
       "4                         RASA NLU Spacy-sklearn                0.400000   \n",
       "5                            RASA NLU TensorFlow                0.800000   \n",
       "6                                      Snips NLU                0.200000   \n",
       "7                                     IBM Watson                0.800000   \n",
       "8                              Google Dialogflow                0.800000   \n",
       "9                                 Microsoft LUIS                0.200000   \n",
       "10                                    Amazon Lex                0.600000   \n",
       "11                           Salesforce Einstein                0.200000   \n",
       "12                       fastText Classification                0.700000   \n",
       "13                                Word-level CNN                0.400000   \n",
       "14                   Word-level CNN + Embeddings                0.200000   \n",
       "15          Word-level CNN + Embeddings + L2 Reg                0.000000   \n",
       "16  Word-level CNN + Embeddings + Higher Dropout                0.200000   \n",
       "17                                Char-level CNN                0.400000   \n",
       "18                                        BiLSTM                0.168229   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy   roc_auc  mean_latency  \n",
       "0              0.400000         0.400000  0.400000  0.700000      0.003200  \n",
       "1              0.400000         0.400000  0.400000  0.700000      0.003300  \n",
       "2              0.400000         0.400000  0.400000  0.700000      0.000000  \n",
       "3              0.600000         0.600000  0.600000  0.800000      0.350400  \n",
       "4              0.400000         0.400000  0.400000  0.700000      0.015400  \n",
       "5              0.800000         0.800000  0.800000  0.900000      0.013100  \n",
       "6              0.200000         0.200000  0.200000  0.600000      0.015200  \n",
       "7              0.800000         0.800000  0.800000  0.900000      0.229900  \n",
       "8              0.800000         0.800000  0.800000  0.900000      1.182700  \n",
       "9              0.200000         0.200000  0.200000  0.600000      0.810000  \n",
       "10             0.400000         0.466667  0.400000  0.687500      1.066900  \n",
       "11             0.200000         0.200000  0.200000  0.600000      1.543500  \n",
       "12             0.800000         0.733333  0.800000  0.875000      0.000191  \n",
       "13             0.400000         0.400000  0.400000  0.700000      0.057777  \n",
       "14             0.200000         0.200000  0.200000  0.600000      0.091200  \n",
       "15             0.000000         0.000000  0.000000  0.500000      0.055783  \n",
       "16             0.200000         0.200000  0.200000  0.600000      0.053188  \n",
       "17             0.400000         0.400000  0.400000  0.700000      0.026536  \n",
       "18             0.203125         0.174740  0.203125  0.600008      0.151344  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined CNN and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common.load_data as load_data\n",
    "import common.util as data_util\n",
    "import tf_model.text_classifier.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(load_data)\n",
    "# importlib.reload(data_util)\n",
    "# importlib.reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = {\n",
    "    'batch_size': 128,\n",
    "    'keep_prob': 0.5,\n",
    "    'emb_dim': 300,\n",
    "    'eval_every': 500,\n",
    "    'filter_sizes': [3, 4, 5],\n",
    "    'n_hidden': 300,\n",
    "    'l2_reg_lambda': 0.0,\n",
    "    'max_pool_size': 4,\n",
    "    'non_static': False,\n",
    "    'n_epochs': 1000,\n",
    "    'n_filters': 32,\n",
    "    'learning_rate': 0.001,\n",
    "    'decay': 0.9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_ = pd.concat([train_df[['label', 'utterance']], val_df])\n",
    "# train_df_ = train_df_.reset_index(drop=True)\n",
    "# x_train_, y_train_, vocab, vocab_inv, df, labels = \\\n",
    "#     load_data.prepare_classification_training_set(train_df_, selected=['label', 'utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trained_dir = util.train(x_train_, y_train_, vocab, vocab_inv, labels, constants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_DIR = '/Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/notebooks/trained_results_1542333262/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:In prediction, reading trained sequence length...\n",
      "INFO:root:Max sequence length: 62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len: 62\n",
      "non_static: False\n",
      "n_hidden: 300\n",
      "filter_sizes: [3, 4, 5]\n",
      "n_filters: 32\n",
      "emb_dim: 300\n",
      "max_pool_size: 4\n",
      "WARNING:tensorflow:From ../../tf_model/text_classifier/model_setup.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From ../../tf_model/text_classifier/model_setup.py:78: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/notebooks/trained_results_1542333262/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/notebooks/trained_results_1542333262/best_model\n",
      "CRITICAL:root:/Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/notebooks/trained_results_1542333262/best_model has been loaded\n",
      "CRITICAL:root:Prediction complete! Saved to predicted_results_1542333262/.\n"
     ]
    }
   ],
   "source": [
    "params, words_index, labels, embedding_mat = util.load_trained_params(TRAINED_DIR)\n",
    "x_test_, y_test_, df = load_data.prepare_classification_test_set(test_df[:max_api_calls], selected=['utterance'],\n",
    "                                                                 labels=labels)\n",
    "tic = time.time()\n",
    "preds, _, _ = util.predict(x_test_, y_test_, df, params, words_index, labels, embedding_mat, TRAINED_DIR)\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.4\n",
      "Recall (weighted avg)   : 0.4\n",
      "F1 Score (weighted avg) : 0.4\n",
      "Accuracy                : 0.4\n",
      "ROC AUC (macro avg)     : 0.7\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_test[:max_api_calls], preds)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.6438003540039062\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / len(x_test)\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Combined CNN + RNN', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Word-level CNN + Embeddings + Higher Dropout</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Char-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.026536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>0.168229</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.174740</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.151344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Combined CNN + RNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.643800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  precision_weighted_avg  \\\n",
       "0                        Multinomial Naive Bayes                0.400000   \n",
       "1                            Logistic Regression                0.400000   \n",
       "2                                     Linear SVC                0.400000   \n",
       "3                                          NBSVM                0.600000   \n",
       "4                         RASA NLU Spacy-sklearn                0.400000   \n",
       "5                            RASA NLU TensorFlow                0.800000   \n",
       "6                                      Snips NLU                0.200000   \n",
       "7                                     IBM Watson                0.800000   \n",
       "8                              Google Dialogflow                0.800000   \n",
       "9                                 Microsoft LUIS                0.200000   \n",
       "10                                    Amazon Lex                0.600000   \n",
       "11                           Salesforce Einstein                0.200000   \n",
       "12                       fastText Classification                0.700000   \n",
       "13                                Word-level CNN                0.400000   \n",
       "14                   Word-level CNN + Embeddings                0.200000   \n",
       "15          Word-level CNN + Embeddings + L2 Reg                0.000000   \n",
       "16  Word-level CNN + Embeddings + Higher Dropout                0.200000   \n",
       "17                                Char-level CNN                0.400000   \n",
       "18                                        BiLSTM                0.168229   \n",
       "19                            Combined CNN + RNN                0.400000   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy   roc_auc  mean_latency  \n",
       "0              0.400000         0.400000  0.400000  0.700000      0.003200  \n",
       "1              0.400000         0.400000  0.400000  0.700000      0.003300  \n",
       "2              0.400000         0.400000  0.400000  0.700000      0.000000  \n",
       "3              0.600000         0.600000  0.600000  0.800000      0.350400  \n",
       "4              0.400000         0.400000  0.400000  0.700000      0.015400  \n",
       "5              0.800000         0.800000  0.800000  0.900000      0.013100  \n",
       "6              0.200000         0.200000  0.200000  0.600000      0.015200  \n",
       "7              0.800000         0.800000  0.800000  0.900000      0.229900  \n",
       "8              0.800000         0.800000  0.800000  0.900000      1.182700  \n",
       "9              0.200000         0.200000  0.200000  0.600000      0.810000  \n",
       "10             0.400000         0.466667  0.400000  0.687500      1.066900  \n",
       "11             0.200000         0.200000  0.200000  0.600000      1.543500  \n",
       "12             0.800000         0.733333  0.800000  0.875000      0.000191  \n",
       "13             0.400000         0.400000  0.400000  0.700000      0.057777  \n",
       "14             0.200000         0.200000  0.200000  0.600000      0.091200  \n",
       "15             0.000000         0.000000  0.000000  0.500000      0.055783  \n",
       "16             0.200000         0.200000  0.200000  0.600000      0.053188  \n",
       "17             0.400000         0.400000  0.400000  0.700000      0.026536  \n",
       "18             0.203125         0.174740  0.203125  0.600008      0.151344  \n",
       "19             0.400000         0.400000  0.400000  0.700000      0.643800  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "\n",
    "Based on the paper, [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf).\n",
    "\n",
    "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import text_classification_benchmarks.transformer.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Classification Vocab size: 500001\n",
      "Loading data...\n",
      "test data length: 703\n",
      "n_examples: 703\n",
      "Encoding started\n",
      "Encoding ended. Q: Tensor(\"layer_normalization_0_encoder_position_wise_ff/add_1:0\", shape=(256, 60, 300), dtype=float32), Ks: Tensor(\"layer_normalization_0_encoder_position_wise_ff/add_1:0\", shape=(256, 60, 300), dtype=float32), latency: 0.1480870246887207\n",
      "Restoring variables from checkpoint\n",
      "INFO:tensorflow:Restoring parameters from ../transformer/trnfmr_model/model-17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../transformer/trnfmr_model/model-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 703\n",
      "logits_batch shape: (256, 191)\n",
      "logits_batch shape: (256, 191)\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "result, labels = util.predict(test_file='../fasttext/test.txt',\n",
    "                              n_classes=len(classes),\n",
    "                              learning_rate=0.01,\n",
    "                              batch_size=256,\n",
    "                              decay_steps=12000,\n",
    "                              decay_rate=1.0,\n",
    "                              seq_len=60,\n",
    "                              embed_size=300,\n",
    "                              d_model=300,\n",
    "                              d_k=64,\n",
    "                              d_v=64,\n",
    "                              h=10,\n",
    "                              n_layers=1,\n",
    "                              l2_lambda=0.0001,\n",
    "                              checkpoint_dir='../transformer/trnfmr_model/',\n",
    "                              vocab_labels_filename='../transformer/labels.txt',\n",
    "                              word2vec_filename='../../../data/word2vec/GoogleNews-vectors-negative300.bin'\n",
    "                             )\n",
    "toc = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = [x[1][0] for x in result]\n",
    "preds = [list(classes).index(x) for x in intents]\n",
    "y_true = [list(classes).index(x) for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (weighted avg): 0.4\n",
      "Recall (weighted avg)   : 0.4\n",
      "F1 Score (weighted avg) : 0.4\n",
      "Accuracy                : 0.4\n",
      "ROC AUC (macro avg)     : 0.7\n"
     ]
    }
   ],
   "source": [
    "stats = perf_summary(y_true[:max_api_calls], preds[:max_api_calls])\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean latency (secs): 0.00386834856795722\n"
     ]
    }
   ],
   "source": [
    "mean_latency = (toc - tic) / n_test\n",
    "print('Mean latency (secs):', mean_latency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict({'model': 'Transformer', 'mean_latency': mean_latency}, **stats)\n",
    "benchmarks = benchmarks.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Word-level CNN + Embeddings + Higher Dropout</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Char-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.026536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>0.168229</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.174740</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.151344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Combined CNN + RNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.643800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  precision_weighted_avg  \\\n",
       "0                        Multinomial Naive Bayes                0.400000   \n",
       "1                            Logistic Regression                0.400000   \n",
       "2                                     Linear SVC                0.400000   \n",
       "3                                          NBSVM                0.600000   \n",
       "4                         RASA NLU Spacy-sklearn                0.400000   \n",
       "5                            RASA NLU TensorFlow                0.800000   \n",
       "6                                      Snips NLU                0.200000   \n",
       "7                                     IBM Watson                0.800000   \n",
       "8                              Google Dialogflow                0.800000   \n",
       "9                                 Microsoft LUIS                0.200000   \n",
       "10                                    Amazon Lex                0.600000   \n",
       "11                           Salesforce Einstein                0.200000   \n",
       "12                       fastText Classification                0.700000   \n",
       "13                                Word-level CNN                0.400000   \n",
       "14                   Word-level CNN + Embeddings                0.200000   \n",
       "15          Word-level CNN + Embeddings + L2 Reg                0.000000   \n",
       "16  Word-level CNN + Embeddings + Higher Dropout                0.200000   \n",
       "17                                Char-level CNN                0.400000   \n",
       "18                                        BiLSTM                0.168229   \n",
       "19                            Combined CNN + RNN                0.400000   \n",
       "20                                   Transformer                0.400000   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy   roc_auc  mean_latency  \n",
       "0              0.400000         0.400000  0.400000  0.700000      0.003200  \n",
       "1              0.400000         0.400000  0.400000  0.700000      0.003300  \n",
       "2              0.400000         0.400000  0.400000  0.700000      0.000000  \n",
       "3              0.600000         0.600000  0.600000  0.800000      0.350400  \n",
       "4              0.400000         0.400000  0.400000  0.700000      0.015400  \n",
       "5              0.800000         0.800000  0.800000  0.900000      0.013100  \n",
       "6              0.200000         0.200000  0.200000  0.600000      0.015200  \n",
       "7              0.800000         0.800000  0.800000  0.900000      0.229900  \n",
       "8              0.800000         0.800000  0.800000  0.900000      1.182700  \n",
       "9              0.200000         0.200000  0.200000  0.600000      0.810000  \n",
       "10             0.400000         0.466667  0.400000  0.687500      1.066900  \n",
       "11             0.200000         0.200000  0.200000  0.600000      1.543500  \n",
       "12             0.800000         0.733333  0.800000  0.875000      0.000191  \n",
       "13             0.400000         0.400000  0.400000  0.700000      0.057777  \n",
       "14             0.200000         0.200000  0.200000  0.600000      0.091200  \n",
       "15             0.000000         0.000000  0.000000  0.500000      0.055783  \n",
       "16             0.200000         0.200000  0.200000  0.600000      0.053188  \n",
       "17             0.400000         0.400000  0.400000  0.700000      0.026536  \n",
       "18             0.203125         0.174740  0.203125  0.600008      0.151344  \n",
       "19             0.400000         0.400000  0.400000  0.700000      0.643800  \n",
       "20             0.400000         0.400000  0.400000  0.700000      0.003868  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>precision_weighted_avg</th>\n",
       "      <th>recall_weighted_avg</th>\n",
       "      <th>f1_weighted_avg</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>mean_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RASA NLU TensorFlow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM Watson</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.229900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Dialogflow</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fastText Classification</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBSVM</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.350400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon Lex</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Combined CNN + RNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.643800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Char-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.026536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Word-level CNN</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.057777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Multinomial Naive Bayes</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RASA NLU Spacy-sklearn</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Transformer</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.003868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salesforce Einstein</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.543500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Microsoft LUIS</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Snips NLU</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Word-level CNN + Embeddings</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.091200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Word-level CNN + Embeddings + Higher Dropout</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.053188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BiLSTM</td>\n",
       "      <td>0.168229</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.174740</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.151344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Word-level CNN + Embeddings + L2 Reg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.055783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           model  precision_weighted_avg  \\\n",
       "0                            RASA NLU TensorFlow                0.800000   \n",
       "1                                     IBM Watson                0.800000   \n",
       "2                              Google Dialogflow                0.800000   \n",
       "3                        fastText Classification                0.700000   \n",
       "4                                          NBSVM                0.600000   \n",
       "5                                     Amazon Lex                0.600000   \n",
       "6                            Logistic Regression                0.400000   \n",
       "7                             Combined CNN + RNN                0.400000   \n",
       "8                                 Char-level CNN                0.400000   \n",
       "9                                 Word-level CNN                0.400000   \n",
       "10                       Multinomial Naive Bayes                0.400000   \n",
       "11                        RASA NLU Spacy-sklearn                0.400000   \n",
       "12                                    Linear SVC                0.400000   \n",
       "13                                   Transformer                0.400000   \n",
       "14                           Salesforce Einstein                0.200000   \n",
       "15                                Microsoft LUIS                0.200000   \n",
       "16                                     Snips NLU                0.200000   \n",
       "17                   Word-level CNN + Embeddings                0.200000   \n",
       "18  Word-level CNN + Embeddings + Higher Dropout                0.200000   \n",
       "19                                        BiLSTM                0.168229   \n",
       "20          Word-level CNN + Embeddings + L2 Reg                0.000000   \n",
       "\n",
       "    recall_weighted_avg  f1_weighted_avg  accuracy   roc_auc  mean_latency  \n",
       "0              0.800000         0.800000  0.800000  0.900000      0.013100  \n",
       "1              0.800000         0.800000  0.800000  0.900000      0.229900  \n",
       "2              0.800000         0.800000  0.800000  0.900000      1.182700  \n",
       "3              0.800000         0.733333  0.800000  0.875000      0.000191  \n",
       "4              0.600000         0.600000  0.600000  0.800000      0.350400  \n",
       "5              0.400000         0.466667  0.400000  0.687500      1.066900  \n",
       "6              0.400000         0.400000  0.400000  0.700000      0.003300  \n",
       "7              0.400000         0.400000  0.400000  0.700000      0.643800  \n",
       "8              0.400000         0.400000  0.400000  0.700000      0.026536  \n",
       "9              0.400000         0.400000  0.400000  0.700000      0.057777  \n",
       "10             0.400000         0.400000  0.400000  0.700000      0.003200  \n",
       "11             0.400000         0.400000  0.400000  0.700000      0.015400  \n",
       "12             0.400000         0.400000  0.400000  0.700000      0.000000  \n",
       "13             0.400000         0.400000  0.400000  0.700000      0.003868  \n",
       "14             0.200000         0.200000  0.200000  0.600000      1.543500  \n",
       "15             0.200000         0.200000  0.200000  0.600000      0.810000  \n",
       "16             0.200000         0.200000  0.200000  0.600000      0.015200  \n",
       "17             0.200000         0.200000  0.200000  0.600000      0.091200  \n",
       "18             0.200000         0.200000  0.200000  0.600000      0.053188  \n",
       "19             0.203125         0.174740  0.203125  0.600008      0.151344  \n",
       "20             0.000000         0.000000  0.000000  0.500000      0.055783  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked = benchmarks.sort_values('f1_weighted_avg', ascending=False)\n",
    "ranked.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "1. Stratified sampling for splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
