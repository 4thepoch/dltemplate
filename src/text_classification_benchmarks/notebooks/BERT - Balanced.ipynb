{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT - Balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pre-training of Deep Bidirectional Transformers for Language Understanding.*\n",
    "\n",
    "Using transfer learning techniques: first training a model architecture on one language modeling objective, and then fine-tune it for a supervised downstream task.\n",
    "\n",
    "The BERT modelâ€™s architecture is a bidirectional Transformer encoder. The Transformer model is good at capturing long-distance dependencies compared to a recurrent neural network architecture. The bidirectional encoder meanwhile is a standout feature that differentiates BERT from OpenAI GPT (a left-to-right Transformer) and ELMo (a concatenation of independently trained left-to-right and right- to-left LSTM).\n",
    "\n",
    "BERT is a huge model with 24 Transformer blocks, 1024 hidden layers, and 340M parameters.\n",
    "\n",
    "The model is pre-trained on 40 epochs over a 3.3 billion word corpus, including BooksCorpus (800 million words) and English Wikipedia (2.5 billion words).\n",
    "\n",
    "In the pre-training process, researchers took an approach which involved randomly masking a percentage of the input tokens (15 percent) to train a deep bidirectional representation. They refer to this method as a Masked Language Model (MLM).\n",
    "\n",
    "A pre-trained language model cannot understand relationships between sentences, which is vital to language tasks such as question answering and natural language inferencing. Researchers therefore pre-trained a binarized next sentence prediction task that can be trivially generated from any monolingual corpus.\n",
    "\n",
    "From Tim Dettmers regarding compute for BERT: uses 256 TPU-days similar to the OpenAI model. Lots of TPUs parallelize about 25% better than GPUs. RTX 2080 Ti and V100 should be ~70% matmul and ~90% matmul perf vs TPU if you use 16-bit (important!). Therefore BERT ~= 375 RTX 2080 Ti days or 275 V100 days.\n",
    "\n",
    "That would burn a large hole in the wallet. At 5.22 USD per TPU per hour for a Cloud TPU v2 in Asia Pacific, that equates to 32,072 USD or 44,347 AUD (not including experiments and optimization). Likely in the 100,000's.\n",
    "\n",
    "Are we entering the era that while algorithms are available as open source, the data and compute required to implement them are out of reach for most people and organisations who albeit can rent the outcomes?\n",
    "\n",
    "See [Cloud TPU Pricing](https://cloud.google.com/tpu/docs/pricing). Also see [BERT sets new standards](https://medium.com/syncedreview/best-nlp-model-ever-google-bert-sets-new-standards-in-11-language-tasks-4a2a189bc155)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/d777710/src/bert')\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_classification_benchmarks.metrics import perf_summary, print_perf_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/d777710/src/DeepLearning/dltemplate/src/text_classification_benchmarks/fastai'\n",
    "BERT_BASE_DIR = '/Users/d777710/src/DeepLearning/dltemplate/pretrained_models/bert/uncased_L-12_H-768_A-12'\n",
    "CODI_BERT_MODEL = '/Users/d777710/src/bert/codiout3'\n",
    "OUTPUT_DIR = '/tmp/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modeling\n",
    "import run_classifier as clf\n",
    "import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_api_calls = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = os.path.join(BERT_BASE_DIR, 'bert_config.json')\n",
    "bert_config = modeling.BertConfig.from_json_file(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = clf.CsvProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = processor.get_labels(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = os.path.join(BERT_BASE_DIR, 'vocab.txt')\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_checkpoint = os.path.join(BERT_BASE_DIR, 'bert_model.ckpt')\n",
    "init_checkpoint = CODI_BERT_MODEL\n",
    "model_fn = clf.model_fn_builder(\n",
    "    bert_config=bert_config,\n",
    "    num_labels=len(label_list),\n",
    "    init_checkpoint=init_checkpoint,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_steps=None,\n",
    "    num_warmup_steps=None,\n",
    "    use_tpu=False,\n",
    "    use_one_hot_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "run_config = tf.contrib.tpu.RunConfig(\n",
    "      cluster=None,\n",
    "      model_dir=OUTPUT_DIR,\n",
    "      save_checkpoints_steps=1000,\n",
    "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "          iterations_per_loop=1000,\n",
    "          num_shards=8,\n",
    "          per_host_input_for_training=is_per_host\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tf.contrib.tpu.TPUEstimator(\n",
    "    use_tpu=False,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=8,\n",
    "    predict_batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_utterance = 'How long do I have left on my plan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [clf.InputExample(guid=1, text_a=tokenization.convert_to_unicode(sample_utterance))]\n",
    "features = clf.convert_examples_to_features(examples, \n",
    "                                            label_list, \n",
    "                                            max_seq_length=max_seq_length, \n",
    "                                            tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = clf.input_fn_builder(\n",
    "    features=features,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = estimator.predict(input_fn=input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_csv = '../fastai/balanced/val.csv'\n",
    "test_csv = '../fastai/balanced/test.csv'\n",
    "classes_txt = '../fastai/classes.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.genfromtxt(classes_txt, dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in result:\n",
    "    print(classes[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lines = []\n",
    "with tf.gfile.Open(val_csv, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        val_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = []\n",
    "y_val_pred = []\n",
    "incorrect = 0\n",
    "for label, utterance in val_lines[:max_api_calls]:\n",
    "    y_true = int(label)\n",
    "    y_val.append(y_true)\n",
    "    examples = [clf.InputExample(guid=1, text_a=tokenization.convert_to_unicode(utterance))]\n",
    "    features = clf.convert_examples_to_features(examples,\n",
    "                                                label_list,\n",
    "                                                max_seq_length=max_seq_length,\n",
    "                                                tokenizer=tokenizer)\n",
    "    input_fn = clf.input_fn_builder(\n",
    "        features=features,\n",
    "        seq_length=max_seq_length,\n",
    "        is_training=False,\n",
    "        drop_remainder=False\n",
    "    )\n",
    "    pred = next(estimator.predict(input_fn=input_fn))\n",
    "    y_val_pred.append(pred)\n",
    "    if pred != y_true:\n",
    "        print('Utterance:', utterance)\n",
    "        print('Actual   :', classes[int(label)])\n",
    "        print('Pred     :', classes[int(pred)])\n",
    "        print(':)' if int(label) == int(pred) else ':(')\n",
    "        print('')\n",
    "        incorrect += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set performance:\n",
      "Precision (weighted avg): 0.79\n",
      "Recall (weighted avg)   : 0.72\n",
      "F1 Score (weighted avg) : 0.73\n",
      "Accuracy                : 0.72\n",
      "ROC AUC (macro avg)     : 0.85\n"
     ]
    }
   ],
   "source": [
    "print('Dev set performance:')\n",
    "stats = perf_summary(y_val, y_val_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lines = []\n",
    "with tf.gfile.Open(test_csv, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in reader:\n",
    "        test_lines.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "y_test_pred = []\n",
    "for label, utterance in test_lines[:200]:\n",
    "    y_true = int(label)\n",
    "    y_test.append(y_true)\n",
    "    examples = [clf.InputExample(guid=1, text_a=tokenization.convert_to_unicode(utterance))]\n",
    "    features = clf.convert_examples_to_features(examples,\n",
    "                                                label_list,\n",
    "                                                max_seq_length=max_seq_length,\n",
    "                                                tokenizer=tokenizer)\n",
    "    input_fn = clf.input_fn_builder(\n",
    "        features=features,\n",
    "        seq_length=max_seq_length,\n",
    "        is_training=False,\n",
    "        drop_remainder=False\n",
    "    )\n",
    "    pred = next(estimator.predict(input_fn=input_fn))\n",
    "    y_test_pred.append(pred)\n",
    "    print('Utterance:', utterance)\n",
    "    print('Actual   :', classes[int(label)])\n",
    "    print('Pred     :', classes[int(pred)])\n",
    "    print(':)' if int(label) == int(pred) else ':(')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set performance:\n",
      "Precision (weighted avg): 0.76\n",
      "Recall (weighted avg)   : 0.73\n",
      "F1 Score (weighted avg) : 0.71\n",
      "Accuracy                : 0.73\n",
      "ROC AUC (macro avg)     : 0.87\n"
     ]
    }
   ],
   "source": [
    "print('Test set performance:')\n",
    "stats = perf_summary(y_test, y_test_pred)\n",
    "print_perf_summary(stats, rounded=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_examples = processor.get_dev_examples(DATA_DIR)\n",
    "eval_features = clf.convert_examples_to_features(eval_examples, label_list, max_seq_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = clf.input_fn_builder(\n",
    "    features=eval_features,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "eval_result = estimator.evaluate(input_fn=eval_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eval_accuracy = 0.718799352645874\n",
      "  eval_loss = 2.0258591175079346\n",
      "  global_step = 0\n",
      "  loss = 2.0037953853607178\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(eval_result.keys()):\n",
    "    print('  {} = {}'.format(key, eval_result[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = processor.get_test_examples(DATA_DIR)\n",
    "test_features = clf.convert_examples_to_features(test_examples, label_list, max_seq_length, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_fn = clf.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=max_seq_length,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)\n",
    "\n",
    "test_result = estimator.evaluate(input_fn=test_input_fn, steps=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eval_accuracy = 0.6031294465065002\n",
      "  eval_loss = 2.745549440383911\n",
      "  global_step = 0\n",
      "  loss = 2.7473702430725098\n"
     ]
    }
   ],
   "source": [
    "for key in sorted(test_result.keys()):\n",
    "    print('  {} = {}'.format(key, test_result[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "1. Inference slower than API services.\n",
    "2. Best suited to batch predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
