{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem Context\n",
    "\n",
    "Given an FAQ database, if we can match a new question to the closest known question, within some threshold of certainty, we can provide a known answer to this new question.\n",
    "\n",
    "Therefore, a key capability in a knowledge application is the ability to determine the similarity between two questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..')\n",
    "sys.path.append('/Users/d777710/src/Python/spaCy')\n",
    "sys.path.append('/Users/d777710/src/Python/spaCy/examples/keras_parikh_entailment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Quora Question Pairs\n",
    "\n",
    "A dataset created for a [Kaggle competition](https://www.kaggle.com/c/quora-question-pairs).\n",
    "\n",
    "* Duplicates proportion: 36.9% in train, 17.4% in test\n",
    "* Number of question pairs: ~400k in train, ~2.3M in test\n",
    "* ~80% of test dataset contains fake question pairs, such that we can’t hand label test question pairs (avoid cheating)\n",
    "* ~530k unique questions in train dataset\n",
    "* ~110k questions appear multiple times in train and test datasets\n",
    "* Questions which contains:\n",
    "  * Question mark: 99.87%\n",
    "  * [math] tags: 0.12%\n",
    "  * Capitalized first letter: 99.81%\n",
    "  * Capital letters: 99.95%\n",
    "  * Numbers: 11.83%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_model.decomposable_attention as dec_attn\n",
    "import keras_model.decomposable_attention.util as dec_attn_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('train_df.pkl'):\n",
    "    train_df = pd.read_pickle('train_df.pkl')\n",
    "else:\n",
    "    train_df, _ = dec_attn.load_question_pairs_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, shuffle=True):\n",
    "    data_size = len(data)\n",
    "    n_batches = int(data_size / batch_size) + 1\n",
    "    if shuffle:\n",
    "        shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "        shuffled_data = data[shuffle_indices]\n",
    "    else:\n",
    "        shuffled_data = data\n",
    "        \n",
    "    for i in range(n_batches):\n",
    "        start_i = i * batch_size\n",
    "        end_i = min((i + 1) * batch_size, data_size)\n",
    "        yield shuffled_data[start_i:end_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_binned</th>\n",
       "      <th>q2_binned</th>\n",
       "      <th>q1_encoded</th>\n",
       "      <th>q1_length</th>\n",
       "      <th>q2_encoded</th>\n",
       "      <th>q2_length</th>\n",
       "      <th>lsa_cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107142</th>\n",
       "      <td>173615</td>\n",
       "      <td>17297</td>\n",
       "      <td>How does one get many views on a Quora question?</td>\n",
       "      <td>How do you get so many views on Quora?</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.622637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253480</th>\n",
       "      <td>368033</td>\n",
       "      <td>368034</td>\n",
       "      <td>What was your favorite road trip?</td>\n",
       "      <td>What are some of your favorite road trip games?</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.996812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293641</th>\n",
       "      <td>415432</td>\n",
       "      <td>121619</td>\n",
       "      <td>What countries have extradition treaties with ...</td>\n",
       "      <td>Which countries that Singapore doesn't have an...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.846337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312673</th>\n",
       "      <td>437156</td>\n",
       "      <td>437157</td>\n",
       "      <td>Is the Aligno surname Italian?</td>\n",
       "      <td>Any body know …Anand motor products …how is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.120422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97689</th>\n",
       "      <td>8639</td>\n",
       "      <td>134638</td>\n",
       "      <td>Why Cyrus Mistry has been removed from Tata Gr...</td>\n",
       "      <td>Why was Cyrus Mistry removed as the Chairman o...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>(5, 10]</td>\n",
       "      <td>(10, 20]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.804597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qid1    qid2                                          question1  \\\n",
       "107142  173615   17297   How does one get many views on a Quora question?   \n",
       "253480  368033  368034                  What was your favorite road trip?   \n",
       "293641  415432  121619  What countries have extradition treaties with ...   \n",
       "312673  437156  437157                     Is the Aligno surname Italian?   \n",
       "97689     8639  134638  Why Cyrus Mistry has been removed from Tata Gr...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "107142             How do you get so many views on Quora?             1   \n",
       "253480    What are some of your favorite road trip games?             0   \n",
       "293641  Which countries that Singapore doesn't have an...             0   \n",
       "312673  Any body know …Anand motor products …how is th...             0   \n",
       "97689   Why was Cyrus Mistry removed as the Chairman o...             1   \n",
       "\n",
       "        q1_len  q2_len q1_binned q2_binned  \\\n",
       "107142      10       9   (5, 10]   (5, 10]   \n",
       "253480       6       9   (5, 10]   (5, 10]   \n",
       "293641       7      10   (5, 10]   (5, 10]   \n",
       "312673       5      10       NaN   (5, 10]   \n",
       "97689        9      11   (5, 10]  (10, 20]   \n",
       "\n",
       "                                               q1_encoded  q1_length  \\\n",
       "107142  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         10   \n",
       "253480  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          6   \n",
       "293641  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          7   \n",
       "312673  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          5   \n",
       "97689   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          9   \n",
       "\n",
       "                                               q2_encoded  q2_length  \\\n",
       "107142  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          9   \n",
       "253480  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...          9   \n",
       "293641  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         10   \n",
       "312673  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         10   \n",
       "97689   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...         11   \n",
       "\n",
       "        lsa_cosine_similarity  \n",
       "107142               0.622637  \n",
       "253480               0.996812  \n",
       "293641               0.846337  \n",
       "312673               0.120422  \n",
       "97689                0.804597  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_lens = train_df.question1.apply(lambda x: len(re.split(r'\\s+', x.strip()))).values\n",
    "q2_lens = train_df.question2.apply(lambda x: len(re.split(r'\\s+', x.strip()))).values\n",
    "train_df = train_df.assign(q1_len=q1_lens, q2_len=q2_lens)\n",
    "lens = np.vstack([q1_lens, q2_lens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = lens.max()\n",
    "print('max_len:', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(q1_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.q1_len.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(q2_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.q2_len.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [5, 10, 20, 30, 40, 50, 60, 70, 100, 228]\n",
    "train_df = train_df.assign(q1_binned=pd.cut(train_df.q1_len, bins), q2_binned=pd.cut(train_df.q2_len, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(train_df.q1_binned).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupby(train_df.q2_binned).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, word2idx, _, _ = dec_attn.load_embeddings('../../keras_model/decomposable_attention/ft.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = dec_attn.preprocess(train_df, word2idx, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[0].question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.iloc[0].q1_encoded[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_label = train_df.groupby('is_duplicate').qid1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_by_label.loc[1] / counts_by_label.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = plt.axes()\n",
    "counts_by_label.plot.bar(ylim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to create the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('test_df.pkl'):\n",
    "    test_df = pd.read_pickle('test_df.pkl')\n",
    "else:\n",
    "    train_df, test_df = train_test_split(train_df, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('train_df.pkl'):\n",
    "    train_df.to_pickle('train_df.pkl')\n",
    "    \n",
    "if not os.path.exists('test_df.pkl'):\n",
    "    test_df.to_pickle('test_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_attn_embeddings_path = '../../keras_model/decomposable_attention/ft.vec'\n",
    "embeddings, word2idx, _, _ = dec_attn_util.load_embeddings(dec_attn_embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dec_attn_util.preprocess(test_df, word2idx, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 - Decomposable Attention Model\n",
    "\n",
    "We can think of question similarity as an entailment task.\n",
    "\n",
    "Textual entailment (TE) in natural language processing is a directional relation between text fragments. The relation holds whenever the truth of one text fragment follows from another text. In the TE framework, the entailing and entailed texts are termed text (t) (or premise (p)) and hypothesis (h), respectively.\n",
    "\n",
    "The winning solution to the Quora challenge ended up using a decomposable attention model, a siamese network, an enhanced sequential inference model, and more. These were stacked together to form the final classifier.\n",
    "\n",
    "This model architecture from [A Decomposable Attention Model for Natural Language Inference](https://arxiv.org/pdf/1606.01933.pdf), Parikh, et al., provides an efficient way to calculate entailment with attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras_model.layers import MaskedGlobalAveragePooling1D, MaskedGlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_attn_model_path = '../../keras_model/decomposable_attention/decom_attn_checkpoint'\n",
    "dec_attn_model = load_model(dec_attn_model_path, custom_objects={\n",
    "            'MaskedGlobalAveragePooling1D': MaskedGlobalAveragePooling1D(),\n",
    "            'MaskedGlobalMaxPooling1D': MaskedGlobalMaxPooling1D()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dec_attn_model.predict([np.asarray(test_df.q1_encoded.tolist()),\n",
    "                                np.asarray(test_df.q2_encoded.tolist())],\n",
    "                               batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [int(x[0] > .5) for x in preds]\n",
    "y_true = test_df.is_duplicate.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "ll = log_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decomposable Attn model accuracy: {:.2f}, log_loss: {:.2f}'.format(acc, ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 - Decomposable Attention Model from Spacy team\n",
    "\n",
    "Mainly to validate my version of the model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_hook import KerasSimilarityShim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_vectors_web_lg')\n",
    "nlp.add_pipe(KerasSimilarityShim.load(nlp.path / 'similarity', nlp, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1 = test_df.question1.tolist()\n",
    "docs2 = test_df.question2.tolist()\n",
    "labels = test_df.is_duplicate.tolist()\n",
    "y_pred = []\n",
    "for doc1, doc2, label in zip(docs1, docs2, labels):\n",
    "    d1 = nlp(doc1)\n",
    "    d2 = nlp(doc2)\n",
    "    sim, _ = d1.similarity(d2)\n",
    "    \n",
    "    # sim is returning one of [\"entailment\", \"contradiction\", \"neutral\"]\n",
    "    # however my label is one of [0, 1] representing \"is_duplicate\" or not\n",
    "    # therefore I need to extract the index from the prediction to get my label\n",
    "    y_pred.append(KerasSimilarityShim.entailment_types.index(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df.is_duplicate.tolist()\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "ll = log_loss(y_true, y_pred)\n",
    "print('Decomposable Attn model accuracy: {:.2f}, log_loss: {:.2f}'.format(acc, ll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 - Siamese CNN\n",
    "\n",
    "A Siamese CNN is built by combining two CNNs (which are often identical), then running\n",
    "some distance metric on their outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4 - LightGBM and custom features\n",
    "\n",
    "LightGBM is a gradient boosting framework that uses tree based learning algorithm.\n",
    "\n",
    "LightGBM grows the tree vertically while other algorithms grow trees horizontally. In other words, LightGBM grows the tree leaf-wise while other algorithms grow level-wise. It will choose the leaf with the maximum delta loss to grow. When growing the same branch, leaf-wise algorithm can reduce more loss than a level-wise algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import gensim\n",
    "from pyemd import emd\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('../../../data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_model = gensim.models.KeyedVectors.load_word2vec_format('../../../data/word2vec/GoogleNews-vectors-negative300.bin', binary=True)\n",
    "norm_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(tokens):\n",
    "    words = [w for w in tokens if w.isalpha()]\n",
    "    W = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            W.append(model[w])\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "    W = np.array(W)\n",
    "    v = W.sum(axis=0)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stop words and convert to lower case\n",
    "train_df = train_df.assign(\n",
    "    q1_nostop=train_df.question1.apply(lambda x: [w.text.lower() for w in nlp(x) if not w.is_stop]),\n",
    "    q2_nostop=train_df.question2.apply(lambda x: [w.text.lower() for w in nlp(x) if not w.is_stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[1].question1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.iloc[1].q1_nostop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df_nostop.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train_df_nostop.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Mover's Distance**\n",
    "\n",
    "Word Mover's Distance (WMD) is a method that computes the \"distance\" between two documents, even when they have no words in common. It uses word2vec vector embeddings of words. It's been shown to outperform many state-of-the-art methods in k-nearest neighbors classification.\n",
    "\n",
    "This method was introduced in the article [From Word Embeddings To Document Distances](http://proceedings.mlr.press/v37/kusnerb15.pdf) by Matt Kusner, et al.\n",
    "\n",
    "See this [tutorial](https://markroxor.github.io/gensim/static/notebooks/WMD_tutorial.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Normalized WMD**\n",
    "\n",
    "When using the wmdistance method it is beneficial to normalize the word2vec vectors first so they all have equal length. To do this, simply call model.init_sims(replace=True) and Gensim will take care of that for you.\n",
    "\n",
    "Usually, one measures the distance between two word2vec vectors using the cosine distance, which measures the angle between vectors. WMD, on the other hand, uses the Euclidean distance. The Euclidean distance between two vectors might be large because their lengths differ, but the cosine distance is small because the angle between them is small. We can mitigate some of this by normalizing the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(\n",
    "    wmd=train_df.apply(lambda x: model.wmdistance(x.q1_nostop, x.q2_nostop), axis=1),\n",
    "    norm_wmd=train_df.apply(lambda x: norm_model.wmdistance(x.q1_nostop, x.q2_nostop), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distance measures**\n",
    "\n",
    "*cosine*: the cosine distance between 1-D arrays $u$ and $v$ is defined as:\n",
    "\n",
    "$$1 - \\frac{u \\cdot v}{\\lVert u\\rVert_2 \\lVert v\\rVert_2}$$\n",
    "\n",
    "*cityblock*: the Manhattan distance between two 1-D arrays $u$ and $v$, which is defined as:\n",
    "\n",
    "$$\\sum_{i}\\lvert u_i - v_i\\rvert$$\n",
    "\n",
    "*jaccard*: the Jaccard-Needham dissimilarity between 1-D boolean arrays $u$ and $v$ is defined as:\n",
    "\n",
    "$$\\frac{c_{TF} + c_{FT}}{c_{TT} + c_{FT} + c_{TF}}$$\n",
    "\n",
    "where $c_ij$ is the number of occurrences of $u[k] = i$ and $v[k] = j$ for $k < n$.\n",
    "\n",
    "*canberra*: the Canberra distance between two 1-D arrays is defined as:\n",
    "\n",
    "$$d(u, v) = \\sum_{i}\\frac{\\lvert u_i - v_i\\rvert}{\\lvert u_i\\rvert + \\lvert v_i\\rvert}$$\n",
    "\n",
    "*euclidean*: the Euclidean distance between 1-D arrays $u$ and $v$ is defined as:\n",
    "\n",
    "$${||u-v||}_2$$\n",
    "$$\\left(\\sum{(w_i |(u_i - v_i)|^2)}\\right)^{1/2}$$\n",
    "\n",
    "where $w$ is the weights for each value in $u$ and $v$. Default is None, which gives each value a weight of 1.0.\n",
    "\n",
    "*minkowski*: the Minkowski distance between 1-D arrays $u$ and $v$ is defined as:\n",
    "\n",
    "$${||u-v||}_p = (\\sum{|u_i - v_i|^p})^{1/p}$$\n",
    "$$\\left(\\sum{w_i(|(u_i - v_i)|^p)}\\right)^{1/p}$$\n",
    "\n",
    "where $w$ is the weights for each value in $u$ and $v$. Default is None, which gives each value a weight of 1.0.\n",
    "\n",
    "*braycurtis*: Bray-Curtis distance is defined as:\n",
    "\n",
    "$$\\sum{|u_i-v_i|} / \\sum{|u_i+v_i|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skew and Kurtosis**\n",
    "\n",
    "*skew*: For normally distributed data, the skewness should be about 0. For unimodal continuous distributions, a skewness value > 0 means that there is more weight in the right tail of the distribution.\n",
    "\n",
    "*kurtosis*: Kurtosis is the fourth central moment divided by the square of the variance. If Fisher’s definition is used, then 3.0 is subtracted from the result to give 0.0 for a normal distribution. If bias is False then the kurtosis is calculated using k statistics to eliminate bias coming from biased moment estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_vectors = np.zeros((len(train_df), 300))\n",
    "q2_vectors = np.zeros((len(train_df), 300))\n",
    "\n",
    "for i, q in tqdm(enumerate(train_df.question1.values)):\n",
    "    q1_vectors[i, :] = sent2vec(q)\n",
    "\n",
    "for i, q in tqdm(enumerate(train_df.question2.values)):\n",
    "    q2_vectors[i, :] = sent2vec(q)\n",
    "    \n",
    "train_df = train_df.assign(\n",
    "    cosine_distance=[cosine(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    cityblock_distance=[cityblock(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    jaccard_distance=[jaccard(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    canberra_distance=[canberra(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    euclidean_distance=[euclidean(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    minkowski_distance=[minkowski(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    braycurtis_distance=[braycurtis(x, y) for x, y in zip(np.nan_to_num(q1_vectors), np.nan_to_num(q2_vectors))],\n",
    "    skew_q1vec=[skew(x) for x in np.nan_to_num(q1_vectors)],\n",
    "    skew_q2vec=[skew(x) for x in np.nan_to_num(q2_vectors)],\n",
    "    kurtosis_q1vec=[kurtosis(x) for x in np.nan_to_num(q1_vectors)],\n",
    "    kurtosis_q2vec=[kurtosis(x) for x in np.nan_to_num(q2_vectors)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More features:**\n",
    "\n",
    "* Length\n",
    "* Difference in lengths between questions\n",
    "* Char length (without spaces)\n",
    "* Number of words\n",
    "* Number of words in common\n",
    "* Various Levenshtein Distance ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(\n",
    "    q1_len=train_df.question1.apply(lambda x: len(str(x))),\n",
    "    q2_len=train_df.question2.apply(lambda x: len(str(x))),\n",
    "    q1_char_len=train_df.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', ''))))),\n",
    "    q2_char_len=train_df.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', ''))))),\n",
    "    q1_num_words=train_df.question1.apply(lambda x: len(str(x).split())),\n",
    "    q2_num_words=train_df.question2.apply(lambda x: len(str(x).split())),\n",
    "    num_common_words=train_df.apply(lambda x: len(set(str(x.question1).lower().split()).intersection(set(str(x.question2).lower().split()))), axis=1),\n",
    "    fuzz_qratio=train_df.apply(lambda x: fuzz.QRatio(str(x.question1), str(x.question2)), axis=1),\n",
    "    fuzz_wratio=train_df.apply(lambda x: fuzz.WRatio(str(x.question1), str(x.question2)), axis=1),\n",
    "    fuzz_partial_ratio=train_df.apply(lambda x: fuzz.partial_ratio(str(x.question1), str(x.question2)), axis=1),\n",
    "    fuzz_partial_token_set_ratio=train_df.apply(lambda x: fuzz.partial_token_set_ratio(str(x.question1), str(x.question2)), axis=1),\n",
    "    fuzz_partial_token_sort_ratio=train_df.apply(lambda x: fuzz.partial_token_sort_ratio(str(x.question1), str(x.question2)), axis=1),\n",
    "    fuzz_token_set_ratio=train_df.apply(lambda x: fuzz.token_set_ratio(str(x.question1), str(x.question2)), axis=1),\n",
    "    fuzz_token_sort_ratio=train_df.apply(lambda x: fuzz.token_sort_ratio(str(x.question1), str(x.question2)), axis=1)\n",
    ")\n",
    "train_df = train_df.assign(len_diff=train_df.q1_len - train_df.q2_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_words = ['am', 'are', 'can', 'could', 'did', 'does', 'had', 'has', 'have', 'how', 'is', 'may', 'might',\n",
    "           'shall', 'was', 'were', 'what', 'where', 'which', 'who', 'why', 'will', 'would']\n",
    "add_q_words = ['at', 'do', 'from', 'if', 'in', 'on', 'over', 'should', 'to', 'under', 'when']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(\n",
    "    q1_starts_with_q_word=train_df.question1.apply(lambda x: int([w.lower() for w in x.split()][0] in q_words)),\n",
    "    q2_starts_with_q_word=train_df.question2.apply(lambda x: int([w.lower() for w in x.split()][0] in q_words)),\n",
    "    q1_starts_with_add_q_word=train_df.question1.apply(lambda x: int([w.lower() for w in x.split()][0] in add_q_words)),\n",
    "    q2_starts_with_add_q_word=train_df.question2.apply(lambda x: int([w.lower() for w in x.split()][0] in add_q_words)),\n",
    "    q1_ends_with_q_mark=train_df.question1.apply(lambda x: int(x.endswith('?'))),\n",
    "    q2_ends_with_q_mark=train_df.question2.apply(lambda x: int(x.endswith('?')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args:\n",
    "# decode_error: {‘strict’, ‘ignore’, ‘replace’} instruction on what to do if a byte sequence \n",
    "#               is given to analyze that contains characters not of the given encoding.\n",
    "#\n",
    "# stop_words: If a string, it is passed to _check_stop_list and the appropriate stop list is returned. \n",
    "#             ‘english’ is currently the only supported string value.\n",
    "#\n",
    "# ngram_range: (tuple[int]) lower and upper boundary of the range of n-values for different \n",
    "#              n-grams to be extracted\n",
    "#\n",
    "# max_df: (float|int) maximum document frequency (corpus-specific stop words)\n",
    "#\n",
    "# min_df: (float|int) minimum document frequency (cutoff)\n",
    "#\n",
    "# max_features: (int) selects the top-n most frequently occurring words in the corpus\n",
    "#\n",
    "# norm: {‘l1’, ‘l2’, None} Norm used to normalize term vectors.\n",
    "#\n",
    "# use_idf: (bool) enable inverse-document-frequency reweighting.\n",
    "#\n",
    "# smooth_idf: (bool) Smooth idf weights by adding one to document frequencies, as if an extra \n",
    "#             document was seen containing every term in the collection exactly once. Prevents \n",
    "#             zero divisions.\n",
    "#\n",
    "# sublinear_tf: (bool) apply sublinear tf scaling, i.e. replace tf with 1 + log(tf).\n",
    "#\n",
    "# sublinear scaling and inverse document frequency should be turned on (sublinear_tf=True, \n",
    "# use_idf=True) to bring the feature values closer to a Gaussian distribution, compensating \n",
    "# for LSA’s erroneous assumptions about textual data.\n",
    "vectorizer = TfidfVectorizer(decode_error='ignore', stop_words='english', ngram_range=(1, 2),\n",
    "                             max_df=0.5, min_df=2, max_features=10000,\n",
    "                             norm='l2', use_idf=True, smooth_idf=True,  # defaults\n",
    "                             sublinear_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = np.concatenate([train_df.question1.values, train_df.question2.values])\n",
    "vectorizer = vectorizer.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tfidf = vectorizer.transform(train_df.question1.values)\n",
    "q2_tfidf = vectorizer.transform(train_df.question2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latent Semantic Analysis (LSA)**\n",
    "\n",
    "All topic models are based on the same basic assumptions:\n",
    "* Each *document* consists of a mixture of *topics*, and\n",
    "* Each *topic* consists of a collection of *words*.\n",
    "\n",
    "In other words, topic models are built around the idea that the semantics of our document are actually being governed by some hidden, or “latent,” variables that we are not observing. As a result, the goal of topic modeling is to uncover these latent variables — *topics* — that shape the meaning of our document and corpus.\n",
    "\n",
    "The core idea is to take a matrix of what we have — documents and terms (words in the document) — and decompose it into a separate document-topic matrix and a topic-term matrix.\n",
    "\n",
    "The first step is generating our document-term matrix. Given m documents and n words in our vocabulary, we can construct an m × n matrix A in which each row represents a document and each column represents a word. In the simplest version of LSA, each entry can simply be a raw count of the number of times the j-th word appeared in the i-th document. In practice, however, raw counts do not work particularly well because they do not account for the significance of each word in the document. For example, the word “nuclear” probably informs us more about the topic(s) of a given document than the word “test.”\n",
    "\n",
    "Consequently, LSA models typically replace raw counts in the document-term matrix with a tf-idf score.\n",
    "\n",
    "Once we have our document-term matrix A, we can start thinking about our latent topics. Here’s the thing: in all likelihood, $A$ is very sparse, very noisy, and very redundant across its many dimensions. As a result, to find the few latent topics that capture the relationships among the words and documents, we want to perform dimensionality reduction on $A$.\n",
    "\n",
    "This dimensionality reduction can be performed using truncated SVD. SVD, or singular value decomposition, is a technique in linear algebra that factorizes any matrix $M$ into the product of 3 separate matrices: The $M = U\\times S\\times V$, where $S$ is a diagonal matrix of the singular values of $M$. Critically, truncated SVD reduces dimensionality by selecting only the $t$ largest singular values, and only keeping the first $t$ columns of $U$ and $V$. In this case, $t$ is a hyperparameter we can select and adjust to reflect the number of topics we want to find.\n",
    "\n",
    "See [Topic Modeling with LSA, PLSA, LDA & lda2Vec](https://medium.com/nanonets/topic-modeling-with-lsa-psla-lda-and-lda2vec-555ff65b0b05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vstack([q1_tfidf, q2_tfidf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = TruncatedSVD(n_components=100, algorithm='randomized', n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_model = svd_model.fit(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(svd_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_svd = normalizer.transform(svd_model.transform(q1_tfidf))\n",
    "q2_svd = normalizer.transform(svd_model.transform(q2_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `spatial.distance.cosine` computes the distance, not the similarity.\n",
    "# So you must subtract the value from 1 to get the similarity.\n",
    "scores = []\n",
    "for u, v in zip(q1_svd, q2_svd):\n",
    "    cosine_similarity = 1 - cosine(u, v)\n",
    "    scores.append(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(lsa_cosine_similarity=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = umap.UMAP(n_neighbors=150, min_dist=0.5, random_state=12).fit_transform(q1_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=train_df.is_duplicate.values, s=10, edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Latent Dirichlet Allocation (LDA)**\n",
    "\n",
    "LDA is a Bayesian version of Probabilistic Latent Semantic Analysis (pLSA). In particular, it uses dirichlet priors for the document-topic and word-topic distributions, lending itself to better generalization.\n",
    "\n",
    "With LDA, we can extract human-interpretable topics from a document corpus, where each topic is characterized by the words they are most strongly associated with. For example, topic 2 could be characterized by terms such as “oil, gas, drilling, pipes, Keystone, energy,” etc. Furthermore, given a new document, we can obtain a vector representing its topic mixture, e.g. 5% topic 1, 70% topic 2, 10% topic 3, etc. These vectors are often very useful for downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.contrib.learn.python.learn.preprocessing.text.VocabularyProcessor at 0x134ef64e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_processor.fit(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_processor.vocabulary_._mapping['countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamulticore import LdaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dictionary = Dictionary(texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]\n",
    "lda = LdaModel(common_corpus, num_topics=100, update_every=1, chunksize=10000, passes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `spatial.distance.cosine` computes the distance, not the similarity.\n",
    "# So you must subtract the value from 1 to get the similarity.\n",
    "scores = []\n",
    "for q1, q2 in zip(train_df.question1.values, train_df.question2.values):\n",
    "    q1_bow = common_dictionary.doc2bow(q1.split())\n",
    "    q2_bow = common_dictionary.doc2bow(q2.split())\n",
    "    # `<doc>_lda` is a vector of length num_topics representing \n",
    "    # the weighted presence of each topic in the doc\n",
    "    q1_lda = lda[q1_bow]\n",
    "    q2_lda = lda[q2_bow]\n",
    "    cosine_similarity = 1 - cosine(q1_lda, q2_lda)\n",
    "    scores.append(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.assign(lda_cosine_similarity=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lda2vec**\n",
    "\n",
    "lda2vec is an extension of word2vec and LDA that jointly learns word, document, and topic vectors.\n",
    "\n",
    "With lda2vec, instead of using the word vector directly to predict context words, we leverage a context vector to make the predictions. This context vector is created as the sum of two other vectors: the word vector and the document vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.doc_similarity.extractor as extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ml.doc_similarity.graph_features as graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_rank_feature = graph.GraphPageRank(train_df, config,\n",
    "                                        weight_feature_name=None,\n",
    "                                        weight_feature_id=None,\n",
    "                                        reverse=False,\n",
    "                                        alpha=0.85,\n",
    "                                        max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['qid1', 'qid2', 'question1', 'question2', 'is_duplicate', 'q1_nostop',\n",
    "       'q2_nostop', 'norm_wmd', 'wmd', 'braycurtis_distance',\n",
    "       'canberra_distance', 'cityblock_distance', 'cosine_distance',\n",
    "       'euclidean_distance', 'jaccard_distance', 'kurtosis_q1vec',\n",
    "       'kurtosis_q2vec', 'minkowski_distance', 'skew_q1vec', 'skew_q2vec',\n",
    "       'fuzz_partial_ratio', 'fuzz_partial_token_set_ratio',\n",
    "       'fuzz_partial_token_sort_ratio', 'fuzz_qratio', 'fuzz_token_set_ratio',\n",
    "       'fuzz_token_sort_ratio', 'fuzz_wratio', 'num_common_words',\n",
    "       'q1_char_len', 'q1_len', 'q1_num_words', 'q2_char_len', 'q2_len',\n",
    "       'q2_num_words', 'len_diff', 'q1_ends_with_q_mark',\n",
    "       'q1_starts_with_add_q_word', 'q1_starts_with_q_word',\n",
    "       'q2_ends_with_q_mark', 'q2_starts_with_add_q_word',\n",
    "       'q2_starts_with_q_word']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*page rank*: only relevant if using weights otherwise every pair scores the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_df = page_rank_feature.extract(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_max_clique_size_feature = graph.GraphEdgeMaxCliqueSize(train_df, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = edge_max_clique_size_feature.extract(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle('train_df_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
